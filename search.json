[{"title":"PAT 1033：To Fill or Not to Fill 贪心","url":"/2020/02/25/2020-02-25-PAT-1033-%E8%B4%AA%E5%BF%83/","content":"<blockquote>\r\n<p>加油站问题</p>\r\n</blockquote>\r\n<h3 id=\"题目链接\">题目链接</h3>\r\n<p>PAT：<a href=\"https://pintia.cn/problem-sets/994805342720868352/problems/994805458722734080\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://pintia.cn/problem-sets/994805342720868352/problems/994805458722734080</a></p>\r\n<p>牛客：<a href=\"https://www.nowcoder.com/practice/f7eba38f7cd24c45982831e0f38518f9?tpId=63&amp;tqId=29602&amp;tPage=2&amp;ru=/kaoyan/retest/9001&amp;qru=/ta/zju-kaoyan/question-ranking\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://www.nowcoder.com/practice/f7eba38f7cd24c45982831e0f38518f9?tpId=63&amp;tqId=29602&amp;tPage=2&amp;ru=/kaoyan/retest/9001&amp;qru=/ta/zju-kaoyan/question-ranking</a></p>\r\n<h3 id=\"题意\">题意</h3>\r\n<p>一条线段，起点到终点的距离是D，从起点开始路上有N个加油站，每个加油站的油价都不一样。现在一辆车的油箱容量是Cmax，每单位的油可以跑Davg的路程。现在给定N个加油站各自离起点的距离Di、油价Pi(钱/单位油)。问汽车能否顺利到达终点。如果能，采取怎样的加油策略，花费最少；如果不能，最多能走多少距离。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"题解\">题解</h3>\r\n<h4 id=\"分析\">分析</h4>\r\n<p>到达不了终点的情况很好判定：在某两个加油站之间的路程，加满了油也无法通过。此时加满油最多能走的路程+上一个加油站的位置，就是最多能走的距离。</p>\r\n<p>下面考虑在一定能到达情况下，花费最少的策略：</p>\r\n<p>总路程是一定的，每单位的油能跑的路程也是一定的。所以最终使用的油的总量也是定值。直观来看，应该在保证能够继续前行的前提下，在更便宜的加油站加更多的油。</p>\r\n<p>先粗略分析一下，当路过每个加油站的时候，决定是否加油、加多少油的因素有：</p>\r\n<ul>\r\n<li><p>首先得保证能在油尽之前到达下一个加油站</p></li>\r\n<li><p>其次，如果加油太多，会不会因为前方有更便宜的加油站，导致不划算？</p>\r\n<p>===&gt;毕竟如果有更便宜的加油站，到那里留着更大的空间（带着空油箱去）加更多的油，才是更划算的决策</p></li>\r\n<li><p>反之，如果加油太少，会不会因为前方可到达的加油站都比较贵，导致不划算？</p>\r\n<p>===&gt;为了继续前进，必须到前方可到达的加油站之一进行加油，如果他们都比目前的贵，为何不趁现在多加一点油（加满）？</p></li>\r\n</ul>\r\n<h4 id=\"采用的贪心策略\">采用的贪心策略</h4>\r\n<p>依据上述的分析，先给出贪心策略（后面证明其正确性）：</p>\r\n<ul>\r\n<li><p>到达某个加油站时，检查后面可到达的加油站的范围（加满油可到达的加油站的范围）</p></li>\r\n<li><p>若找到了第一个（离当前加油站最近的）价格低于当前加油站价格的加油站st[next]</p>\r\n<ul>\r\n<li>检查当前的油量</li>\r\n<li>若不够到达st[next]，则加油到刚好到达那个加油站,前往st[next],开始下一轮选择</li>\r\n<li>若够到达，则不加油，直接前往st[next],开始下一轮选择</li>\r\n</ul></li>\r\n<li><p>若每一个可到达的加油站都比当前的贵</p>\r\n<ul>\r\n<li>检查是否能直接到达终点</li>\r\n<li>若能直接到达终点\r\n<ul>\r\n<li>检查当前油量是否能到达终点</li>\r\n<li>若能，则直接前往终点</li>\r\n<li>若不能，则加油至正好能到达终点</li>\r\n</ul></li>\r\n<li>若不能直接到达终点\r\n<ul>\r\n<li>在当前加油站加满油</li>\r\n<li>直接前往后面加油站中油价最低的,开始下一轮选择</li>\r\n</ul></li>\r\n</ul></li>\r\n</ul>\r\n<h4 id=\"最优子结构\">最优子结构</h4>\r\n<p><strong>对子问题进行定义：</strong>当前到达第i个加油站，油箱内的剩余油量是gas，求到达终点的最低代价，记做二元组(i, gas)。此最低代价记作S(i, gas)。</p>\r\n<p><strong>对求解每个子问题时候的\"选择\"进行定义：</strong>选择加add的油，下一次前往第j个加油站，记做二元组(add,j)。对于每个子问题(i, gas)，都有一个选择的取值集合<span class=\"math inline\">\\(C\\)</span>_<span class=\"math inline\">\\(S(i,gas)\\)</span> (Choose_set的简写)，满足选择的合理性（不能超过油箱、加油后能到达所选择的加油站）：</p>\r\n<p><span class=\"math display\">\\[\r\nC\\_S(i,gas) =\\{(add,j)\\Big| i \\le j, \\ \\frac {st[j].dist-st[i].dist}{Davg} \\le add+gas\\le Cmax \\}\r\n\\]</span></p>\r\n<p>若原问题的解是最优的，那么当做出选择之后，会得到一个子问题，这个的子问题的解一定是最优的。（若不是最优的，则换成最优的，而选择的代价没有改变，进而得到的新的原问题是更优的，与原本的原问题最优的假设矛盾，反证成立）===&gt;最优子结构得证</p>\r\n<p>所以能够得到以下递推式：</p>\r\n<p><span class=\"math display\">\\[\r\nS(i,gas)=\\min_{(add,j)\\in C\\_S(i,gas)}\\{add\\cdot st[i].price + S(j, gas-\\frac{st[j].dist-st[i].dist}{Davg}) \\}\r\n\\]</span></p>\r\n<h4 id=\"贪心选择性\">贪心选择性</h4>\r\n<p>这个形式化证明起来比较繁琐，这里简要说明<del>（口胡）</del></p>\r\n<ul>\r\n<li><p>当后续加油站有更便宜的</p>\r\n<ul>\r\n<li>为何要用第一个更便宜的，而不是后面的更便宜的（如果有）\r\n<ul>\r\n<li>粗证：假设不用第一个，那么需要花更多的油到达后面的，行驶这整个部分的油，都是来自与较高价格的油。而用第一个的话，可以在后续段中使用更低价格的油。</li>\r\n</ul></li>\r\n<li>为何要加油至能正好到达：\r\n<ul>\r\n<li>粗证：假设加更多的油，相当于多加了一部分高价油，而本来这部分油可以被 在到达便宜加油站之后加的油替换掉。因此只需保证能到达这个“第一个更便宜的加油站即可”</li>\r\n</ul></li>\r\n</ul></li>\r\n<li><p>如果后续加油站没有更便宜的</p>\r\n<ul>\r\n<li><p>若能直接到终点</p>\r\n<ul>\r\n<li>为何尽量直接到达终点\r\n<ul>\r\n<li>粗证：既然后面的加油站都比较贵，与其在它们那里停靠加油，不如直接在当前（更便宜的）加油站加满到终点所需的油。</li>\r\n</ul></li>\r\n</ul></li>\r\n<li><p>若不能直接到终点：</p>\r\n<ul>\r\n<li>为何要加满\r\n<ul>\r\n<li>粗证：为了继续前进，必须在后续加油站的其中一个停靠。最后总得在某个更贵的站点补充油，所以为了能在后续更贵的站点补更少的油，此时应该加得尽可能多。</li>\r\n</ul></li>\r\n<li>为何要停在后续最低价的加油站\r\n<ul>\r\n<li>粗证：为了继续前进，必须在后续加油站的其中一个停靠。既然停靠的话，应该找更便宜的停靠，进而寻找接下来的机会。 <em>(注：我感觉这段证明真的口胡，但没有严谨证明的思路，恳请大家指点)</em></li>\r\n</ul></li>\r\n</ul></li>\r\n</ul></li>\r\n</ul>\r\n<h3 id=\"ac代码\">AC代码</h3>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;bits/stdc++.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Station</span> &#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">double</span> price;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> dist;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">bool</span> <span class=\"keyword\">operator</span>&lt;(<span class=\"keyword\">const</span> Station&amp; s)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dist &lt; s.dist;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">Station st[<span class=\"number\">505</span>];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> Cmax, D, Davg, N;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">while</span> (~<span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d %d %d %d\"</span>, &amp;Cmax, &amp;D, &amp;Davg, &amp;N)) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; N; i++) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%lf %d\"</span>, &amp;(st[i].price), &amp;(st[i].dist));</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        </span><br><span class=\"line\">        sort(st, st + N);</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\">// 第N + 1个加油站为终点</span></span><br><span class=\"line\">        st[N].price = <span class=\"number\">0</span>;</span><br><span class=\"line\">        st[N].dist = D;</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">int</span> loc = <span class=\"number\">0</span>;   <span class=\"comment\">// 当前是第几个加油站</span></span><br><span class=\"line\">        <span class=\"keyword\">double</span> gas = <span class=\"number\">0</span>;   <span class=\"comment\">// 当前油量</span></span><br><span class=\"line\">        <span class=\"keyword\">double</span> dist = <span class=\"number\">0</span>;  <span class=\"comment\">// 当前行驶距离</span></span><br><span class=\"line\">        <span class=\"keyword\">double</span> pay = <span class=\"number\">0</span>;   <span class=\"comment\">// 当前累计付款</span></span><br><span class=\"line\">        <span class=\"keyword\">bool</span> ach = <span class=\"literal\">true</span>;   <span class=\"comment\">// 标记是否能够到达目的地</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (st[<span class=\"number\">0</span>].dist != <span class=\"number\">0</span>) &#123; <span class=\"comment\">// 第一个加油站不在0位置，一定到不了</span></span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"The maximum travel distance = 0.00\\n\"</span>);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (loc &lt; N) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">bool</span> hasNext = <span class=\"literal\">false</span>;  <span class=\"comment\">// 从当前加油站出去，是否能到达下个加油站</span></span><br><span class=\"line\">            <span class=\"keyword\">bool</span> minor = <span class=\"literal\">false</span>;    <span class=\"comment\">/*当前加油站后面能到达</span></span><br><span class=\"line\"><span class=\"comment\">                                      的所有加油站中，是否有比当前价格低的*/</span></span><br><span class=\"line\">            <span class=\"keyword\">double</span> mmin = DBL_MAX; </span><br><span class=\"line\">            <span class=\"keyword\">int</span> next = loc;    <span class=\"comment\">// 下次加油的加油站序号</span></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">int</span> i = loc + <span class=\"number\">1</span>;   </span><br><span class=\"line\">            <span class=\"comment\">// 开始向后检索当前能够到达的加油站  </span></span><br><span class=\"line\">            <span class=\"comment\">// 最多检查到st[N](终点), 以便最后一个加油站的判定</span></span><br><span class=\"line\">            <span class=\"keyword\">while</span> (i &lt;= N &amp;&amp; st[i].dist - st[loc].dist &lt;= Cmax * Davg) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!hasNext) hasNext = <span class=\"literal\">true</span>;   <span class=\"comment\">// 能进入循环, 代表能继续往后走</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (i &lt; N)&#123;   <span class=\"comment\">// 不包括终点</span></span><br><span class=\"line\">                    <span class=\"comment\">// 寻找离当前加油站最近的价格低的加油站</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (st[i].price &lt; st[loc].price) &#123;</span><br><span class=\"line\">                        minor = <span class=\"literal\">true</span>;   <span class=\"comment\">// 标记\"有价格比当前低的\"</span></span><br><span class=\"line\">                        next = i;       <span class=\"comment\">// 将其设为下一次加油的点</span></span><br><span class=\"line\">                        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    <span class=\"comment\">// 同时统计所有能到达的加油站中, 价格最低的</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (st[i].price &lt; mmin) &#123;</span><br><span class=\"line\">                        mmin = st[i].price;</span><br><span class=\"line\">                        next = i;</span><br><span class=\"line\">                    &#125; </span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                i++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">// 如果当前加油站无法到达任何后续的加油站, 则无法到达终点</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!hasNext) &#123;</span><br><span class=\"line\">                ach = <span class=\"literal\">false</span>;</span><br><span class=\"line\">                dist += Cmax * Davg; <span class=\"comment\">// 这一小段最多行驶这么多</span></span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">// 如果后续可到达的加油站中, 没有比当前价格低的</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!minor) &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 若直接可以到达终点, 下次就直接到终点</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (D - st[loc].dist &lt;= Cmax * Davg) &#123;</span><br><span class=\"line\">                    <span class=\"comment\">// 如果油不够到终点, 就加到正好够到达终点</span></span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (gas * Davg &lt; D - st[loc].dist) &#123;</span><br><span class=\"line\">                        pay += ((<span class=\"keyword\">double</span>)(D - st[loc].dist) / Davg - gas) * st[loc].price;</span><br><span class=\"line\">                        gas = (<span class=\"keyword\">double</span>)(D - st[loc].dist) / Davg;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    gas -= (<span class=\"keyword\">double</span>)(st[N].dist - st[loc].dist) / Davg;</span><br><span class=\"line\">                    dist = D;</span><br><span class=\"line\">                    loc = N;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"comment\">// 不能到达终点, 就加满油, 然后到达可到的的加油站中价格最低的</span></span><br><span class=\"line\">                <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                    pay += (Cmax - gas) * st[loc].price;</span><br><span class=\"line\">                    gas = Cmax;</span><br><span class=\"line\"></span><br><span class=\"line\">                    gas -= (<span class=\"keyword\">double</span>)(st[next].dist - st[loc].dist) / Davg;</span><br><span class=\"line\">                    dist = st[next].dist;</span><br><span class=\"line\">                    loc = next;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">// 有价格低于当前加油站的</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"comment\">// 油不够, 就加到正好够到那个加油站</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (gas * Davg &lt; st[next].dist - st[loc].dist) &#123;</span><br><span class=\"line\">                    pay += ((<span class=\"keyword\">double</span>)(st[next].dist - st[loc].dist) / Davg  - gas) * st[loc].price;</span><br><span class=\"line\">                    gas = (<span class=\"keyword\">double</span>)(st[next].dist - st[loc].dist) / Davg;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                </span><br><span class=\"line\">                gas -= (<span class=\"keyword\">double</span>)(st[next].dist - st[loc].dist) / Davg;</span><br><span class=\"line\">                dist = st[next].dist;</span><br><span class=\"line\">                loc = next;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> (ach) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"%.2f\\n\"</span>, pay);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"The maximum travel distance = %.2f\\n\"</span>, dist);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\r\n","categories":["算法题解"],"tags":["算法","贪心","PAT"]},{"title":"CodeForce 555 B：Case of Fugitive 贪心","url":"/2020/02/23/2020-02-23-CF-555B-%E8%B4%AA%E5%BF%83/","content":"<blockquote>\r\n<p>架桥连接相邻岛</p>\r\n</blockquote>\r\n<h3 id=\"题目链接\">题目链接</h3>\r\n<p><a href=\"https://codeforces.com/problemset/problem/555/B\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://codeforces.com/problemset/problem/555/B</a></p>\r\n<h3 id=\"题意\">题意</h3>\r\n<p>一维数轴上有若干个岛，岛屿岛之间不重叠，每个岛在数轴上有起点和终点。相邻两个岛上可以架桥，桥的两头要正好在岛上（不能多出去，但也要能架住）。现在给你一系列的桥，问能否把这些相邻的岛全部连起来。</p>\r\n<p>数据范围：岛和桥的数量都<span class=\"math inline\">\\(\\le2\\times10^5\\)</span></p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"解题的悲惨心路历程\">解题的<del>（悲惨）</del>心路历程</h3>\r\n<p>首先就想到了，应该把每个gap的min和max记录下来，然后开始猜想如何贪心 (因为是在王道上的贪心章节看到的题) 。然后就想到了把gap按min从大到小排序，按次序处理gap，每次找能满足当前(min最大)的gap的 可用的最长的bridge。。然后在脑海里成功证明了贪心选择性（开局能完成这个工作老兴奋了，后来blb尝试叉掉失败，我的分析是正确的，<del>不愧是我</del>）：</p>\r\n<blockquote>\r\n<p>反证法：如果当前可用的最长的bridge不用在这个min最大的gap上（即假设该局部解不是全局解），那么有两种可能（假设这种情况下，min最大的gap记做<span class=\"math inline\">\\(G_0\\)</span>，此时放在<span class=\"math inline\">\\(G_0\\)</span>上的bridge是$ B'<span class=\"math inline\">\\(， 当前可用的最长的bridge为\\)</span>B_{max}<span class=\"math inline\">\\(。显然\\)</span>B'B_{max}$）：</p>\r\n<ol type=\"1\">\r\n<li>这个bridge在全局解中完全没有出现。那么，把$ B'<span class=\"math inline\">\\(换成\\)</span>B_{max}<span class=\"math inline\">\\(是可行的（因为根据假设，\\)</span>B_{max}<span class=\"math inline\">\\(放在\\)</span>G_0$上是可行的）</li>\r\n<li>这个bridge在全局解中出现了，但是放在了另一个gap上（设为<span class=\"math inline\">\\(G&#39;\\)</span>）。根据前述gap的排序，<span class=\"math inline\">\\(G&#39;.min\\le G_0.min\\)</span>，既然<span class=\"math inline\">\\(B&#39;\\)</span>能放在<span class=\"math inline\">\\(G_0\\)</span>上，说明<span class=\"math inline\">\\(G&#39;.min\\le G_0.min\\le B&#39;\\)</span>。同理，既然<span class=\"math inline\">\\(B_{max}\\)</span>能放在<span class=\"math inline\">\\(G&#39;\\)</span>上，说明<span class=\"math inline\">\\(B&#39;\\le B_{max}\\le G&#39;.max\\)</span>。综合起来就是<span class=\"math inline\">\\(G&#39;.min\\le B&#39; \\le G&#39;.max\\)</span>，因此<span class=\"math inline\">\\(B&#39;\\)</span>可以放到<span class=\"math inline\">\\(G&#39;\\)</span>上。又根据假设，<span class=\"math inline\">\\(B_{max}\\)</span>放在<span class=\"math inline\">\\(G_0\\)</span>上是可行的，所以<span class=\"math inline\">\\(B&#39;\\)</span>和<span class=\"math inline\">\\(B_{max}\\)</span>可以交换位置，这样的解也是符合要求的。</li>\r\n</ol>\r\n<p>根据上述分析，每次找能满足当前(min最大)的gap的 可用的最长的bridge，是某个可行解的一部分，按照这个贪心下去，一定能找到可行解。</p>\r\n</blockquote>\r\n<p>主要工作已经完成了，屁颠屁颠写了个代码，大致是把gaps排序，bridges也排序，然后遍历每个gap，从前到后找可行bridge，找到就将其匹配，再另一个used数组上标记一下，表示这个bridge已经被用。算了一下复杂度是<span class=\"math inline\">\\(O(mn)\\)</span>，侥幸交了几发，然后就T了。</p>\r\n<p>于是痛定思痛，开始优化复杂度。想到bridges是有序的，想到二分。写了个二分，找小于当前gap.max的最大bridge。找到之后再往后移，直到有没用到的(used[l] = false)，如果这个bridge<span class=\"math inline\">\\(\\ge\\)</span>gap.min，就当做找到了；否则如果没找到或者bridge&lt;gap.min就无解。这样写来是降了一点复杂度，多过了几个test，但是还是T了。原因应该是找used[l] = false花了不少时间。</p>\r\n<p>大大小小调了很多东西，未果，扔给blb。得知C++中的set是平衡树，可用set来存bridges，利用其lower_bound方法实现上述的二分过程，同时返回的迭代器可直接用于erase方法。</p>\r\n<p>遂尝试，结果WA了，仔细分析盲目分析数学分析xjb分析未果，遂扔给blb，出去遛弯。。。</p>\r\n<p>后来blb发现了我的锅，在重载Bridge结构体的&lt;的时候，只写了个长度的比较，没有把index加进去。由于set中元素的唯一性，导致了相同的Bridge就被替换掉了，遂顿悟。(此锅在后文中有详细总结)</p>\r\n<h3 id=\"题解\">题解</h3>\r\n<p>上面的贪心选择性已经证明了，这里直接给贪心思路：</p>\r\n<p>把gaps以min为第一关键字，max为第二关键字，降序排序。依次处理每个gap，这样就相当于每次都在处理min最大的gap，记为<span class=\"math inline\">\\(G\\)</span>。现在需要找能放在<span class=\"math inline\">\\(G\\)</span>上的<strong>最大的</strong>bridge，只需找小于等于<span class=\"math inline\">\\(G.max\\)</span>最大的bridge就可，若找到的bridge的长度是<span class=\"math inline\">\\(\\ge G.min\\)</span>的，就完成了这个gap的匹配，erase掉这个bridge即可；否则代表无解。</p>\r\n<p>于是，把bridges放在set里，在找小于等于<span class=\"math inline\">\\(G.max\\)</span>最大的bridge时，就可以用到lower_bound方法。返回的迭代器可直接用于erase方法。</p>\r\n<h3 id=\"相似的问题\">相似的问题</h3>\r\n<p>数轴上有n条线段，m个点，每个点最多可以分配给一个<strong>通过该点</strong>的线段，问是否每条线段都能被分配到一个符合要求的点，如何分配。</p>\r\n<p>线段的起点终点就相当于本题的Gap的min和max，点的坐标就是各个bridge的长度。</p>\r\n<h3 id=\"需要记住的坑\">需要记住的坑</h3>\r\n<ol type=\"1\">\r\n<li><p>C++中set是平衡树实现，能执行lower_bound(key)操作，意思是在set中找大于等于key的最小的元素，复杂度是<span class=\"math inline\">\\(log\\)</span>的。通过重载$ &lt;$运算符能或自定义比较函数够实现相反的（找小于等于key的最小的元素）。</p></li>\r\n<li><p>upper_bound是在set中找大于key的最小的元素</p></li>\r\n<li><p><strong>set不允许有两个同样的key值，所以在重载运算符的时候要注意。一定要保证 想加入进set的两个对象的值不能相等。</strong></p>\r\n<p>错误：</p>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Bridge</span> &#123;</span></span><br><span class=\"line\">    ll l;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> index;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">bool</span> <span class=\"keyword\">operator</span>&lt;(<span class=\"keyword\">const</span> <span class=\"built_in\">Bridge</span>&amp; b) <span class=\"keyword\">const</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> l &gt; b.l;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\r\n<p>正确：</p>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Bridge</span> &#123;</span></span><br><span class=\"line\">    ll l;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> index;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">bool</span> <span class=\"keyword\">operator</span>&lt;(<span class=\"keyword\">const</span> <span class=\"built_in\">Bridge</span>&amp; b) <span class=\"keyword\">const</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> l &gt; b.l || (l == b.l &amp;&amp; index &lt; b.index);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></li>\r\n<li><p>重载上述&lt;运算符的时候(包括在优先队列里也是)，要给函数加const，否则会报错</p>\r\n<p>(至于为什么，现在也不是很懂，以后再研究。。。。)</p></li>\r\n<li><p>long long输出的格式符是%lld而不是%ld</p></li>\r\n</ol>\r\n<h3 id=\"ac代码\">AC代码</h3>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;bits/stdc++.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">long</span> <span class=\"keyword\">long</span> ll;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Gap</span> &#123;</span></span><br><span class=\"line\">    ll <span class=\"built_in\">min</span>;</span><br><span class=\"line\">    ll <span class=\"built_in\">max</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> index;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">bool</span> <span class=\"keyword\">operator</span>&lt;(<span class=\"keyword\">const</span> Gap&amp; g) <span class=\"keyword\">const</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"built_in\">min</span> != g.<span class=\"built_in\">min</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"built_in\">min</span> &gt; g.<span class=\"built_in\">min</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"built_in\">max</span> &gt; g.<span class=\"built_in\">max</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Bridge</span> &#123;</span></span><br><span class=\"line\">    ll l;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> index;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">bool</span> <span class=\"keyword\">operator</span>&lt;(<span class=\"keyword\">const</span> <span class=\"built_in\">Bridge</span>&amp; b) <span class=\"keyword\">const</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> l &gt; b.l || (l == b.l &amp;&amp; index &lt; b.index);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">Gap g[<span class=\"number\">200005</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span> rec[<span class=\"number\">200005</span>];</span><br><span class=\"line\"><span class=\"built_in\">set</span>&lt;<span class=\"built_in\">Bridge</span>&gt; s;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">int</span> n, m;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d %d\"</span>, &amp;n, &amp;m);</span><br><span class=\"line\"></span><br><span class=\"line\">    ll p_l, p_r, l, r;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%lld %lld\"</span>, &amp;p_l, &amp;p_r);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt; n; i++) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%lld %lld\"</span>, &amp;l, &amp;r);</span><br><span class=\"line\">        g[i - <span class=\"number\">1</span>] = (Gap)&#123;l - p_r, r - p_l, i - <span class=\"number\">1</span>&#125;;</span><br><span class=\"line\">        p_l = l;</span><br><span class=\"line\">        p_r = r;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; m; i++) &#123;</span><br><span class=\"line\">        ll x;</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%lld\"</span>, &amp;x);</span><br><span class=\"line\">        s.insert((<span class=\"built_in\">Bridge</span>) &#123;x, i + <span class=\"number\">1</span>&#125;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (m &lt; n - <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"No\\n\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        sort(g, g + n - <span class=\"number\">1</span>);</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> res = <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; n - <span class=\"number\">1</span>; i++) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">auto</span> it = s.lower_bound((<span class=\"built_in\">Bridge</span>)&#123;g[i].<span class=\"built_in\">max</span>, <span class=\"number\">0</span>&#125;);</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (it == s.<span class=\"built_in\">end</span>() || (*it).l &lt; g[i].<span class=\"built_in\">min</span>) &#123;</span><br><span class=\"line\">                res = <span class=\"literal\">false</span>;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                rec[g[i].index] = (*it).index;</span><br><span class=\"line\">                s.erase(it);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (res) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"Yes\\n\"</span>);</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; n - <span class=\"number\">1</span>; i++) &#123;</span><br><span class=\"line\">                <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d \"</span>, rec[i]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"No\\n\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\r\n","categories":["算法题解"],"tags":["算法","贪心","CF"]},{"title":"CodeForce 1311 B：WeirdSort","url":"/2020/03/01/2020-03-01-CF-1311B-%E9%99%90%E5%AE%9A%E4%BA%A4%E6%8D%A2%E6%8E%92%E5%BA%8F/","content":"<blockquote>\r\n<p>限定了交换位置的排序</p>\r\n</blockquote>\r\n<h3 id=\"题目链接\">题目链接</h3>\r\n<p><a href=\"https://codeforces.com/contest/1311/problem/B\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://codeforces.com/contest/1311/problem/B</a></p>\r\n<h3 id=\"题意\">题意</h3>\r\n<p>一个乱序的数组<span class=\"math inline\">\\(a_1,a_2,a_3,...,a_n\\)</span>。想要将排成非递减序列。但是限制了只有某些位置可以交换：给定数组<span class=\"math inline\">\\(p_1,p_2,p_3,...,p_m\\)</span>，<span class=\"math inline\">\\(p_i\\)</span>表示<span class=\"math inline\">\\(a[p_i]\\)</span>可以和<span class=\"math inline\">\\(a[p_i + 1]\\)</span>进行交换。给定n、m，以及数组a[]、p[]，问在p数组的限制条件下，是否能将其排成非递减序列。</p>\r\n<p>数据范围：<span class=\"math inline\">\\(1\\le m&lt;n\\le 100\\)</span></p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"题解\">题解</h3>\r\n<h4 id=\"我的复杂做法\">我的复杂做法</h4>\r\n<p>排序过程就是移动元素的过程——也就是不断交换的过程。乱序数组的最终排序是唯一的，因此对于每个元素，如果在前往其目标位置的路上，都能连续进行交换，则排序是可行的。</p>\r\n<p>在下面的叙述中，为简便起见，若数组中某个元素能够到达最终的位置，则称这个元素为<strong>可排序的</strong>。</p>\r\n<p>首先将p数组排序。再设置一个temp数组，存储排序后的a数组。再对temp数组的每个元素(设下标为i)，依次查找其在a数组的原始位置j(不妨设i &lt; j 。因为j &gt;i同理；i = j则无需移动)，若p数组存在一组连续的子序列为i, i + 1, ..., j - 1。则对于此元素temp[i]是可排序的。只有当所有元素是可排序的，整个数组才是可排序的。</p>\r\n<p>这里需要设置一个visit数组，标记已经对应过的a[i]，用来应对多个相等元素的情况。</p>\r\n<p>另外，考虑 多个相等元素的情况时，无需担心相等元素的之间的不同的配对方案对结果的影响。因为在上述算法中，每轮处理的temp[i]，都是所有未被配对的temp数组元素最左边的元素；每次查找的a[j]，也都是所有未被配对的a数组元素最左边的元素。</p>\r\n<ul>\r\n<li>如果在某一轮中，查找到的a[j]无法到达temp[i]\r\n<ul>\r\n<li>若j &lt; i。则a[j]肯定也无法到达temp[i]之后的与temp[i]相等的元素；结果为NO没毛病。</li>\r\n<li>若i &lt; j。则a[j]之后的所有与a[j]相等的元素，都无法到达temp[i]的位置。结果为NO也没毛病。</li>\r\n</ul></li>\r\n<li>如果在某一轮中，查找到的a[j]可以到达temp[i]，并直接作为最终配对\r\n<ul>\r\n<li>若后续所有与a[j]相等的元素都找到了可到达的元素，则此配对合理；</li>\r\n<li>若后续存在temp[k] = temp[i] (k &gt;i)，没有元素可到达temp[k]，则位于所有可能的a数组元素最左边的a[j]，也不可能到达temp[k]。</li>\r\n<li>换句话说，a[j]和temp[i]配对，不影响任何一种结果的判断。</li>\r\n</ul></li>\r\n</ul>\r\n<h4 id=\"更优美的做法\">更优美的做法</h4>\r\n<p>这里参考了blb的做法）</p>\r\n<p>我们把目光聚焦到p数组。升序排序后的p数组，如同把a数组划定了若干个区域。p数组任意的连续段，就是划定了一个“自由排序”的区域。比方说， <span class=\"math inline\">\\(p_i, p_{i +1}, p_{i+2},...,p_{j - 1},p_j\\)</span>是一段连续段。则说明<span class=\"math inline\">\\(a[p_i]\\)</span>到<span class=\"math inline\">\\(a[p_j+1]\\)</span>这一段可以做局部排序。注意单独的<span class=\"math inline\">\\(p_k\\)</span>也是一个连续段，说明<span class=\"math inline\">\\(a[p_k]\\)</span>到<span class=\"math inline\">\\(a[p_k+1]\\)</span>可以做局部排序。</p>\r\n<p>那么，除了上述定义的可局部排序之外的区域，都无法进行任何移动。因此，只需找出这些可排序的区域，应用sort函数进行排序即可。最终检查a数组是否为非降序即可。</p>\r\n<h3 id=\"ac代码\">AC代码</h3>\r\n<p>更优美的做法：</p>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;bits/stdc++.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> a[<span class=\"number\">105</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span> p[<span class=\"number\">105</span>];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> t;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, &amp;t);</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (t--) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> n, m;</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d %d\"</span>, &amp;n, &amp;m);</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i++) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, a + i);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= m; i++) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, p + i);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        sort(p + <span class=\"number\">1</span>, p + m + <span class=\"number\">1</span>);</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">int</span> start = <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> <span class=\"built_in\">end</span> = <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= m; i++) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i == <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">                start = p[i];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i != <span class=\"number\">1</span> &amp;&amp; p[i] &gt; p[i - <span class=\"number\">1</span>] + <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">                sort(a + start, a + <span class=\"built_in\">end</span> + <span class=\"number\">1</span>);</span><br><span class=\"line\">                start = p[i];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"built_in\">end</span> = p[i] + <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        sort(a + start, a + <span class=\"built_in\">end</span> + <span class=\"number\">1</span>); </span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">bool</span> res = <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt; n; i++) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (a[i + <span class=\"number\">1</span>] &lt; a[i]) &#123;</span><br><span class=\"line\">                res = <span class=\"literal\">false</span> ;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (res) <span class=\"built_in\">printf</span>(<span class=\"string\">\"YES\\n\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">else</span> <span class=\"built_in\">printf</span>(<span class=\"string\">\"NO\\n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\r\n<p>我的WA了一万发终于A了的又臭又长的代码：</p>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;bits/stdc++.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> a[<span class=\"number\">105</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span> p[<span class=\"number\">105</span>];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    ios::sync_with_stdio(<span class=\"literal\">false</span>);</span><br><span class=\"line\">    <span class=\"keyword\">int</span> t;</span><br><span class=\"line\">    <span class=\"built_in\">cin</span> &gt;&gt; t;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (t--) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> n, m;</span><br><span class=\"line\">        <span class=\"built_in\">cin</span> &gt;&gt; n &gt;&gt; m;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> temp[<span class=\"number\">105</span>];</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i++) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">cin</span> &gt;&gt; a[i];</span><br><span class=\"line\">            temp[i] = a[i];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; m; i++) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> num;</span><br><span class=\"line\">            <span class=\"built_in\">cin</span> &gt;&gt; num;</span><br><span class=\"line\">            p[i] = num - <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        sort(temp, temp + n);</span><br><span class=\"line\">        sort(p, p + m);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">bool</span> visit[<span class=\"number\">105</span>];  <span class=\"comment\">// visit[i] == true 代表下标为i的已经访问</span></span><br><span class=\"line\">        <span class=\"built_in\">memset</span>(visit, <span class=\"literal\">false</span>, <span class=\"keyword\">sizeof</span>(visit));</span><br><span class=\"line\">        <span class=\"keyword\">bool</span> res = <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i++) &#123;  <span class=\"comment\">// 排序后的列表往后找</span></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">int</span> index = <span class=\"number\">0</span>;</span><br><span class=\"line\">            <span class=\"keyword\">bool</span> <span class=\"built_in\">find</span> = <span class=\"literal\">false</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">// 在原数组中查找未被匹配过的元素（有重复元素的情况下）</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = <span class=\"number\">0</span>; j &lt; n; j++) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!visit[j] &amp;&amp; temp[i] == a[j]) &#123;</span><br><span class=\"line\">                    visit[j] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">                    index = j;</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (index == i) &#123; <span class=\"comment\">// 位置相同，不用交换。</span></span><br><span class=\"line\">                <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">int</span> low = <span class=\"built_in\">min</span>(index, i);</span><br><span class=\"line\">            <span class=\"keyword\">int</span> high = <span class=\"built_in\">max</span>(index, i);</span><br><span class=\"line\">            <span class=\"keyword\">int</span> p_indix_start = <span class=\"number\">-1</span>;</span><br><span class=\"line\">            <span class=\"comment\">// 在p数组中查找第一个等于low的元素</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> k = <span class=\"number\">0</span>; k &lt; m; k++) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (p[k] == low) &#123;</span><br><span class=\"line\">                    p_indix_start = k;</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (p[k] &gt; low) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">// 若找到第一个等于low的元素，则查询后续元素是否都是连续递增的(直到high-1)</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (p_indix_start != <span class=\"number\">-1</span>) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> k = p_indix_start; k &lt; m; k++) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (p[k] == high - <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">                        <span class=\"built_in\">find</span> = <span class=\"literal\">true</span>;</span><br><span class=\"line\">                        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                    <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (k + <span class=\"number\">1</span> &gt;= m || p[k] != p[k + <span class=\"number\">1</span>] - <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">                        <span class=\"built_in\">find</span> = <span class=\"literal\">false</span>;</span><br><span class=\"line\">                        <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">// 若没找到第一个等于low的元素，则一定无法到达</span></span><br><span class=\"line\">            <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                <span class=\"built_in\">find</span> = <span class=\"literal\">false</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"comment\">// 若某元素无法排序，则整个数组必定无法排序</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!<span class=\"built_in\">find</span>) &#123;</span><br><span class=\"line\">                res = <span class=\"literal\">false</span>;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (res) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"YES\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"built_in\">cout</span> &lt;&lt; <span class=\"string\">\"NO\"</span> &lt;&lt; <span class=\"built_in\">endl</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\r\n","categories":["算法题解"],"tags":["算法","CF","排序"]},{"title":"如何在Baidu AI平台上配置tensorflow-gpu","url":"/2020/03/03/2020-03-03-%E9%85%8D%E7%BD%AEBaidu-AI/","content":"<blockquote>\r\n<p>薅百度的羊毛</p>\r\n</blockquote>\r\n<p>这几天做软件杯的项目的时候，为了实现文本中关键词关系的抽取，clone了github上的一个TensorFlow项目。该项目需要较高配置的GPU，本地跑不了，因此开始尝试寻找免费的算力资源。发现百度AI平台上面提供AI studio的算力平台，配置了Tesla V100-SXM2的GPU，算力超强。更重要的是，每天登录都可领12小时的算力卡。但是本平台只支持PaddlePaddle（飞桨）深度学习平台，于是开始搜索资料，尝试在其上面配置tensorflow-gpu。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"主要参考的教程\">主要参考的教程</h3>\r\n<p><a href=\"https://www.zhihu.com/question/336485090\" target=\"_blank\" rel=\"noopener\">知乎用户“杜俊”的回答</a></p>\r\n<p>这个知乎回答已经把主要的流程写出来了，但是我在照着做的时候，还是遇到了一些细节的问题，因此写这篇博客梳理一下。</p>\r\n<h3 id=\"预备步骤\">预备步骤</h3>\r\n<p>在多次配置后发现，百度的机器比较玄学，每次启动的时候，机器配置都会发生改变：有时候是32G的显存，有时候是16G的显存；有时候是396.37版本的显卡驱动，有时候又是418.39的版本。这样的不确定性导致每次配置之前，都得注意其显卡驱动的版本（AI studio并不提供sudo权限，无法自行升级显卡驱动）。</p>\r\n<p>后来发现了，早期的鸟儿有虫吃！早上打开环境，更高几率获得32G的显存及418.39的版本的驱动。</p>\r\n<p>于是每次配置之前，使用以下命令查看NVIDIA驱动的版本：</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ nvidia-smi</span><br></pre></td></tr></table></figure>\r\n<p>然后会显示以下输出：（以我某次的输出为例）</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">Tue Mar  3 15:20:05 2020       </span><br><span class=\"line\">+-----------------------------------------------------------------------------+</span><br><span class=\"line\">| NVIDIA-SMI 396.37                 Driver Version: 396.37                    |</span><br><span class=\"line\">|-------------------------------+----------------------+----------------------+</span><br><span class=\"line\">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class=\"line\">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class=\"line\">|===============================+======================+======================|</span><br><span class=\"line\">|   0  Tesla V100-SXM2...  On   | 00000000:00:0B.0 Off |                    0 |</span><br><span class=\"line\">| N/A   28C    P0    40W / 300W |     10MiB / 32510MiB |      0%      Default |</span><br><span class=\"line\">+-------------------------------+----------------------+----------------------+</span><br><span class=\"line\">                                                                               </span><br><span class=\"line\">+-----------------------------------------------------------------------------+</span><br><span class=\"line\">| Processes:                                                       GPU Memory |</span><br><span class=\"line\">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class=\"line\">|=============================================================================|</span><br><span class=\"line\">|  No running processes found                                                 |</span><br><span class=\"line\">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>\r\n<p>其中Driver Version: 396.37就是显卡驱动版本信息。</p>\r\n<p>另外，当后续跑代码的时候，也可以利用此命令来监控GPU的状态，验证GPU是否在工作。</p>\r\n<p>这里提供Nvidia驱动版本与CUDA版本的对应关系：</p>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>CUDA Toolkit</th>\r\n<th>Linux x86_64 Driver Version</th>\r\n<th>Windows x86_64 Driver Version</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td>CUDA 10.2.89</td>\r\n<td>&gt;= 440.33</td>\r\n<td>&gt;= 441.22</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>CUDA 10.1 (10.1.105 general release, and updates)</td>\r\n<td>&gt;= 418.39</td>\r\n<td>&gt;= 418.96</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>CUDA 10.0.130</td>\r\n<td>&gt;= 410.48</td>\r\n<td>&gt;= 411.31</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>CUDA 9.2 (9.2.148 Update 1)</td>\r\n<td>&gt;= 396.37</td>\r\n<td>&gt;= 398.26</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>CUDA 9.2 (9.2.88)</td>\r\n<td>&gt;= 396.26</td>\r\n<td>&gt;= 397.44</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>CUDA 9.1 (9.1.85)</td>\r\n<td>&gt;= 390.46</td>\r\n<td>&gt;= 391.29</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>CUDA 9.0 (9.0.76)</td>\r\n<td>&gt;= 384.81</td>\r\n<td>&gt;= 385.54</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>CUDA 8.0 (8.0.61 GA2)</td>\r\n<td>&gt;= 375.26</td>\r\n<td>&gt;= 376.51</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>CUDA 8.0 (8.0.44)</td>\r\n<td>&gt;= 367.48</td>\r\n<td>&gt;= 369.30</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>CUDA 7.5 (7.5.16)</td>\r\n<td>&gt;= 352.31</td>\r\n<td>&gt;= 353.66</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>CUDA 7.0 (7.0.28)</td>\r\n<td>&gt;= 346.46</td>\r\n<td>&gt;= 347.62</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<p>同时，tensorflow-gpu的版本与CUDA和CUDA版本之间也有对应：</p>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th style=\"text-align: center;\"><strong><a href=\"https://pypi.tuna.tsinghua.edu.cn/simple/tensorflow-gpu/\" target=\"_blank\" rel=\"noopener\">Tensorflow-GPU</a></strong></th>\r\n<th><strong><a href=\"https://developer.nvidia.com/cuda-toolkit-archive\" target=\"_blank\" rel=\"noopener\">CUDA</a></strong></th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: center;\">2.0</td>\r\n<td>10.1</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: center;\">1.15</td>\r\n<td>10.0</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: center;\">1.14</td>\r\n<td>10.0</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: center;\">1.13</td>\r\n<td>10.0</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: center;\">1.12</td>\r\n<td>9.0</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: center;\">1.5</td>\r\n<td>9.0</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td style=\"text-align: center;\">1.4</td>\r\n<td>8.0</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td style=\"text-align: center;\">1.0</td>\r\n<td>8.0</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<p>这里值得注意的是，TensorFlow-GPU对CUDA的版本及其严格，必须完全与上表对应，否则都无法正常运算。比如TensorFlow-gpu 1.12，必须对应CUDA9.0，CUDA9.2也不行，import的时候会报错。</p>\r\n<p>另附：</p>\r\n<p>TensorFlow各版本的下载地址（清华源）：</p>\r\n<p><a href=\"https://pypi.tuna.tsinghua.edu.cn/simple/tensorflow-gpu/\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://pypi.tuna.tsinghua.edu.cn/simple/tensorflow-gpu/</a></p>\r\n<p>CUDA各版本的下载地址：</p>\r\n<p><a href=\"https://developer.nvidia.com/cuda-toolkit-archive\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://developer.nvidia.com/cuda-toolkit-archive</a></p>\r\n<p>CUDNN各版本的下载地址：</p>\r\n<p><a href=\"https://developer.nvidia.com/rdp/cudnn-archive\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://developer.nvidia.com/rdp/cudnn-archive</a></p>\r\n<h3 id=\"主要步骤\">主要步骤</h3>\r\n<p>需要安装正确版本的CUDA、cuDNN。这里以安装CUDA10.0为例。（注意：必须符合驱动版本要求）</p>\r\n<h4 id=\"下载并安装cuda\">下载并安装CUDA</h4>\r\n<p>下载CUDA10.0的安装包：</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ wget https://developer.nvidia.com/compute/cuda/10.0/Prod/local_installers/cuda_10.0.130_410.48_linux</span><br></pre></td></tr></table></figure>\r\n<p>获得一个cuda_10.0.130_410.48_linux可执行文件。</p>\r\n<p>执行以下命令安装cuda 10.0，实际就是在当前目录下，生成了一个cuda_10.0的库文件夹：</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ sh cuda_10.0.130_410.48_linux --silent --toolkit --toolkitpath=<span class=\"variable\">$HOME</span>/cuda_10.0</span><br></pre></td></tr></table></figure>\r\n<h4 id=\"下载并导入cudnn库文件\">下载并导入cuDNN库文件</h4>\r\n<p>下载cuDNN v7.6.4, for CUDA 10.0:</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ wget https://developer.download.nvidia.cn/compute/machine-learning/cudnn/secure/7.6.4.38/Production/10.0_20190923/cudnn-10.0-linux-x64-v7.6.4.38.tgz?RmkwolGzfXCe3BzgvLvAGvIyj5pIjHANLKL3MvnNYd0zxhgOfohxlIU9JjwUshKylDJdgSCbYTWtWYlDuBKE_omlbjg1GVZpRw_dt1VR095j1IcZcH_mkzcfViSViZgsvTD0PMOrD3sYj96AFFnV-dM_gwpoRzSnZAJMA_K010rhfdEvINFaYB9azWuJ42oUNzmsRgbtam8YUOkVKAbK5Agi3YVZY2ajGw</span><br><span class=\"line\">$ mv cudnn-10.0-linux-x64-v7.6.4.38.tgz?RmkwolGzfXCe3BzgvLvAGvIyj5pIjHANLKL3MvnNYd0zxhgOfohxlIU9JjwUshKylDJdgSCbYTWtWYlDuBKE_omlbjg1GVZpRw_dt1VR095j1IcZcH_mkzcfViSViZgsvTD0PMOrD3sYj96AFFnV-dM_gwpoRzSnZAJMA_K010rhfdEvINFaYB9azWuJ42oUNzmsRgbtam8YUOkVKAbK5Agi3YVZY2ajGw cudnn-10.0.tgz</span><br></pre></td></tr></table></figure>\r\n<p>解压cudnn-10.0.tgz:</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ tar zxvf cudnn-10.9.tgz</span><br></pre></td></tr></table></figure>\r\n<p>之后会生成一个名为cuda文件夹，执行以下命令，将cuDNN的库放进刚刚安装生成的cuda_10.0文件夹的对应目录：</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ cp cuda/include/cudnn.h cuda_10.0/include/</span><br><span class=\"line\">$ cp cuda/lib64/libcudnn* cuda_10.0/lib64/</span><br></pre></td></tr></table></figure>\r\n<h4 id=\"配置环境变量\">配置环境变量</h4>\r\n<p>上述两步生成的cuda_10.0文件夹，会被Baidu Studio作为用户文件一直保存，因此以后每次登陆环境无需重新配置。</p>\r\n<p>但从这一步开始（包括后续步骤），每次启动服务器的时候都需重新配置。因此，最后可以写成一个.sh脚本文件，脚本文件的内容我会总结在最后。</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ chmod a+r cuda_10.0/include/cudnn.h</span><br><span class=\"line\">$ chmod a+r cuda_10.0/lib64/libcudnn*</span><br><span class=\"line\">$ vim 环境变量    <span class=\"comment\"># 保存并退出</span></span><br><span class=\"line\">$ <span class=\"built_in\">echo</span> -e <span class=\"string\">'export PATH=$HOME/cuda_10.0/bin:$PATH\\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/cuda_10.0/lib64'</span>&gt;~/环境变量</span><br><span class=\"line\">$ <span class=\"built_in\">source</span> ~/环境变量</span><br></pre></td></tr></table></figure>\r\n<h4 id=\"安装tensorflow-gpu\">安装tensorflow-gpu</h4>\r\n<p>根据CUDA版本（对应关系见上文的表）以及自身需求，选择合适版本的tensorflow-gpu下载 <a href=\"https://pypi.tuna.tsinghua.edu.cn/simple/tensorflow-gpu/\" target=\"_blank\" rel=\"noopener\">各版本下载地址</a></p>\r\n<p>另外还要注意tensorflow-gpu与python版本的对应关系，观察下载的.whl文件名即可判断其适配的python版本：</p>\r\n<p><img src=\"https://jamekuma.github.io/images/image-20200303201813126.png\" alt=\"image-20200303201813126\" style=\"zoom: 67%;\" /></p>\r\n<p>此处以tensorflow-gpu 1.15.0，python 3.7为例。</p>\r\n<p>下载： <figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ wget https://pypi.tuna.tsinghua.edu.cn/packages/bc/72/d06017379ad4760dc58781c765376ce4ba5dcf3c08d37032eeefbccf1c51/tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl<span class=\"comment\">#sha256=1344a3541e19e5b5cfde1c7b71fb02cb2f593262841a0e064df033619137f609</span></span><br></pre></td></tr></table></figure></p>\r\n<p>pip安装：</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ pip install tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl</span><br></pre></td></tr></table></figure>\r\n<p>大功告成！</p>\r\n<p>最后利用下列python代码测试GPU是否在tensorflow下正常工作：</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\">print(tf.test.is_gpu_available())</span><br></pre></td></tr></table></figure>\r\n<p>返回True则代表配置成功。</p>\r\n<h4 id=\"编写启动脚本\">编写启动脚本</h4>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ vim start.sh</span><br></pre></td></tr></table></figure>\r\n<p>键入以下内容并保存：</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#!/bin/bash</span></span><br><span class=\"line\">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class=\"line\">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge</span><br><span class=\"line\">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/</span><br><span class=\"line\">conda config --<span class=\"built_in\">set</span> show_channel_urls yes</span><br><span class=\"line\">conda create -n tf10.0 python=3.7</span><br><span class=\"line\"><span class=\"built_in\">source</span> activate tf10.0</span><br><span class=\"line\">chmod a+r ~/cuda_10.0/include/cudnn.h</span><br><span class=\"line\">chmod a+r ~/cuda_10.0/lib64/libcudnn*</span><br><span class=\"line\"><span class=\"built_in\">source</span> ~/环境变量</span><br><span class=\"line\">chmod +x set_pip_source.sh</span><br><span class=\"line\">./set_pip_source.sh</span><br><span class=\"line\">pip install ~/tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl</span><br><span class=\"line\">conda install scikit-learn</span><br></pre></td></tr></table></figure>\r\n<p>这里我用的是anoconda虚拟环境，所以多了一些conda配置。</p>\r\n<p>以后每次启动环境后，只需键入以下命令，即可配置完成：</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">source</span> start.sh</span><br></pre></td></tr></table></figure>\r\n<h3 id=\"参考资料\">参考资料</h3>\r\n<ul>\r\n<li><p><a href=\"https://www.zhihu.com/question/336485090\" target=\"_blank\" rel=\"noopener\">知乎用户杜俊的回答</a></p></li>\r\n<li><p><a href=\"https://blog.csdn.net/mouse1598189/article/details/86695400\" target=\"_blank\" rel=\"noopener\">sundaygeek的csdn博客</a></p></li>\r\n<li><p><a href=\"https://www.fatrabbids.com/2019/09/23/gpu%E7%89%88%E6%9C%ACtensorflow%E5%8F%8A%E5%AF%B9%E5%BA%94cuda%E5%92%8Ccudnn%E7%9A%84%E5%AE%89%E8%A3%85/\" target=\"_blank\" rel=\"noopener\">Fat Rabbidsd的博客</a></p></li>\r\n</ul>\r\n","categories":["教程"],"tags":["深度学习","配置环境"]},{"title":"HDU 2064：汉诺塔Ⅲ 递归","url":"/2020/02/28/2020-02-28-HDU-2064-%E6%B1%89%E8%AF%BA%E5%A1%94/","content":"<blockquote>\r\n<p>找规律水题</p>\r\n</blockquote>\r\n<h3 id=\"题目链接\">题目链接</h3>\r\n<p><a href=\"http://acm.hdu.edu.cn/showproblem.php?pid=2064\" target=\"_blank\" rel=\"noopener\" class=\"uri\">http://acm.hdu.edu.cn/showproblem.php?pid=2064</a></p>\r\n<h3 id=\"题意\">题意</h3>\r\n<p>汉诺塔问题变形，还是三根柱子，每次只能从中间的柱子移动到旁边的柱子，或者从旁边的柱子移动到中间。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"思路\">思路</h3>\r\n<p>汉诺塔肯定就往递归上想。先分析简单情况，设结果为：</p>\r\n<p>N = 1：f(1) = 2;显然</p>\r\n<p>N = 2: f(2) = 8;以下用\"大\"、\"小\"的符号来图示：</p>\r\n<p>​ 小大、空、空</p>\r\n<ol type=\"1\">\r\n<li>大、小、空</li>\r\n<li>大、空、小</li>\r\n<li>空、大、小</li>\r\n<li>空、小大、空</li>\r\n<li>小、大、空</li>\r\n<li>小、空、大</li>\r\n<li>空、小、大</li>\r\n<li>空、空、小大</li>\r\n</ol>\r\n<p>然后思考递归的过程。参考经典汉诺塔的递归，每次递归关注的点在于<strong>最底下的盘子</strong>和<strong>上方的所有盘子</strong>。可以把N=2的情况中的\"大\"看做最底下的盘子，而\"小\"看成是上方的一摞盘子(子问题)。那么可以看出，”大“移动的次数为2次，其余6次都是\"小\"在移动。</p>\r\n<p>因此我们只需抽象出每次移动\"小\"的操作，所对应的子问题的规模，便可列出递归方程式。由题意知，每次小的移动，都是<strong>进中间</strong>/<strong>出中间</strong>。而原问题是：从最左到最右。因而，当完成了一摞盘子“进中间”的操作后，只需把每个原子操作逆序执行（只不过对象换成另一根柱子），完成\"出中间\"的操作。因此，每个“进中间/出中间”的操作都是相同规模的子问题的一半，那么容易推导出递推式：</p>\r\n<p><span class=\"math display\">\\[\r\nf(n)=2 + 6 \\times \\frac 12 f(n-1)=2+3f(n-1)\r\n\\]</span></p>\r\n<p>验证一下N=1和N=2的情况，发现符合。从而代码易得。</p>\r\n<h3 id=\"代码\">代码</h3>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;bits/stdc++.h&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">long</span> <span class=\"keyword\">long</span> ll;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">ll <span class=\"title\">f</span><span class=\"params\">(<span class=\"keyword\">int</span> n)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (n == <span class=\"number\">1</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">2</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">2</span> + <span class=\"number\">3</span> * f(n - <span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> N;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (~<span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, &amp;N)) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%lld\\n\"</span>, f(N));</span><br><span class=\"line\">    &#125; </span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\r\n","categories":["算法题解"],"tags":["算法","递归","HDU"]},{"title":"CodeForce 1311 D：Three Integers","url":"/2020/03/03/2020-03-03-CF-1311D-%E4%B8%89%E4%B8%AA%E6%95%B4%E6%95%B0/","content":"<blockquote>\r\n<p>非 暴 力 不 A C</p>\r\n</blockquote>\r\n<h3 id=\"题目链接\">题目链接</h3>\r\n<p><a href=\"https://codeforces.com/contest/1311/problem/D\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://codeforces.com/contest/1311/problem/D</a></p>\r\n<h3 id=\"题意\">题意</h3>\r\n<p>输入三个整数<span class=\"math inline\">\\(1\\le a\\le b\\le c\\le10^4\\)</span>，每次操作可任意选定其中一个整数，作<span class=\"math inline\">\\(+1/ -1\\)</span>的操作，只要操作不产生一个非正数，那么就是合法的。问最少经过多少次合法的操作，产生出的新的<span class=\"math inline\">\\(A\\le B\\le C\\)</span>，且<span class=\"math inline\">\\(B\\)</span>是<span class=\"math inline\">\\(A\\)</span>的倍数，<span class=\"math inline\">\\(C\\)</span>是<span class=\"math inline\">\\(B\\)</span>的倍数。输出次数与相应的<span class=\"math inline\">\\(A、B、C\\)</span>.</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"我的解题脑回路\">我的解题脑回路</h3>\r\n<p>第一反应是，最少的次数，是不是BFS啊？后仔细一想，不对，要是以ABC为状态进行BFS，复杂度怕是得爆炸。于是开始找规律，是不是先调整a呢，还是先调整c呢，或者先调整b呢？然后脑补出一系列的规律，但是都被自己叉掉了。终于，我，停止了思考。 <del>（卡兹sama觉得很赞）</del></p>\r\n<h3 id=\"真正的题解\">真正的题解</h3>\r\n<p><del>··遂答应blb带他上分，换来了解题思路··</del></p>\r\n<p>数据范围！数据范围！数据范围！</p>\r\n<p><span class=\"math inline\">\\(10^4\\)</span>的范围，只要低于<span class=\"math inline\">\\(O(n^2)\\)</span>就基本可以。所以从1~10000直接暴力枚举A；再对于每个A，继续枚举B（这里只需枚举所有的A的倍数即可）；接着，对于每组A，B，枚举C的操作是<span class=\"math inline\">\\(O(1)\\)</span>的：因为C只需是离c最近的B的倍数即可，可用min(c%B, B - c%B)表示。</p>\r\n<p>有n个A要枚举，对于每个A，需要枚举B的数量是n/A，而枚举C为<span class=\"math inline\">\\(O(1)\\)</span>，这样枚举的复杂度是：</p>\r\n<p><span class=\"math display\">\\[\r\n\\sum^n_{A=1}{\\frac nA\\cdot O(1)}=n\\cdot \\sum^n_{i=1}{\\frac 1i}=O(n\\cdot log\\ n)\r\n\\]</span></p>\r\n<h3 id=\"ac代码\">AC代码</h3>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;bits/stdc++.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> MAX = <span class=\"number\">10000</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> t;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, &amp;t);</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (t--) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> a, b, c;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> res_a, res_b, res_c;</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d %d %d\"</span>, &amp;a, &amp;b, &amp;c);</span><br><span class=\"line\">        <span class=\"keyword\">int</span> mmin = <span class=\"number\">40000</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= MAX; i++) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">int</span> cnt_a = <span class=\"built_in\">abs</span>(a - i);</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = i; j &lt;= <span class=\"number\">2</span> * MAX; j += i) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> cnt_b = <span class=\"built_in\">abs</span>(j - b);</span><br><span class=\"line\">                <span class=\"keyword\">int</span> cnt_c;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> k;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (c &lt;= j) &#123;</span><br><span class=\"line\">                    cnt_c = j - c;</span><br><span class=\"line\">                    k = j;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                    cnt_c = <span class=\"built_in\">min</span>(c % j, j - c % j);</span><br><span class=\"line\">                    k = c % j &lt; j - c % j ? c / j * j : (c / j + <span class=\"number\">1</span>) * j;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> cnt = cnt_a + cnt_b + cnt_c;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (cnt &lt; mmin) &#123;</span><br><span class=\"line\">                    mmin = cnt;</span><br><span class=\"line\">                    res_a = i;</span><br><span class=\"line\">                    res_b = j;</span><br><span class=\"line\">                    res_c = k;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\n\"</span>, mmin);</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d %d %d\\n\"</span>, res_a, res_b, res_c);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\r\n","categories":["算法题解"],"tags":["算法","暴力枚举"]},{"title":"HYSBZ 1968：约数研究","url":"/2020/03/09/2020-03-09-HYSBZ-1968/","content":"<blockquote>\r\n<p>约数之和 =&gt; 倍数之和</p>\r\n</blockquote>\r\n<h3 id=\"题目链接\">题目链接</h3>\r\n<p><a href=\"https://vjudge.net/problem/HYSBZ-1968\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://vjudge.net/problem/HYSBZ-1968</a></p>\r\n<h3 id=\"题意\">题意</h3>\r\n<p>定义<span class=\"math inline\">\\(f(n)\\)</span>为整数<span class=\"math inline\">\\(n\\)</span>的因数的个数。现输入一个N，求<span class=\"math inline\">\\(\\sum_{i=1}^N{f(i)}\\)</span>。</p>\r\n<p>数据范围：<span class=\"math inline\">\\(0&lt;N&lt;10^6\\)</span></p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"我的失败尝试\">我的失败尝试</h3>\r\n<p>直接想把1~1000000的直接初始化出来，于是直接写成了这样：</p>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\">ll sum[MAX + <span class=\"number\">5</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span> f[MAX + <span class=\"number\">5</span>];</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">init</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(f, <span class=\"number\">0</span>, <span class=\"keyword\">sizeof</span>(f));</span><br><span class=\"line\">    sum[<span class=\"number\">0</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt; MAX; i++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> j = i; j &lt; MAX; j += i) &#123;</span><br><span class=\"line\">            f[j]++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        sum[i] = sum[i - <span class=\"number\">1</span>] + f[i];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\r\n<p>算了算复杂度好像是<span class=\"math inline\">\\(O(N\\cdot log\\ N)\\)</span>的，以为能过，结果T了。</p>\r\n<h3 id=\"题解\">题解</h3>\r\n<p>题目要求[1, N]范围内所有数的因数个数之和。分析可得：<strong>对任意一个在[1, N]范围内的数，因数都在[1, N]范围内</strong></p>\r\n<p>因此，<strong>[1, N]范围内所有数的因数个数之和</strong>可以转化为<strong>[1, N]范围内所有数的在[1, N]范围的倍数的个数之和</strong>。</p>\r\n<p>那么对于任意<span class=\"math inline\">\\(i\\in [1,N]\\)</span>，i在[1, N]范围内的倍数个数为:<span class=\"math inline\">\\(\\lfloor \\frac N i \\rfloor\\)</span>。则容易得到最终的解如下：</p>\r\n<p><span class=\"math display\">\\[\r\n\\sum_{i=1}^N{f(i)}=\\sum_{i=1}^N\\lfloor \\frac N i \\rfloor\r\n\\]</span></p>\r\n<h3 id=\"ac代码\">AC代码</h3>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;bits/stdc++.h&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">long</span> <span class=\"keyword\">long</span> ll;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> N;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, &amp;N);</span><br><span class=\"line\">    ll res = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= N; i++) &#123;</span><br><span class=\"line\">        res += N / i;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%lld\\n\"</span>, res);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\r\n","categories":["算法题解"],"tags":["算法","数论","HYSBZ"]},{"title":"POJ 2362：Square DFS剪枝","url":"/2020/03/06/2020-03-06-POJ-2362/","content":"<blockquote>\r\n<p>状态定义有时要服务于剪枝策略</p>\r\n</blockquote>\r\n<h3 id=\"题目链接\">题目链接</h3>\r\n<p><a href=\"http://poj.org/problem?id=2362\" target=\"_blank\" rel=\"noopener\" class=\"uri\">http://poj.org/problem?id=2362</a></p>\r\n<h3 id=\"题意\">题意</h3>\r\n<p>输入M个棍子(<span class=\"math inline\">\\(4\\le M\\le 20\\)</span>)，问这M个棍子是否能首尾相接形成一个正方形。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"题解\">题解</h3>\r\n<p>本质就是找一个数组的全排列，使得从头到尾能形成4段长度相等的区域。</p>\r\n<p>由于只需找到一个符合条件的排列，想到直接使用DFS。</p>\r\n<p>如果直接暴力搜索，复杂度是<span class=\"math inline\">\\(O(n!)\\)</span>的，显然会爆。必然需要剪枝。</p>\r\n<p>定义stick[M]数组为：所有木棍及其长度。</p>\r\n<h4 id=\"搜索状态的定义\">搜索状态的定义</h4>\r\n<h5 id=\"基本的状态\">基本的状态</h5>\r\n<p>假设木棍总长度为target，则正方形边长是side = target / 4。</p>\r\n<p>如果存在某个排列，那么在搜索到这个排列的过程中，应该有5个阶段：</p>\r\n<ul>\r\n<li>已组建完成0条边</li>\r\n<li>已组建完成1条边</li>\r\n<li>已组建完成2条边</li>\r\n<li>已组建完成3条边</li>\r\n<li>已组建完成4条边</li>\r\n</ul>\r\n<p>因此，在状态描述中，必须有<strong>已经完成多少条边</strong>这一状态，记为finished_side</p>\r\n<p>然后考虑上述每个阶段，都有一个<strong>当前边已有的长度</strong>这一状态，记为len</p>\r\n<p>（其实上述两种状态可以使用当前的总长度sum来表示，sum % side表示len，sum / side表示已经完成多少边，为清晰期间，还是分成两个量表示）</p>\r\n<p>visit数组标记已用过的木棍，用于表示<strong>当前状态下，还可以使用哪些木棍扩展子节点</strong>(visit值为false的点)</p>\r\n<h5 id=\"服务于剪枝的状态\">服务于剪枝的状态</h5>\r\n<p>按道理来说，以上三个状态已经足够完成搜索了，但是如果仅仅这样搜索的话，无法完全支持后续的剪枝策略。这里引入另一个状态描述——<strong>当前状态下，用于构建子节点的木棍的起始下标</strong>，记为start_index。</p>\r\n<p>为何引入这个状态，在下文剪枝策略中描述。</p>\r\n<h4 id=\"剪枝策略\">剪枝策略</h4>\r\n<p>首先是全局的判断（甚至称不上是剪枝）</p>\r\n<ul>\r\n<li>总长度不为4的倍数，肯定不行<del>··废话··</del></li>\r\n<li>最长的棍子大于边长，肯定不行</li>\r\n</ul>\r\n<p>然后几个重点的剪枝策略：</p>\r\n<ul>\r\n<li>当finished_side == 3时，就可直接判断为可行了，因为只要总长度是4的倍数，最后一条边一定能构建成功</li>\r\n<li>构建某条边时，如果长度等于fail_length的木棍构建正方形失败，那么所有长度为fail_length的木棍都不能用于构建 ====&gt; 剪去了在相同的长度木棍下重复搜索（也就是，每种长度的棍子，只需做一次拓展）\r\n<ul>\r\n<li>这里为了判断方便，可以事先将棍子排序，让相同长度的都在一起</li>\r\n</ul></li>\r\n<li>如果本状态构造的边和父状态构造的边时同一条边，则只需扩展本状态后面（这里的“后面”指stick数组中）的木棍。\r\n<ul>\r\n<li><strong>这里解释了start_index这个状态存在的意义</strong></li>\r\n<li>每次扩展子状态i之前，判断是否开启了一条新边：如果不是，则子状态的扩展起点只需在后面即可（start_index=i +1）；如果是，则扩展起点需重置为0(start_index=0)。</li>\r\n</ul></li>\r\n</ul>\r\n<p><strong>对最后一个剪枝策略的正确性作一个证明：</strong></p>\r\n<p>在构建同一条边的情况下，当前木棍(下标记做i)的前面的木棍(下标记做k)(k &lt; i)，无非两种状态：</p>\r\n<ul>\r\n<li>已经被选择了，visit[k]值为true。这样的话，本来就不该选</li>\r\n<li>未被选择，visit[k]值为false。按照不剪枝的策略，木棍k本来是要被用来扩展子节点的，为什么不呢？\r\n<ul>\r\n<li>由于每次都是按照stick数组的从前到后的顺序扩展的，k肯定在当前节点i的某个祖先节点扩展子节点时，曾经被选中过。且当时选中之后，k也曾把i拿去用于扩展子节点（即，选k又选i的情况，早就出现过了）。但显然那种情况是不可行的，否则早就成功返回了。因此，选择k肯定是不可行的。</li>\r\n</ul></li>\r\n</ul>\r\n<p>但是当不是构建同一条边的时候，就应该从0开始重新找了。直观地看，构建上一条边舍弃的某些木棍，可能可以用于构建下一条边。</p>\r\n<h3 id=\"ac代码\">AC代码</h3>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstring&gt; </span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;iostream&gt; </span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;cstdio&gt; </span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;algorithm&gt; </span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>; </span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">long</span> <span class=\"keyword\">long</span> ll; </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> stick[<span class=\"number\">25</span>];</span><br><span class=\"line\"><span class=\"keyword\">bool</span> visit[<span class=\"number\">25</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span> target = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> side = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">int</span> M;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"keyword\">int</span> start_index, <span class=\"keyword\">int</span> finished_side, <span class=\"keyword\">int</span> len)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (finished_side == <span class=\"number\">3</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">int</span> last = <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = start_index; i &lt; M; i++) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 如果 访问过/太长了/跟上次失败的一样长 就剪枝</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (visit[i] || stick[i] + len &gt; side || stick[i] == last) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        visit[i] = <span class=\"literal\">true</span>; <span class=\"comment\">// 开始扩展i节点, 标记visit数组</span></span><br><span class=\"line\">        <span class=\"comment\">// 正好开启下一条边</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (stick[i] + len == side) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (dfs(<span class=\"number\">0</span>, finished_side + <span class=\"number\">1</span>, <span class=\"number\">0</span>)) &#123;  <span class=\"comment\">// 下次的start_index = 0</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 还是同一条边</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 下次的start_index为i + 1</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (dfs(i + <span class=\"number\">1</span>, finished_side, len + stick[i])) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        last = stick[i];</span><br><span class=\"line\">        visit[i] = <span class=\"literal\">false</span>; <span class=\"comment\">// 到达这里，说明上述的扩展不可行，恢复visit数组</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">cmp</span><span class=\"params\">(<span class=\"keyword\">int</span> a, <span class=\"keyword\">int</span> b)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> a &gt; b;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> t;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, &amp;t);</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (t--) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, &amp;M);</span><br><span class=\"line\">        target = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> mmax = <span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; M; i++) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, stick + i);</span><br><span class=\"line\">            target += stick[i];</span><br><span class=\"line\">            mmax = <span class=\"built_in\">max</span>(mmax, stick[i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> (target % <span class=\"number\">4</span>) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">puts</span>(<span class=\"string\">\"no\"</span>);</span><br><span class=\"line\">            <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        side = target / <span class=\"number\">4</span>;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (mmax &gt; side) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">puts</span>(<span class=\"string\">\"no\"</span>);</span><br><span class=\"line\">            <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"built_in\">memset</span>(visit, <span class=\"literal\">false</span>, <span class=\"keyword\">sizeof</span>(visit));</span><br><span class=\"line\">        sort(stick, stick + M, cmp);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (dfs(<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>)) &#123; <span class=\"comment\">// 初始: 从0开始扩展、完成0条边、当前长度为0</span></span><br><span class=\"line\">            <span class=\"built_in\">puts</span>(<span class=\"string\">\"yes\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"built_in\">puts</span>(<span class=\"string\">\"no\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\r\n","categories":["算法题解"],"tags":["算法","搜索","DFS","POJ"]},{"title":"CodeForce 1327 D：Infinite Path","url":"/2020/03/26/2020-03-26-CF-1327D/","content":"<blockquote>\r\n<p>排列==&gt;多个环 简单的gcd、lcm关系</p>\r\n</blockquote>\r\n<h3 id=\"题目链接\">题目链接</h3>\r\n<p><a href=\"https://codeforces.com/contest/1327/problem/D\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://codeforces.com/contest/1327/problem/D</a></p>\r\n<h3 id=\"题目大意\">题目大意</h3>\r\n<p>引入几个定义：</p>\r\n<p><strong>排列的乘法：</strong>如果<span class=\"math inline\">\\(a\\)</span>、<span class=\"math inline\">\\(b\\)</span>是两个排列，那么定义排列<span class=\"math inline\">\\(c=a\\times b\\)</span>，其中<span class=\"math inline\">\\(\\forall 1\\le i\\le n\\ \\ c[i] = b[a[i]]\\)</span>。</p>\r\n<p><strong>排列<span class=\"math inline\">\\(p\\)</span>的<span class=\"math inline\">\\(k\\)</span>次幂为：</strong><span class=\"math inline\">\\(p^k=\\underbrace{p \\times p \\times \\dots \\times p}_{k \\text{ times}}\\)</span></p>\r\n<p>给定n，给定一个数字1~n的排列<span class=\"math inline\">\\(p_1,p_2,...,p_n\\)</span>，对于每个<span class=\"math inline\">\\(p[i]\\)</span>，有一个“颜色”<span class=\"math inline\">\\(c[i]\\)</span>。</p>\r\n<p><strong>“无限路径”：</strong>对于排列<span class=\"math inline\">\\(p\\)</span>，存在一个序列<span class=\"math inline\">\\(i, p[i], p[p[i]], p[p[p[i]]] \\dots\\)</span>拥有相同的颜色<span class=\"math inline\">\\(c[i] = c[p[i]] = c[p[p[i]]] = \\dots\\)</span>，则称排列<span class=\"math inline\">\\(p\\)</span><strong>具有无限路径</strong>。</p>\r\n<p>问：对于已知的排列<span class=\"math inline\">\\(p\\)</span>，求最小的<span class=\"math inline\">\\(k\\)</span>，使得<span class=\"math inline\">\\(p^k\\)</span>具有无限路径。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"题解\">题解</h3>\r\n<h4 id=\"问题抽象\">问题抽象</h4>\r\n<p>把原始的排列<span class=\"math inline\">\\(p\\)</span>，可以看做是，节点为<span class=\"math inline\">\\(V = \\{1,2,3,...,n\\}\\)</span>，<span class=\"math inline\">\\(E=\\big\\{(i, p[i])\\bigg|1\\le i\\le n\\big\\}\\)</span>有向图$G=《V,E》 $ 。由图论的知识可知，<span class=\"math inline\">\\(n\\)</span>个节点，<span class=\"math inline\">\\(n\\)</span>条边，该图的每个连通分量上有且只有一个环。而又根据排列的性质，<span class=\"math inline\">\\(p[i]\\)</span>各不相同且覆盖了所有的<span class=\"math inline\">\\(i\\)</span>，可知每个节点的入度都为1。因此，整个有向图，由多个连通分量构成，每个连通分量为一个环。</p>\r\n<p>若要判断排列<span class=\"math inline\">\\(p\\)</span>是否具有“无线路径”，即看是<span class=\"math inline\">\\(G\\)</span>上是否有某个环，其中的每个节点的颜色都相等（步长为1）。</p>\r\n<p>而要要判断排列<span class=\"math inline\">\\(p^k\\)</span>是否具有无线路径，即看<span class=\"math inline\">\\(G\\)</span>上是否存在某个环的某个步长为 <span class=\"math inline\">\\(k\\)</span> 的“路径”所构成的“环路”，此“环路”上的每个节点的颜色都相等。</p>\r\n<h4 id=\"求解\">求解</h4>\r\n<p>显然通过遍历的方式很容易找到所有环。现在的问题就是，对于每个环，要找一个最小的k。</p>\r\n<p>设某个环的长度为<span class=\"math inline\">\\(m\\)</span>，若步长为<span class=\"math inline\">\\(k\\)</span>，则每条“k-环路”的“长度”（节点个数）为<span class=\"math inline\">\\(\\frac {lcm(m,k)}k\\)</span>(<span class=\"math inline\">\\(lcm\\)</span>是最小公倍数<span class=\"math inline\">\\(least\\ common\\ multiple\\)</span>的简称)。而根据一个很简单但重要的公式：</p>\r\n<p><span class=\"math display\">\\[\r\n\\forall a,b\\in \\mathbb{R}^+,\\ \\ lcm(a,b)\\cdot gcd(a,b)=a\\cdot b\r\n\\]</span></p>\r\n<p>每条“k-环路”的“长度”为<span class=\"math inline\">\\(\\frac {lcm(m,k)}k=\\frac m {gcd(m,k)}\\)</span>。</p>\r\n<p>而对于一共有<span class=\"math inline\">\\(m\\)</span>个节点的环，这样的环路一共有<span class=\"math inline\">\\(m\\div \\frac m {gcd(m,k)}=gcd(m,k)\\)</span>个。</p>\r\n<p>分析到这里，一个朴素的想法是，对每个环，从小到大验证每个k；进而对每个k，验证<span class=\"math inline\">\\(gcd(m,k)\\)</span>个“环路”，若某个环路上所有点的颜色均相同，则这个k可被接受。统计出所有可被接受的k，并求min即可。</p>\r\n<p>先分析一下复杂度，对于每个环路，验证每个k需要遍历该环的所有“k-环路”，也就是遍历该环的所有节点，复杂度为<span class=\"math inline\">\\(O(m)\\)</span>，而<u>k的可能取值为1~m</u>（虽说k&gt;m也有可能，但k=m必定可接受，因而k&gt;m的情况必不是最小，无需考虑），那么验证每个环路，则需要<span class=\"math inline\">\\(O(m^2)\\)</span>的时间。那么对于全局来说，最坏情况的时间复杂度为<span class=\"math inline\">\\(O(n^2)\\)</span>，会爆TLE。</p>\r\n<p>注意上一段画下划线的部分，对于k，是否所有的1~m的取值，都要考虑呢？</p>\r\n<p>对于<span class=\"math inline\">\\(k_1,k_2\\)</span>，若<span class=\"math inline\">\\(gcd(k_1,m)=gcd(k_2,m)\\)</span>，则“k-环路”的“长度”是一样的，因而该环上的“k-环路”的个数也是一样的。从而每个“k-环路”上的节点也是一样的( 口胡，我不会证o(╥﹏╥)o)。故对于每个<span class=\"math inline\">\\(gcd(k,m)\\)</span>的值，我们只需要对其中最小k的验证一次即可。也就是，<strong>我们只需验证所有的m的因数k即可</strong>（对于任意k, 若m % k == 0，则gcd(k, m) = k，且对于任意一个q &lt; k，gcd(q, m) != k = gcd(k,m)。即m的因数k，是所有gcd(ki, m) == gcd(k,m)中最小的一个ki）。</p>\r\n<h3 id=\"ac代码\">AC代码</h3>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;bits/stdc++.h&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> DB(x) cout &lt;&lt; #x &lt;&lt; <span class=\"meta-string\">\" = \"</span> &lt;&lt; x &lt;&lt; <span class=\"meta-string\">\"\\n\"</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> FIN ios_base::sync_with_stdio(0);cin.tie(0);cout.tie(0)</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> SZ(s) ((int)(s.size()))</span></span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">long</span> <span class=\"keyword\">long</span> ll;</span><br><span class=\"line\"><span class=\"keyword\">typedef</span> pair&lt;<span class=\"keyword\">int</span>, <span class=\"keyword\">int</span>&gt; pii;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> p[<span class=\"number\">200005</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span> c[<span class=\"number\">200005</span>];</span><br><span class=\"line\"><span class=\"keyword\">bool</span> visit[<span class=\"number\">200005</span>];</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">bool</span> <span class=\"title\">check_k</span><span class=\"params\">(<span class=\"keyword\">int</span> k, <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt;&amp; v)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> m = SZ(v);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> l = <span class=\"number\">0</span>; l &lt; k; l++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> q = l;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> color = c[v[q]];</span><br><span class=\"line\">        q += k;</span><br><span class=\"line\">        q %= m;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> flag = <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (q != l) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (color != c[v[q]]) &#123;</span><br><span class=\"line\">                flag = <span class=\"literal\">false</span>;</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            q += k;</span><br><span class=\"line\">            q %= m;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (flag) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> T;</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, &amp;T);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (T--) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> n;</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, &amp;n);</span><br><span class=\"line\">        <span class=\"built_in\">memset</span>(visit, <span class=\"literal\">false</span>, <span class=\"keyword\">sizeof</span>(visit));</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i++) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, p + i);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i++) &#123;</span><br><span class=\"line\">            <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, c + i);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> min_k = n;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i++) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!visit[i]) &#123;</span><br><span class=\"line\">                <span class=\"keyword\">int</span> j = i;</span><br><span class=\"line\">                <span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; v;</span><br><span class=\"line\">                <span class=\"keyword\">while</span> (!visit[j]) &#123;</span><br><span class=\"line\">                    v.push_back(j);</span><br><span class=\"line\">                    visit[j] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">                    j = p[j];</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                <span class=\"keyword\">int</span> m = SZ(v);</span><br><span class=\"line\">                <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> k = <span class=\"number\">1</span>; k &lt;= m; k++) &#123;</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> (m % k == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">                        <span class=\"keyword\">bool</span> flag = check_k(k, v);</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> (flag) &#123;</span><br><span class=\"line\">                            min_k = <span class=\"built_in\">min</span>(min_k, k);</span><br><span class=\"line\">                            <span class=\"keyword\">break</span>;</span><br><span class=\"line\">                        &#125;</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d\\n\"</span>, min_k);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\r\n","categories":["算法题解"],"tags":["算法","CF","数论","排列"]},{"title":"CodeForce 1324 F：Maximum White Subtree","url":"/2020/03/14/2020-03-14-CF-1324F/","content":"<blockquote>\r\n<p>求每个节点“最白的”子树</p>\r\n</blockquote>\r\n<h3 id=\"题目链接\">题目链接</h3>\r\n<p><a href=\"https://codeforces.com/contest/1324/problem/F\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://codeforces.com/contest/1324/problem/F</a></p>\r\n<h3 id=\"题意\">题意</h3>\r\n<p>给<span class=\"math inline\">\\(1,2,3,...,n\\)</span>一共<span class=\"math inline\">\\(n\\)</span>个点，每个点<span class=\"math inline\">\\(v\\)</span>都有一个颜色<span class=\"math inline\">\\(a_v\\)</span>——白色(<span class=\"math inline\">\\(a_v=1\\)</span>)或黑色(<span class=\"math inline\">\\(a_v=0\\)</span>)。现在用<span class=\"math inline\">\\(n-1\\)</span>条边把这<span class=\"math inline\">\\(n\\)</span>个点连成一棵树。对于每个点<span class=\"math inline\">\\(v\\)</span>，求包含该点<span class=\"math inline\">\\(v\\)</span>的所有子树中，<span class=\"math inline\">\\(cnt_{white}-cnt_{black}\\)</span>最大的子树，输出该子树对应的<span class=\"math inline\">\\(cnt_{white}-cnt_{black}\\)</span>的值。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"题解\">题解</h3>\r\n<p>参考了<a href=\"https://codeforces.ml/blog/entry/74714\" target=\"_blank\" rel=\"noopener\">CF中的Tutorial</a>：</p>\r\n<p><img src=\"https://jamekuma.github.io/images/image-20200314134231.png\" alt=\"image-20200303201813126\" style=\"zoom: 100%;\" /></p>\r\n<p>把上述Tutorial中的主要思想阐述如下：</p>\r\n<p>首先，可以把黑点的权值视为-1，白点的权值设为1。因此为方便起见，把数组<span class=\"math inline\">\\(a_1,a_2,...,a_n\\)</span>中所有为0的元素都替换成-1。</p>\r\n<p>设<span class=\"math inline\">\\(dp_v\\)</span>为顶点<span class=\"math inline\">\\(v\\)</span>对应的答案。<strong>现在把树想象成，以顶点<span class=\"math inline\">\\(v\\)</span>为根的树</strong>。这样一来，其余的点都是<span class=\"math inline\">\\(v\\)</span>的子节点或是后辈节点。</p>\r\n<p><strong>在将点<span class=\"math inline\">\\(v\\)</span>视为树根的前提下</strong>，对于任意一点<span class=\"math inline\">\\(u\\)</span>，设<span class=\"math inline\">\\(sub^{(v)}_u\\)</span>为：当只考虑以<span class=\"math inline\">\\(u\\)</span>为根的子树时，点<span class=\"math inline\">\\(u\\)</span>对应的答案。显然点<span class=\"math inline\">\\(v\\)</span>为根的子树就是整个树，所以<span class=\"math inline\">\\(dp_v=sub^{(v)}_v\\)</span>。（括号上标中的<span class=\"math inline\">\\(^{(v)}\\)</span>代表是将点<span class=\"math inline\">\\(v\\)</span>视为树根的前提下）</p>\r\n<p>对于每个点<span class=\"math inline\">\\(u\\)</span>而言，在计算<span class=\"math inline\">\\(sub^{(v)}_u\\)</span>的值时，可以对它的每个子节点作考虑，是否要包含其子节点？（注意：这里的“子节点”，还是在将点<span class=\"math inline\">\\(v\\)</span>视为树根的前提之下的，并不是点<span class=\"math inline\">\\(v\\)</span>的所有邻接点都是其“子节点”。如果<span class=\"math inline\">\\(u\\ne v\\)</span>，那么<span class=\"math inline\">\\(u\\)</span>至少还有个邻接点是<span class=\"math inline\">\\(u\\)</span>的“父节点”）</p>\r\n<ul>\r\n<li>当其子节点<span class=\"math inline\">\\(w\\)</span>的<span class=\"math inline\">\\(sub^{(v)}_w\\)</span>值大于等于0时，应将以<span class=\"math inline\">\\(w\\)</span>为根的子树考虑在内，并将其<span class=\"math inline\">\\(sub^{(v)}_w\\)</span>累计进来</li>\r\n<li>当其子节点<span class=\"math inline\">\\(w\\)</span>的<span class=\"math inline\">\\(sub^{(v)}_w\\)</span>值小于0时，不应将以<span class=\"math inline\">\\(w\\)</span>为根的子树考虑在内。</li>\r\n</ul>\r\n<p>于是，可以得到下列递推式：</p>\r\n<p><span class=\"math display\">\\[\r\n对任意的点u:\\ \\ \\ \\ \\ sub^{(v)}_u=a_u+\\sum_{w\\in children_v(u)}{\\max (0,sub^{(v)}_w)}\r\n\\]</span></p>\r\n<p>这里的<span class=\"math inline\">\\(children_v(u)\\)</span>，代表的是：在<strong>以<span class=\"math inline\">\\(v\\)</span>为树根的意义下</strong>，点<span class=\"math inline\">\\(u\\)</span>的孩子节点集。</p>\r\n<p>通过一轮从<span class=\"math inline\">\\(v\\)</span>开始的DFS搜索，可以自底向上计算出每个节点的<span class=\"math inline\">\\(sub\\)</span>值。由于<span class=\"math inline\">\\(dp_v=sub^{(v)}_v\\)</span>，这样我们就得到了点<span class=\"math inline\">\\(v\\)</span>的答案。此时经过了<span class=\"math inline\">\\(O(n)\\)</span>的时间。</p>\r\n<p>如果对<span class=\"math inline\">\\(n\\)</span>个点都进行如此的搜索，显然复杂度会达到<span class=\"math inline\">\\(O(n^2)\\)</span>级别，肯定会爆T。这时，有一种巧妙的方法。</p>\r\n<p>我们把目光移到点<span class=\"math inline\">\\(v\\)</span>的某个邻接点<span class=\"math inline\">\\(to\\)</span>这里，先如同求<span class=\"math inline\">\\(dp_v\\)</span>的思路一样，把树想象成，以顶点<span class=\"math inline\">\\(to\\)</span>为根的树：</p>\r\n<p><span class=\"math display\">\\[\r\ndp_{to}=sub^{(to)}_{to}=a_{to}+\\sum_{w\\in children_{to}(to)}{\\max(0,sub^{(to)}_w)}\r\n\\]</span></p>\r\n<p>此时，<span class=\"math inline\">\\(to\\)</span>的孩子节点<span class=\"math inline\">\\(children_{to}(to)\\)</span>中，除了原本就有的孩子之外，还多了上次的<span class=\"math inline\">\\(v\\)</span>节点，那么上式可继续写为：</p>\r\n<p><span class=\"math display\">\\[\r\n\\begin{aligned}\r\ndp_{to}=sub^{(to)}_{to}&amp;=a_{to}+\\sum_{w\\in children_{to}(to)}{\\max(0,sub^{(to)}_w)} \\\\\r\n&amp;=max(0,sub^{(to)}_v)+a_{to}+\\sum_{w\\in children_{to}(to) \\land w\\ne v}{\\max(0,sub^{(to)}_w)}\r\n\\end{aligned}\r\n\\]</span></p>\r\n<p>上式左边的max函数右侧的<span class=\"math inline\">\\(sub_v^{(to)}\\)</span>意为在以<span class=\"math inline\">\\(to\\)</span>为根节点前提下，点<span class=\"math inline\">\\(v\\)</span>子树对应的答案。这时，相对于上一轮，<span class=\"math inline\">\\(v\\)</span>的子树就少了个<span class=\"math inline\">\\(to\\)</span>（因为此时<span class=\"math inline\">\\(to\\)</span>变成了<span class=\"math inline\">\\(v\\)</span>的父节点），于是<span class=\"math inline\">\\(sub_v^{(to)}\\)</span>的值，就是上一轮计算的<span class=\"math inline\">\\(dp_v\\)</span>减去<span class=\"math inline\">\\(max(0,sub_{to}^{(v)})\\)</span>。</p>\r\n<p>最右边那两项<span class=\"math inline\">\\(a_{to}+\\sum_{w\\in children_{to}(to) \\land w\\ne v}{\\max(0,sub^{(to)}_w)}\\)</span>，就是上一轮算<span class=\"math inline\">\\(dp_v\\)</span>时计算的<span class=\"math inline\">\\(sub^{(v)}_{to}\\)</span>，而这个值是可以事先保存起来的的。那么上式可以继续推导：</p>\r\n<p><span class=\"math display\">\\[\r\n\\begin{aligned}\r\ndp_{to}=sub^{(to)}_{to}&amp;=a_{to}+\\sum_{w\\in children_{to}(to)}{\\max(0,sub^{(to)}_w)} \\\\\r\n&amp;=max(0,sub^{(to)}_v)+a_{to}+\\sum_{w\\in children_{to}(to) \\land w\\ne v}{\\max(0,sub^{(to)}_w)} \\\\\r\n&amp;=max(0,dp_v-max(0,sub^{(v)}_{to}))+sub^{(v)}_{to}\r\n\\end{aligned}\r\n\\]</span></p>\r\n<p>即：</p>\r\n<p><span class=\"math display\">\\[\r\ndp_{to}=max(0,dp_v-max(0,sub^{(v)}_{to}))+sub^{(v)}_{to}\r\n\\]</span></p>\r\n<p>这样，只需利用上一轮计算出的<span class=\"math inline\">\\(dp_v\\)</span>以及<span class=\"math inline\">\\(sub^{(v)}_{to}\\)</span>，即可在<span class=\"math inline\">\\(O(1)\\)</span>的时间里计算出<span class=\"math inline\">\\(v\\)</span>的任意邻接点<span class=\"math inline\">\\(to\\)</span>对应的答案<span class=\"math inline\">\\(dp_{to}\\)</span>。以此类推，按照同样的DFS的顺序，可以计算出每个点的<span class=\"math inline\">\\(dp\\)</span>答案值。</p>\r\n<p>值得注意的是，对于每个点<span class=\"math inline\">\\(w\\)</span>而言，每当其父节点<span class=\"math inline\">\\(v&#39;\\)</span>的<span class=\"math inline\">\\(dp_{v&#39;}\\)</span>值被计算出来，该点的答案<span class=\"math inline\">\\(dp_w\\)</span>就能按照下式被计算出来：</p>\r\n<p><span class=\"math display\">\\[\r\ndp_{w}=max(0,dp_{v&#39;}-max(0,sub^{({v&#39;})}_{w}))+sub^{({v&#39;})}_{w}\r\n\\]</span></p>\r\n<p>而显然，无论以<span class=\"math inline\">\\(v&#39;\\)</span>点为根，还是作为其最终祖先<span class=\"math inline\">\\(v\\)</span>为根，<span class=\"math inline\">\\(sub^{(v&#39;)}_w\\)</span>和<span class=\"math inline\">\\(sub^{(v)}_w\\)</span>的意义都是相同的，于是对于任意的节点<span class=\"math inline\">\\(w\\)</span>，都能以最初的<span class=\"math inline\">\\(sub^{(v)}_w\\)</span>参与计算。</p>\r\n<p>将第二次DFS过程中的递推式描述如下：</p>\r\n<p><span class=\"math display\">\\[\r\n对任意  w\\ne v\\ \\ \\ \\ \\ dp_w=max(0,dp_{DFSfather(w)}-max(0,sub^{(v)}_{w}))+sub^{(v)}_{w}\r\n\\]</span> <span class=\"math inline\">\\(DFSfather(w)\\)</span>代表在DFS过程中，<span class=\"math inline\">\\(w\\)</span>的父节点。这样，再经过<span class=\"math inline\">\\(O(n)\\)</span>的时间，就可以计算出全部答案，总的时间复杂度为<span class=\"math inline\">\\(O(n)+O(n)=O(n)\\)</span></p>\r\n<h3 id=\"ac代码\">AC代码</h3>\r\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;bits/stdc++.h&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"keyword\">long</span> <span class=\"keyword\">long</span> ll;</span><br><span class=\"line\"><span class=\"keyword\">typedef</span> pair&lt;<span class=\"keyword\">int</span>, <span class=\"keyword\">int</span>&gt; pii;</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> MAX 200000</span></span><br><span class=\"line\"><span class=\"built_in\">vector</span>&lt;<span class=\"keyword\">int</span>&gt; G[MAX + <span class=\"number\">5</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span> color[MAX + <span class=\"number\">5</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span> n;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> val_1[MAX + <span class=\"number\">5</span>];</span><br><span class=\"line\"><span class=\"keyword\">int</span> val_2[MAX + <span class=\"number\">5</span>];</span><br><span class=\"line\"><span class=\"keyword\">bool</span> visit[MAX + <span class=\"number\">5</span>];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">dfs1</span><span class=\"params\">(<span class=\"keyword\">int</span> v)</span> </span>&#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    visit[v] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> res = color[v];</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; (<span class=\"keyword\">int</span>)(G[v].<span class=\"built_in\">size</span>()); i++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!visit[G[v][i]])</span><br><span class=\"line\">            res += <span class=\"built_in\">max</span>(<span class=\"number\">0</span>, dfs1(G[v][i]));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    val_1[v] = res;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">dfs2</span><span class=\"params\">(<span class=\"keyword\">int</span> v, <span class=\"keyword\">int</span> father)</span> </span>&#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    visit[v] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">    <span class=\"comment\">// val_2[v] = val_1[v] &gt;= 0 ? val_1[v] + max(0, val_2[father] - val_1[v]) : val_1[v] + max(0, val_2[father]);</span></span><br><span class=\"line\">    val_2[v] = <span class=\"built_in\">max</span>(<span class=\"number\">0</span>, val_2[father] - <span class=\"built_in\">max</span>(<span class=\"number\">0</span>, val_1[v])) + val_1[v]; </span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; (<span class=\"keyword\">int</span>)(G[v].<span class=\"built_in\">size</span>()); i++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!visit[G[v][i]])</span><br><span class=\"line\">            dfs2(G[v][i], v);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(visit, <span class=\"literal\">false</span>, <span class=\"keyword\">sizeof</span>(visit));</span><br><span class=\"line\">    <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, &amp;n);</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> c;</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d\"</span>, &amp;c);</span><br><span class=\"line\">        color[i] = c == <span class=\"number\">0</span> ? <span class=\"number\">-1</span> : c;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; n - <span class=\"number\">1</span>; i++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> v, u;</span><br><span class=\"line\">        <span class=\"built_in\">scanf</span>(<span class=\"string\">\"%d %d\"</span>, &amp;v, &amp;u);</span><br><span class=\"line\">        G[v].push_back(u);</span><br><span class=\"line\">        G[u].push_back(v);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    val_2[<span class=\"number\">1</span>] = dfs1(<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(visit, <span class=\"literal\">false</span>, <span class=\"keyword\">sizeof</span>(visit));</span><br><span class=\"line\"></span><br><span class=\"line\">    visit[<span class=\"number\">1</span>] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; (<span class=\"keyword\">int</span>)(G[<span class=\"number\">1</span>].<span class=\"built_in\">size</span>()); i++) &#123;</span><br><span class=\"line\">        dfs2(G[<span class=\"number\">1</span>][i], <span class=\"number\">1</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i++) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"%d \"</span>, val_2[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"\\n\"</span>);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\r\n","categories":["算法题解"],"tags":["算法","CF","搜索","DFS","树"]},{"title":"(转)根据数据范围反推复杂度及算法内容","url":"/2020/04/12/2020-04-12-%E6%A0%B9%E6%8D%AE%E6%95%B0%E6%8D%AE%E8%8C%83%E5%9B%B4%E5%8F%8D%E6%8E%A8%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%8F%8A%E7%AE%97%E6%B3%95%E5%86%85%E5%AE%B9/","content":"<p>一般ACM或者笔试题的时间限制是1秒或2秒。</p>\r\n<p>在这种情况下，C++代码中的操作次数控制在 <span class=\"math inline\">\\(10^7\\)</span>为最佳。</p>\r\n<p><strong>下面给出在不同数据范围下，代码的时间复杂度和算法该如何选择：</strong></p>\r\n<p><span class=\"math inline\">\\(n≤30\\)</span>, 指数级别, dfs+剪枝，状态压缩dp</p>\r\n<p><span class=\"math inline\">\\(n≤100\\)</span> =&gt; <span class=\"math inline\">\\(O(n^3)\\)</span>，floyd，dp</p>\r\n<p><span class=\"math inline\">\\(n≤10^3\\)</span> =&gt; <span class=\"math inline\">\\(O(n^2)\\)</span>，<span class=\"math inline\">\\(O(n^2log\\ n)\\)</span>，dp，二分</p>\r\n<p><span class=\"math inline\">\\(n≤10^4\\)</span> =&gt; $ O(n∗n)$，块状链表</p>\r\n<p><span class=\"math inline\">\\(n≤10^5\\)</span> =&gt; <span class=\"math inline\">\\(O(n*log\\ n)\\)</span> =&gt; 各种sort，线段树、树状数组、set/map、heap、dijkstra+heap、spfa、求凸包、求半平面交、二分</p>\r\n<p><span class=\"math inline\">\\(n≤10^6\\)</span> =&gt; <span class=\"math inline\">\\(O(n)\\)</span> =&gt; hash、双指针扫描、kmp、AC自动机。以及常数较小的 <span class=\"math inline\">\\(O(n*log\\ n)\\)</span> 算法sort、树状数组、heap、dijkstra、spfa</p>\r\n<p><span class=\"math inline\">\\(n≤10^7\\)</span> =&gt; <span class=\"math inline\">\\(O(n)\\)</span>，双指针扫描、kmp、AC自动机、线性筛素数</p>\r\n<p><span class=\"math inline\">\\(n≤10^9\\)</span> =&gt; <span class=\"math inline\">\\(O(\\sqrt n)\\)</span>，判断质数</p>\r\n<p><span class=\"math inline\">\\(n≤10^{18}\\)</span> =&gt; <span class=\"math inline\">\\(O(log\\ n)\\)</span>，最大公约数</p>\r\n<a id=\"more\"></a>\r\n<p>作者：yxc</p>\r\n<p>链接：https://www.acwing.com/blog/content/32/</p>\r\n<p>来源：AcWing</p>\r\n","categories":["知识总结"],"tags":["算法"]},{"title":"读论文：应用于单图像超分辨率的深度自适应网络","url":"/2020/03/17/2020-03-17-AdaDSR/","content":"<h2 id=\"主要思想\">主要思想</h2>\r\n<p>目前的SISR（单图像超分辨率）领域已经有了很多模型。但是现有的这些模型大多是确定的，一旦模型训练结束，无论输入什么图像，对于整副图像的每个部分，计算卷积的深度都是确定的。</p>\r\n<p>但是作者考虑了以下两点：</p>\r\n<a id=\"more\"></a>\r\n<ol type=\"1\">\r\n<li><p>在一幅图像中，不同区域的纹理复杂度不一样，为达到所需效果而需要的模型深度也不一样。全都采用同样的深度，会浪费计算资源。比如下图，纹理光滑的patch，即使使用深度教小的网络，也能达到很好的效果；</p>\r\n<p><img src=\"https://jamekuma.github.io/images/image-20200317153901125.png\" alt=\"image-20200317153901125\" style=\"zoom: 50%;\" /></p>\r\n<p>​ 图 1</p></li>\r\n<li><p>在很多实际应用条件下，会存在很多的性能约束（比如硬件平台的性能，机器的计算负载等）。应该把这些约束考虑进去。</p></li>\r\n</ol>\r\n<p>这两点综合起来，可以在给定性能限制的前提下，超分辨率的整体效果更好（峰值信噪比更高）。</p>\r\n<p>基于以上思想，作者将一些经典SISR模型进行改进（比如EDSR、RCAN）增加了适配器，形成了本文的工作成果——AdaDSR。</p>\r\n<h2 id=\"主要方法\">主要方法</h2>\r\n<h3 id=\"空域上可变的网络深度\">空域上可变的网络深度</h3>\r\n<p>由图1所述思想，想让图像的不同位置上，跑不同的模型深度(这里表现为残差块的深度)。也就是建立一个空间坐标到网络深度的映射<span class=\"math inline\">\\(\\mathbf d\\in \\mathbb{R}^{G\\times H\\times W}\\)</span>。由这个深度映射，可以为每一层的残差块，建立一个如下的函数，<span class=\"math inline\">\\(l\\)</span>代表残差块层数。一共有D层，那么就有D个下列函数：</p>\r\n<p><img src=\"https://jamekuma.github.io/images/image-20200317160151113.png\" alt=\"image-20200317160151113\" style=\"zoom:67%;\" /></p>\r\n<p>直观来看，这个函数就是每一层残差的模块对每个像素进行筛别，判断其是否需要在本层进行计算。</p>\r\n<p>根据残差网络的性质，容易得到以下公式：</p>\r\n<p><img src=\"https://jamekuma.github.io/images/image-20200317160558094.png\" alt=\"image-20200317160558094\" style=\"zoom:67%;\" /></p>\r\n<p>本质就是对每层残差块做了一个mask操作。</p>\r\n<h3 id=\"基于im2col的稀疏卷积\">基于im2col的稀疏卷积</h3>\r\n<p>如果只是单纯的在原有的卷积运算上加mask，并不能减小运算次数，于是这里引入的一个广泛应用的im2col操作，把卷积的转换为矩阵乘积的过程。</p>\r\n<p><img src=\"https://jamekuma.github.io/images/image-20200317160956786.png\" alt=\"image-20200317160956786\" style=\"zoom:50%;\" /></p>\r\n<p>如上图所示，可以在计算矩阵乘积之前就进行mask操作，大大减小了运算量。</p>\r\n<h3 id=\"考虑性能约束的适配器网络\">考虑性能约束的适配器网络</h3>\r\n<p>为了根据图片的特征构建上述的网络深度的映射<span class=\"math inline\">\\(\\mathbf d\\)</span>，作者构建了一个模型，输入是原图像特征<span class=\"math inline\">\\(\\mathbf z_0\\)</span>和性能约束<span class=\"math inline\">\\(d\\)</span>，输出就是网络深度的映射<span class=\"math inline\">\\(\\mathbf d\\)</span>。作者对这个网络的训练目标有两个，定性来说，一是使超分辨率后的图像与原始高分辨率图像更接近；二是使输出的网络深度的映射<span class=\"math inline\">\\(\\mathbf d\\)</span>更接近于性能约束<span class=\"math inline\">\\(d\\)</span>。从而构造了如下的损失函数进行训练：</p>\r\n<p><img src=\"https://jamekuma.github.io/images/image-20200317162123984.png\" alt=\"image-20200317162123984\" /><img src=\"https://jamekuma.github.io/images/image-20200317162133876.png\" alt=\"image-20200317162133876\" /><img src=\"https://jamekuma.github.io/images/image-20200317162148920.png\" alt=\"image-20200317162148920\" /></p>\r\n<h2 id=\"最终的模型结构\">最终的模型结构</h2>\r\n<p>依据训练好的适配器网络，输入原始图像及性能约束，构造出网络深度的映射<span class=\"math inline\">\\(\\mathbf d\\)</span>，添加到现有SISR模型的各层残差块中去，使得一幅图像的不同位置依据其纹理复杂度的不同，而运行不同的模型深度。在有限的计算资源下达到更好的整体效果。</p>\r\n<p><img src=\"https://jamekuma.github.io/images/image-20200317162509296.png\" alt=\"image-20200317162509296\" style=\"zoom: 30%;\" /></p>\r\n","categories":["科研"],"tags":["图像超分辨"]},{"title":"写在保研基本结束","url":"/2020/07/21/2020-07-21-%E5%86%99%E5%9C%A8%E4%BF%9D%E7%A0%94%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9D%9F/","content":"<p>从大二开始有保研外校的想法，再到大三下学期开始正式准备，现在是7月下旬，终于上岸了。结果并没有特别出色，但是还是挺符合我的预期的，甚至有些环节还算是比较幸运的。</p>\r\n<a id=\"more\"></a>\r\n<h2 id=\"个人情况\">个人情况</h2>\r\n<p>东北某工大，计科学分绩排名4/260，国奖，数竞省一，物联网省二，几乎无科研经历。</p>\r\n<h3 id=\"学分绩\">学分绩</h3>\r\n<p>说实话，学分绩主要还是靠着大一学高数线代的接近满分的高分维持的，毕竟那个时候，趁着强烈转专业的劲头，是我学习状态最好的一年。之后的大一大二，也没有那么专注了，游戏打得也多了，再加上搞了几个毫无成绩但特别占时间的水竞赛，所以学分绩并没有那么出色。但是靠着每个学期期末前肝一肝，最后还是拿出了有保外资本的排名。</p>\r\n<h3 id=\"竞赛\">竞赛</h3>\r\n<p>竞赛可能是我最失败的一个部分了，想要拿奖的竞赛全部打铁<del>（数模国赛美赛物联网竞赛软件杯铁牌拥有者）</del>。只有几个抱着玩一玩的心态的竞赛拿了奖。。。（在此安利大二开学参加数学竞赛，一般是大一下就报名，靠着工数老本，仅需一场考试，省奖点击就送）</p>\r\n<p>教训就是，应该少参加水水的竞赛，不如多搞科研。</p>\r\n<h2 id=\"保研前期准备\">保研前期准备</h2>\r\n<h3 id=\"机试\">机试</h3>\r\n<p>由于我寝室除我人均ACM金/银，因此早就认识到自己机试菜鸡，虽说大二暑假去机房划了下水，结果划水完图论就溜去陪女票过七夕了，后面就再也没有去了。</p>\r\n<p>然后这个寒假开始，先刷完了基础中的基础《王道机试指南》，大致成功的从java选手转变为了C+STL选手。紧接着开学之后，趁着专业课的实验还没开始，就开始打CodeForce，但事实证明，我会做的题都太水了，基本都是简单思维题，最多加一点简单贪心、dp、搜索，其余的就做不出了，rating也一直是青名。</p>\r\n<p>现在想来，不应该沉迷与CF上分的，应该去专题训练一点题目，特别是我不擅长的dp，不然后面的清华贵系机试也不会只会签到题。</p>\r\n<h3 id=\"科研\">科研</h3>\r\n<p>大三下学期之前，科研精力基本为零，虽说早早的和左老师有联系，但是也就听了听组会，其余啥也没干，终究还是自己太懒了，要是少打点游戏，少逛点B站，应该还能更早的接触科研（</p>\r\n<p>多亏了大三下学期CV方向的这门核心课《模式识别与深度学习》，让我至少能在简历上扯一点关于科研的东西。这门课的深度学习部分，左老师讲的真的好，虽然我平常都没有认真听课，但是左老师很贴心的录了屏发在课程群里，简直是我这种不听课党的福音。于是每次实验前，都打开视频，开1.5倍速看。左老师在课上不仅讲基础知识，还会联系近年来的各种论文给我们开拓视野。这门课的实验也是循序渐进，让我有了用Pytorch写DL的基础代码能力，然后结合左老师上课时安利的一些论文，我自己去研读、从零开始复现了一些， 于是就在简历上就扯了一点，虽然水得不能再水，但也聊胜于无。同时因为如此，在面试的时候，也有了一点点点点的科研视野，不至于被老师问的哑口无言。</p>\r\n<h3 id=\"信息收集\">信息收集</h3>\r\n<p>首推计算机保研交流群，群号605176069，必加，<del>里面的人又强，说话又好听，到了这里就卷到家了，我超喜欢在里面的</del>，很多信息都能来源于里面的学长学姐。并且群主还维护了一个github仓库，用于收集夏令营报名信息，真的大大节省了到处找报名信息的时间。</p>\r\n<p>另外就是保研论坛eeban，里面有些信息有点陈旧，所以可以稍微参考一下。但是有的导师课题组的招生简章会在里面发，可以在相关学校的版块去关注一下。</p>\r\n<p><未完待续></p>\r\n","categories":["随笔"],"tags":["保研"]},{"title":"几个重要数论结论的总结","url":"/2020/04/12/2020-04-12-%E5%87%A0%E4%B8%AA%E6%95%B0%E8%AE%BA%E7%BB%93%E8%AE%BA%E7%9A%84%E6%80%BB%E7%BB%93/","content":"<h3 id=\"同余关系\">同余关系</h3>\r\n<h4 id=\"定义\">定义</h4>\r\n<p>数学中同余关系是一种等价关系。当两个整数a, b除以同一个正整数n，若得到相同的余数，则这两个整数同余。记做<span class=\"math inline\">\\(a\\equiv b\\ \\ \\pmod n\\)</span>.</p>\r\n<h4 id=\"性质\">性质</h4>\r\n<p><strong>整除性：</strong>a，b相减能被n整除</p>\r\n<p><strong>传递性：</strong>等价关系的共有特性</p>\r\n<p><span class=\"math inline\">\\(\\left.\\begin{array}{l} a \\equiv b(\\bmod m) \\\\ b \\equiv c(\\bmod m) \\end{array}\\right\\} \\Rightarrow a \\equiv c \\quad(\\bmod m)\\)</span></p>\r\n<a id=\"more\"></a>\r\n<p><strong>保持基本运算：</strong>(<strong>加减乘</strong>)</p>\r\n<p><span class=\"math inline\">\\(\\left.{\\begin{matrix}a\\equiv b{\\pmod {m} }\\\\ c\\equiv d{\\pmod {m} }\\end{matrix} }\\right\\}\\Rightarrow \\left\\{ {\\begin{matrix}a\\pm c\\equiv b\\pm d{\\pmod {m} }\\\\ ac\\equiv bd{\\pmod {m} }\\end{matrix} }\\right.\\)</span></p>\r\n<p>可进一步写成：</p>\r\n<p><span class=\"math inline\">\\(a\\equiv b{\\pmod {m} }\\Rightarrow {\\begin{cases}an\\equiv bn{\\pmod {m} },\\forall n\\in \\mathbb {Z} \\\\ a^{n}\\equiv b^{n}{\\pmod {m} },\\forall n\\in \\mathbb {N} ^{0}\\end{cases} }\\)</span></p>\r\n<p><strong>放大缩小底数：</strong>（对底数加减模数的倍数均可）</p>\r\n<p>k为整数，n为正整数，<span class=\"math inline\">\\((km\\pm a)^{n}\\equiv (\\pm a)^{n}{\\pmod m}\\)</span></p>\r\n<p><strong>放大缩小模数：</strong>（对模数和等式两边的数同乘k）</p>\r\n<p><span class=\"math inline\">\\(k\\)</span>为正整数，<span class=\"math inline\">\\(a\\equiv b{\\pmod m}\\)</span>，当且仅当<span class=\"math inline\">\\(ka\\equiv kb\\pmod {km}\\)</span></p>\r\n<p>还有几个性质，懒得码了，详见wiki：<a href=\"https://zh.wikipedia.org/wiki/同餘\" target=\"_blank\" rel=\"noopener\">同余</a></p>\r\n<h3 id=\"欧拉函数\">欧拉函数</h3>\r\n<p>对正整数<span class=\"math inline\">\\(n\\)</span>，欧拉函数<span class=\"math inline\">\\(\\varphi(n)\\)</span>为小于等于<span class=\"math inline\">\\(n\\)</span>的正整数中，与<span class=\"math inline\">\\(n\\)</span>互质的数的个数。</p>\r\n<h3 id=\"欧拉定理\">欧拉定理</h3>\r\n<p>若<span class=\"math inline\">\\(n,a\\)</span>为正整数，且<span class=\"math inline\">\\(n, a\\)</span>互素(即<span class=\"math inline\">\\(gcd(n, a) = 1\\)</span>) ，则$a^{(n)} $.</p>\r\n<p>一般的证明中会用到“所有与 $ n $<a href=\"https://zh.wikipedia.org/wiki/互質\" target=\"_blank\" rel=\"noopener\">互质</a>的同余类构成一个<a href=\"https://zh.wikipedia.org/wiki/群\" target=\"_blank\" rel=\"noopener\">群</a>”的性质，也就是说，设 <span class=\"math inline\">\\(\\left\\{ {\\overline {a_{1} }},{\\overline {a_{2} }},\\cdots ,{\\overline {a_{\\varphi (n)} }}\\right\\}\\)</span>是比 $ n $ 小的正整数中所有与<span class=\"math inline\">\\(n\\)</span>互素的数对应的<a href=\"https://zh.wikipedia.org/wiki/同余\" target=\"_blank\" rel=\"noopener\">同余类</a>组成的集合（这个集合也称为模<span class=\"math inline\">\\(n\\)</span>的<a href=\"https://zh.wikipedia.org/wiki/简化剩余系\" target=\"_blank\" rel=\"noopener\">简化剩余系</a>）。这些同余类构成一个群，称为<strong><a href=\"https://zh.wikipedia.org/wiki/整数模n乘法群\" target=\"_blank\" rel=\"noopener\">整数模n乘法群</a></strong>。因为此群阶为<span class=\"math inline\">\\(\\varphi (n)\\)</span>，所以 $ a^{(n)} $。<del>(开始后悔近世代数没认真学)</del></p>\r\n<h3 id=\"费马小定理\">费马小定理</h3>\r\n<p>当n为素数的时候,，则<span class=\"math inline\">\\(\\varphi(n)=n-1\\)</span>，即<span class=\"math inline\">\\(a^{n-1}\\equiv1\\ \\ \\pmod n\\)</span>.</p>\r\n<h3 id=\"模逆元\">模逆元</h3>\r\n<p>一<a href=\"https://zh.wikipedia.org/wiki/整数\" target=\"_blank\" rel=\"noopener\">整数</a>a对<a href=\"https://zh.wikipedia.org/wiki/同餘\" target=\"_blank\" rel=\"noopener\">同余</a>n的<strong>模逆元</strong>是指满足<span class=\"math inline\">\\(ab\\equiv1\\ \\pmod n\\)</span>的整数 b。</p>\r\n<p>整数 a 对模数 n 之模逆元存在的<a href=\"https://zh.wikipedia.org/wiki/充分必要條件\" target=\"_blank\" rel=\"noopener\">充分必要条件</a>是 a 和 n <a href=\"https://zh.wikipedia.org/wiki/互質\" target=\"_blank\" rel=\"noopener\">互素</a></p>\r\n<p>如何求a 对模数 n 之模逆元？</p>\r\n<p>由于a与n互质，所以可用欧拉定理，即<span class=\"math inline\">\\(a^{\\varphi(n)}=a\\cdot a^{\\varphi(n)-1}\\equiv1\\ \\ \\pmod n\\)</span>，即a对模数n的模逆元是<span class=\"math inline\">\\(a^{\\varphi(n)-1}\\)</span>。</p>\r\n<p>特别的，当n为质数时，根据费马小定理，a对模数n的模逆元是<span class=\"math inline\">\\(a^{n-2}\\)</span>。(这样就可使用快速幂在<span class=\"math inline\">\\(log(n)\\)</span>时间求出a的逆元)</p>\r\n<p><strong>还有个小trick:</strong></p>\r\n<p>求X的模MOD逆元时，若<span class=\"math inline\">\\(X\\ \\big|\\ (MOD +1)\\)</span>，则X的模逆元可表示成<span class=\"math inline\">\\(\\frac{MOD + 1} X\\)</span>。比如当MOD为奇数时，2的逆元是<span class=\"math inline\">\\(\\frac {MOD +1}2\\)</span></p>\r\n","categories":["知识总结"],"tags":["算法","数论"]},{"title":"读论文：Closed-loop Matters：Dual Regression Networks for Single Image Super-Resolution","url":"/2020/08/06/2020-08-06-Closed-loop-Matters%EF%BC%9ADual-Regression-Networks-for-Single-Image-Super-Resolution/","content":"<h3 id=\"论文背景\">论文背景</h3>\r\n<p>这篇文章的主要思想是利用对偶学习的思想去训练SR网络，涉及到了很多对偶学习的概念，在这里做一些归纳。</p>\r\n<a id=\"more\"></a>\r\n<h4 id=\"对偶学习dual-learning\">对偶学习(dual learning)</h4>\r\n<p>对偶学习最早是在面对机器翻译问题提出来的，发表在Dual Learning for Machine Translation这篇文章里。作者观察到在机器学习的任务中，有许多任务是对偶存在的，比如：英汉互译。现实中我们往往分别考虑两个过程，即对于汉语翻译成英语进行一个模型的训练，对于英语翻译成汉语进行另一个模型的训练。那这两个模型之间是否存在着什么关系呢？是否可以同时训练这两个过程，同时两者之间可以相互的促进？</p>\r\n<figure>\r\n<img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808100504.png\" alt=\"image-20200806121905733\" /><figcaption aria-hidden=\"true\">image-20200806121905733</figcaption>\r\n</figure>\r\n<p>对偶学习的基本思想是两个对偶的任务能形成一个闭环反馈系统，使我们得以从未标注的数据上获得反馈信息，进而利用该反馈信息提高对偶任务中的两个机器学习模型。该思想具有普适性，可以扩展到多个相关任务上面，前提是只要它们能形成一个闭环反馈系统。例如，从中文翻译到英文，然后从英文翻译到日文，再从日文翻译到中文。另外一个例子是从图片转化成文字，然后从文字转成语音，再从语音转化成图片。本文把超分辨问题也看做的一个闭环反馈系统，即LR&lt;—&gt;HR，进而采用了对偶学习的方法。</p>\r\n<h4 id=\"motivation\">motivation</h4>\r\n<ul>\r\n<li>对于LR-&gt;HR这一ill-pose问题，可能的函数空间过大，限制了学习性能。对于这种问题，现有的很多方法的解决方案是提升模型容量，比如EDSR、DBPN、RCAN。但由于函数空间过大，这些方法的性能还是不高，具体体现在难以生成尖锐的纹理(sharp textures) 。<strong>因此本文的第一个motivation在于如何减少LR-&gt;HR映射空间的大小。</strong></li>\r\n<li>对于训练集，当没有paired训练集时，很多SR模型就没用。再者，对于paired训练集，很多真实世界下的LR图片和训练集中使用固定退化形成的LR图片的分布不一样，进而导致模型在自然场景下表现不好。因此，<strong>本文的第二个motivation在于如何有效的利用unpaired数据集进而使SR模型更适应实际应用</strong>。</li>\r\n</ul>\r\n<h3 id=\"主要贡献\">主要贡献</h3>\r\n<ul>\r\n<li>开发了一个对偶回归方案，使映射可以形成一个闭环，通过对LR图像的重建来提高SR模型的性能。此外，还从理论上分析了该方法的泛化能力，进一步证明了该方法相对于现有方法的优越性。</li>\r\n<li>通过提出的双重回归方案，深度模型可以很容易地适应现实世界的数据。</li>\r\n<li>通过对训练数据和非配对真实数据的大量实验，证明了对偶回归方法在图像超分辨方面的有效性。</li>\r\n</ul>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<h4 id=\"对于paired数据的对偶回归\">对于paired数据的对偶回归</h4>\r\n<p>引入两个网络P和D，loss如下：</p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808100513.png\" alt=\"image-20200806135216943\" style=\"zoom:50%;\" /></p>\r\n<p>前者是原始回归的损失，用于优化P网络；后者是对偶回归的损失，用于优化D网络。</p>\r\n<h4 id=\"对于unpaired数据的对偶回归\">对于unpaired数据的对偶回归</h4>\r\n<p>对于unpaired数据，网络和上述一直，只是loss没有了原始回归的部分。</p>\r\n<p>为了结合paired和unpaired的数据，对于两者混合的数据集，loss如下：</p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808100521.png\" alt=\"image-20200806135615012\" style=\"zoom:67%;\" /></p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808100526.png\" alt=\"image-20200806135854191\" />当xi属于paired数据时为1，否则为0.</p>\r\n<h4 id=\"网络结构\">网络结构</h4>\r\n<p>整体的网络是带skip connection的U-Net，没有特别的地方：</p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808100531.png\" alt=\"image-20200806140000924\" style=\"zoom:67%;\" /></p>\r\n<p>注：U-net左边的input是LR图片通过Bicubic kernel来放大的。</p>\r\n<h4 id=\"理论分析\">理论分析</h4>\r\n<p>本篇论文花了较大篇幅证明这种Dual regression对模型的泛化能力的提升，其中涉及到了Rademacher复杂度等机器学习理论的知识。</p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808100536.png\" alt=\"image-20200806140450086\" style=\"zoom:67%;\" /></p>\r\n<p>推导的结论是：与传统的SR方法相比，对偶回归SR方法具有更小的泛化边界，有助于实现更准确的SR预测。</p>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<h4 id=\"只使用paired数据集\">只使用paired数据集</h4>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808100542.png\" alt=\"image-20200806143030438\" style=\"zoom:67%;\" /></p>\r\n<h4 id=\"加上unpaired数据\">加上unpaired数据</h4>\r\n<h5 id=\"在人工的lr图像的数值表现\">在人工的LR图像的数值表现</h5>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815010807.png\" alt=\"image-20200806143156843\" style=\"zoom:67%;\" /></p>\r\n<h5 id=\"在自然图像的视觉表现\">在自然图像的视觉表现</h5>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808100548.png\" alt=\"image-20200806143223305\" style=\"zoom:67%;\" /></p>\r\n<h4 id=\"消融实验\">消融实验</h4>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808100553.png\" alt=\"image-20200806143409359\" style=\"zoom:67%;\" /></p>\r\n<h4 id=\"损失函数中的λ取值实验\">损失函数中的λ取值实验</h4>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808100557.png\" alt=\"image-20200806143530185\" style=\"zoom:67%;\" /></p>\r\n<h4 id=\"unpaired数据在数据集中的占比ρ\">unpaired数据在数据集中的占比ρ</h4>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808100602.png\" alt=\"image-20200806143729831\" style=\"zoom:50%;\" /></p>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li>乍一看觉得dual regression的思路跟上周看的基于Cycle-GAN的方法的机制很像，但是本文中作者也特地强调了区别：\r\n<ul>\r\n<li>基于Cycle-GAN的方法，使用循环一致损失是为了防止在domain transfer的时候模型倒塌(mode collapse)（即把所有的图片都映射为同一张图来骗过discriminator）；而本文中的目的是把“闭环”作为一个额外的约束来减小可能的函数空间。</li>\r\n<li>基于Cycle-GAN的方法完全抛弃了成对的合成数据(paired synthetic data)；但是本文可以同时利用成对的合成数据和真实世界的非成对数据来增强训练。</li>\r\n</ul></li>\r\n<li>本文出现了很多数学推导，特别是函数空间、Rademacher复杂度等概念我之前没有接触过，读起来比较吃力，而且理解得不是很深刻。让我体会到了自己的机器学习基础数学理论还需要加强。</li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Deep Unfolding Network for Image Super-Resolution","url":"/2020/08/14/2020-08-14-Deep%20Unfolding%20Network%20for%20Image%20Super-Resolution/","content":"<p>这篇CVPR的文章我之前在做面试的project的时候略读过，但是对其中的细节把握的不是很到位，所以这次拿出来再重新精读一遍。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"论文背景\">论文背景</h3>\r\n<p>对于SISR（单图像超分辨）问题，现在一般的解决方法分为两大种：基于模型的方法(model-based)和基于学习的方法(learning-based)</p>\r\n<h4 id=\"基于模型的方法model-based\">基于模型的方法(model-based)</h4>\r\n<p>经典的退化模型如下：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005853.png\" alt=\"image-20200812205000287\" style=\"zoom:67%;\" /></p>\r\n<p>x是HR图像。k是模糊核。s代表s-折下采样(s-fold downsampler)，即只保留每个s×s的patch中的左上角的一个像素。n通常是一个加性的高斯白噪声。</p>\r\n<p>在基于模型的方法中，上面的退化模型得到了广泛的研究，该方法在MAP框架下求解<strong>数据项</strong>和<strong>先验项</strong>的组合。</p>\r\n<p>优点：可解释性，可以灵活处理不同的放大系数、模糊核、噪声级别</p>\r\n<p>缺点：一般采用双三次退化而不考虑模糊核和噪声水平。然而，双三次退化在数学上是复杂的，这反过来又阻碍了基于模型的方法的发展。</p>\r\n<h4 id=\"基于学习的方法learning-based\">基于学习的方法(learning-based)</h4>\r\n<p>经典的基于CNN的方法，基本采用的是端到端(end to end)的训练模型，本质是基于大量数据学习一个双三次退化的LR到HR的非线性映射。</p>\r\n<p>优点：模型容量大、并行计算速度快</p>\r\n<p>缺点：缺乏灵活性，无法灵活处理不同的放大系数、模糊核、噪声级别。</p>\r\n<h4 id=\"深度展开网络unfoldingunrolling-network\">深度展开网络(unfolding/unrolling network)</h4>\r\n<p>展开技术为“领域知识”与“数据(和经验)”的结合提供了一种有效的途径。所谓\"展开\"，是指我们将求解一个给定连续模型的迭代优化看成是一个动态系统，进而通过若干可学习模块来离散化这一系统，得到数据驱动的演化过程的方法。</p>\r\n<p>与单纯的学习方法相比，深度展开方法具有可解释性，能够将退化约束融合到学习模型中。</p>\r\n<p>但是作者表示，现有的深度展开方法有以下一种或几种不足：</p>\r\n<ul>\r\n<li>在不使用CNN的情况下，<strong>先验子问题</strong>的求解能力不够强大，无法获得良好的性能。</li>\r\n<li><strong>数据子问题</strong>没有采用闭合解(closed-form solution)，可能会阻碍收敛。</li>\r\n<li>整个推理是通过分段和微调的方式进行训练的，而不是完整的端到端方式。</li>\r\n</ul>\r\n<h3 id=\"主要贡献\">主要贡献</h3>\r\n<ul>\r\n<li>第一次通过一个单一的端到端训练模型，尝试处理经典退化模型与不同的尺度因子、模糊内核和噪声水平；</li>\r\n<li>为弥合基于模型方法和基于学习的方法之间的差距提供了途径；</li>\r\n<li>本质上提出了一个退化约束(即，估计的HR图像应符合退化过程)和一个先验约束(即，估计的HR图像应该具有自然特征)上的解决方案；</li>\r\n<li>在不同退化设置的LR图像上表现良好，显示了巨大的实际应用潜力。</li>\r\n</ul>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<p>首先对于图像恢复模型，使用MAP最大后验概率，能量函数如下：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005846.png\" alt=\"image-20200812220245580\" style=\"zoom: 67%;\" /></p>\r\n<p>即数据项+正则项，<span class=\"math inline\">\\(\\sigma\\)</span>是高斯噪声的标准差。</p>\r\n<p>利用半二次分裂，分成两个可迭代的子问题：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005854.png\" alt=\"image-20200812220708705\" style=\"zoom:67%;\" /></p>\r\n<p>前者为数据子问题，后者为先验子问题(<span class=\"math inline\">\\(\\Phi\\)</span>为先验项)。</p>\r\n<p>对两个子问题分别求解：</p>\r\n<h4 id=\"数据子问题及其模型\">数据子问题及其模型</h4>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005855.png\" alt=\"image-20200812222444119\" style=\"zoom: 67%;\" /></p>\r\n<p>数据子问题的形式，利用FFT，有一个闭合解：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005856.png\" alt=\"image-20200812221036260\" style=\"zoom:67%;\" /></p>\r\n<p>其中</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005857.png\" alt=\"image-20200812221126772\" style=\"zoom:67%;\" /></p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005900.png\" alt=\"image-20200812222521017\" style=\"zoom:67%;\" /></p>\r\n<p>转换成网络模型为：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005901.png\" alt=\"image-20200812223202570\" style=\"zoom:67%;\" /></p>\r\n<p>这里，<span class=\"math inline\">\\(\\pmb{\\rm x}_{k-1}\\)</span>是上一次迭代的输出；<span class=\"math inline\">\\(\\rm\\pmb s\\)</span>为缩放系数；<span class=\"math inline\">\\(\\rm\\pmb k\\)</span>为模糊核；<span class=\"math inline\">\\(\\rm\\pmb y\\)</span>为LR图像；<span class=\"math inline\">\\(\\alpha_k\\)</span>为噪声水平<span class=\"math inline\">\\(\\sigma\\)</span>和超参数<span class=\"math inline\">\\(\\mu_k\\)</span>决定的。</p>\r\n<p><strong>值得注意的是，式(8)中不包含可训练参数，这使得数据项与先验项完全解耦，从而具有更好的可推广性。</strong></p>\r\n<h4 id=\"先验子问题及其模型\">先验子问题及其模型</h4>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005858.png\" alt=\"image-20200812221138493\" style=\"zoom:67%;\" /></p>\r\n<p>这里令： <span class=\"math display\">\\[\r\n\\beta_k =\\sqrt{\\frac \\lambda {\\mu_k}}\r\n\\]</span> 上式就变成了： <span class=\"math display\">\\[\r\n{\\rm\\pmb x_k}=\\arg \\min_{\\rm x} \\frac 1 {2\\beta_k^2}\\|\\rm\\pmb {z_k - x}\\|^2+\\Phi(x)\r\n\\]</span> <strong>从贝叶斯的角度来看，它实际上对应于某个噪声水平<span class=\"math inline\">\\(\\beta_k\\)</span>（和之前的高斯噪声不是同一个）的去噪问题。</strong></p>\r\n<p>于是这个先验模型表示为：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005859.png\" alt=\"image-20200812221556524\" style=\"zoom:67%;\" /></p>\r\n<p><span class=\"math inline\">\\(\\rm\\pmb z_k\\)</span>为上一个数据模型的输出；<span class=\"math inline\">\\(\\beta_k\\)</span>是代表“去噪等级”的超参数。</p>\r\n<p>这个先验网络的具体结构采用了U-net+ResNet的结构。按照按照U-Net的设置，ResUNet包括四个尺度，每个尺度在降级和升级操作之间都有一个跳跃连接(skip)。通道数分别是：64, 128, 256, 512。下采样采用跨步卷积，上采样使用转置卷积。</p>\r\n<h4 id=\"超参数生成器\">超参数生成器</h4>\r\n<p>对于上述两个模型，都存在有超参数，即数据子问题中的<span class=\"math inline\">\\(\\alpha_k\\)</span>与<span class=\"math inline\">\\(\\rm \\pmb s\\)</span>以及先验子问题中的<span class=\"math inline\">\\(\\beta_k\\)</span>。为了实现端到端的训练，作者提出了另一个超参数生成器模型(hyper-parameter generation)。</p>\r\n<p>其中，数据子问题中的<span class=\"math inline\">\\(\\alpha_k=\\mu_k\\sigma^2\\)</span>，先验子问题中的<span class=\"math inline\">\\(\\beta_k=\\sqrt{\\frac \\lambda {\\mu_k}}\\)</span>。而<span class=\"math inline\">\\(\\sigma\\)</span>和<span class=\"math inline\">\\(\\rm\\pmb s\\)</span>是作为已知的输入，所以超参数生产器实际上要生成的超参数就是<span class=\"math inline\">\\(\\mu_k\\)</span>和<span class=\"math inline\">\\(\\lambda\\)</span>，所以超参数生成器表示为：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005902.png\" alt=\"image-20200812231246217\" style=\"zoom:67%;\" /></p>\r\n<p>为了使性能更好，每次迭代都使用不同的<span class=\"math inline\">\\(\\alpha\\)</span>与<span class=\"math inline\">\\(\\beta\\)</span>，所以超参数生成器的输出实际为：<span class=\"math inline\">\\(\\pmb{\\alpha}=[\\alpha_1, \\alpha_2,\\alpha_3,...,\\alpha_k]\\)</span>，<span class=\"math inline\">\\(\\pmb{\\beta}=[\\beta, \\beta,\\beta,...,\\beta]\\)</span>。</p>\r\n<p>其结构是三层全连接层，前两层的激活函数是ReLU，最后一层为Softplus。</p>\r\n<h4 id=\"网络总体结构\">网络总体结构</h4>\r\n<p>总体结构如图：</p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005903.png\" alt=\"image-20200812232811450\" /><figcaption aria-hidden=\"true\">image-20200812232811450</figcaption>\r\n</figure>\r\n<p>其中，D网络(数据子问题模型)不含可训练参数，图中多个P网络(先验子问题模型)的参数是共享的。</p>\r\n<h4 id=\"端到端的训练过程\">端到端的训练过程</h4>\r\n<h5 id=\"训练数据集设计\">训练数据集设计</h5>\r\n<p>使用DIV2K和Flickr2K的作为HR。LR图片由退化模型进行人工合成，缩放系数设置为1、2、3、4，模糊核采用大小为25×25的各向异性高斯核以及运动核，高斯噪声等级设置为[0, 25]。</p>\r\n<h5 id=\"损失函数\">损失函数</h5>\r\n<p>一开始先使用L1损失进行训练，得到模型之后，再使用：L1损失+VGG感知损失+相对对抗损失 (relativistic adversarial loss, 就是Relativistic GAN中的对抗损失)，进行模型的调整，称为USRGAN。</p>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<h4 id=\"psnr结果\">PSNR结果</h4>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200815005904.png\" alt=\"image-20200812233035695\" style=\"zoom:80%;\" /></p>\r\n<h4 id=\"可视化结果\">可视化结果</h4>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201119212930.png\" alt=\"image-20201119212925063\" /><figcaption aria-hidden=\"true\">image-20201119212925063</figcaption>\r\n</figure>\r\n<h4 id=\"对d和p网络的结果分析\">对D和P网络的结果分析</h4>\r\n<p>观察不同迭代次数的结果：</p>\r\n<p><img src=\"C:\\Users\\xjy\\AppData\\Roaming\\Typora\\typora-user-images\\image-20201119212942410.png\" alt=\"image-20201119212942410\"  /></p>\r\n<p>作者发现，P也可以作为高频恢复的细节增强器。此外，P也没有减少模糊核引起的退化，验证了D和P之间的解耦。</p>\r\n<h4 id=\"对h网络的结果分析\">对H网络的结果分析</h4>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201119213001.png\" alt=\"image-20201119212958722\" /><figcaption aria-hidden=\"true\">image-20201119212958722</figcaption>\r\n</figure>\r\n<p>可以看出随着迭代次数的增加，beta呈递减趋势；但beta随着尺度因子和噪声水平的增加而增加。这说明，在迭代过程中，HR的先验会逐渐减少占比；以及，在复杂的退化过程中，需要一个更大的<span class=\"math inline\">\\(\\beta\\)</span>来处理这一ill-posed问题。</p>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li>这类深度展开的方法，通过MAP+半二次分裂，把model-based和learning-based的方法的优点结合在一起，感觉很惊艳。这相当于让“知识”和“数据”对最终的模型都有了贡献。</li>\r\n<li>作者在文中还提到了一个与深度展开有点类似的工作，叫做deep plug-and-play方法，也可以把model-based和learning-based的方法结合起来，我准备把之后把这篇工作也仔细看一下</li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Learning Texture Transformer Network for Image Super-Resolution","url":"/2020/08/04/2020-08-04-Learning-Texture-Transformer-Network-for-Image-Super-Resolution/","content":"<h3 id=\"论文背景\">论文背景</h3>\r\n<p>图像超分的方法主要分为两类：一类是单图像超分(SISR)，比如SRCNN，VDSR,RCAN等；另外一类是基于参考图像的超分方法(RefSR)。因为高分辨率图像在退化过程中会丢失很多细节和纹理信息，所以传统的单图像超分方法会产生模糊的结果；为了恢复更多的纹理信息，有研究者使用GANs来实现图像超分(SRGAN,ESRGAN等)，但是GANs所带来的伪影artifacts却很难避免。 第二类方法通过Ref图像来实现图像超分取得了很好的结果，该方法通过从Ref 图像上迁移HR的纹理信息来获得视觉上可观的效果。本文的方法属于第二类，通过查询Ref 图像上<strong>合理</strong>纹理信息，将其融入到最终的超分结果。<strong>不同于以往的该类方法，本文能够有效的避免错误的纹理迁移。</strong></p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<h4 id=\"四个主要模块\">四个主要模块</h4>\r\n<p>如下图所示，本文提出了四个模块：可学习的纹理提取器模块(Learnable Texture Extractor), 相关性嵌入模块(Relevance Embedding)，硬注意力模块(Hard Attention)，软注意力模块(Soft Attention)。</p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808101919.png\" alt=\"image-20200808003441653\" style=\"zoom:67%;\" /></p>\r\n<p><strong>可学习的纹理提取器模块：</strong> 对于纹理信息提取，目前主流方法是使用VGG网络来提取一些浅层的特征来作为纹理信息。但是，VGG网络的训练目标是以语义为导向的图像类别标签，其高层的语义信息与低层的纹理信息有很大的差异，所以这种方式有明显的缺陷。<strong>本文提出了一种可学习的纹理提取器，其本质是一个浅层的卷积神经网络</strong>。随着训练的不断推进，该提取器不断更新自己的参数，最终可以提取到最适合超分的纹理信息，为后面的纹理迁移和纹理合成提供了很好的基础，最终生成高质量的超分结果。</p>\r\n<p>注：对 Ref 图片做双三次（bicubic）下采样，再做双三次上采样，目的是为了和 LR保持域一致（即都是经过双三次变换得到的）</p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808101926.png\" alt=\"image-20200808004957589\" style=\"zoom: 67%;\" /></p>\r\n<p><strong>相关性嵌入模块：</strong> 本文提出的纹理Transformer有Q，K，V三个要素，分别表示从低分辨率图像所提取的纹理特征信息(用来进行纹理检索)，高分辨率参考图像经过先下采样再上采样得到的与低分辨率图像分布一致的图像纹理信息(用来进行纹理检索)和原参考图像的纹理信息(用来进行纹理迁移)。<strong>将Q和K分别提取特征块，然后以内积的方式计算Q和K中的特征块两两之间的相关性</strong>。内积越大表示这两个特征块之间的相关性越强，可迁移的高频纹理信息越多。反之，内积越小的地方代表这两个特征块之间的相关性越弱，可迁移的高频纹理信息就越少。该模块输出的是一个硬注意力图 H 和软注意力图 S。</p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808102016.png\" alt=\"image-20200808005108730\" style=\"zoom:67%;\" /></p>\r\n<p><strong>硬注意力模块：</strong> 利用硬注意力图 H 中记录的位置，从V中迁移对应位置的特征块，组合成迁移纹理特征图 T，其中 T 的每个位置包含参考图像中最相似的位置的高频纹理特征。T接着与骨干网络中的特征 F 进行级联，通过一个卷积层得到融合后的特征。</p>\r\n<p><strong>软注意力模块：</strong> 将上述融合后的特征与软注意力图进行对应位置作点乘，此时相关性强的纹理信息能够赋予相对更大的权重；相关性弱的纹理信息因为权重小而得到抑制，这样能够更好的迁移高频纹理信息的特征。</p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808102027.png\" alt=\"image-20200808005410271\" style=\"zoom:67%;\" /></p>\r\n<p><strong>跨尺度特征融合：</strong></p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808102031.png\" alt=\"image-20200808003335200\" style=\"zoom:67%;\" /></p>\r\n<p>上图将本文所提出的纹理transformer应用于x1,x2,x4三个尺度，并将不同尺度间的特征通过上采样或者带步长的卷积进行交叉融合。这样，可将参考图像的信息运用到不同的尺度，进而提高网络的特征表达能力，提高图像生成的质量。</p>\r\n<h4 id=\"损失函数\">损失函数</h4>\r\n<p><strong>总的损失函数</strong></p>\r\n<p>损失函数比较常规，由重建损失+对抗损失+感知损失构成：</p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808102037.png\" alt=\"image-20200808003757153\" style=\"zoom:67%;\" /></p>\r\n<p>重建损失使用L1 损失：</p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808102042.png\" alt=\"image-20200808004007973\" style=\"zoom:67%;\" /></p>\r\n<p>对抗损失使用WGAN-GP：</p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808102047.png\" alt=\"image-20200808004017320\" style=\"zoom:67%;\" /></p>\r\n<p>感知损失如下：</p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808102116.png\" alt=\"image-20200808003944923\" style=\"zoom:67%;\" /></p>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<h4 id=\"数值效果和视觉效果\">数值效果和视觉效果</h4>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808102137.png\" alt=\"image-20200808004100714\" style=\"zoom:67%;\" /></p>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808102143.png\" alt=\"image-20200808004124347\" style=\"zoom:67%;\" /></p>\r\n<h4 id=\"消融实验\">消融实验</h4>\r\n<p><img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200808102154.png\" alt=\"image-20200808004237454\" style=\"zoom:67%;\" /></p>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li>不同于我之前接触的SISR，这篇研究的是RefSR， RefSR 能有效利用来自 HR 参照图像的丰富纹理，来补充 LR 图像中缺失的细节，从而缓解不适定问题；</li>\r\n<li>查阅资料得知，Q (query), K(key), V (value)这些思想，最早是应用于NLP的transform中，作者将其用于图像生成任务。对于此类跨研究方向的idea迁移，以后也需多加关注。</li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Unpaired Image Super-Resolution using Pseudo-Supervision","url":"/2020/07/30/2020-07-30-Unpaired-Image-Super-Resolution-using-Pseudo-Supervision/","content":"<h3 id=\"论文背景\">论文背景</h3>\r\n<p>这是CVPR 2020的一篇超分工作。</p>\r\n<p>最开始的超分技术，基于的都是固定的下采样制造的训练数据集(比如双三次)，不适于在真实场景下的超分辨。对此，目前主要有以下两种解决思路：</p>\r\n<a id=\"more\"></a>\r\n<ul>\r\n<li><p>blind SR methods：用一些随机的模糊核去构造LR图像，但是这些退化形式还是有一些限制性的假设。</p></li>\r\n<li><p>GAN-based unpaired SR methods：直接利用GAN来学一个LR-&gt;HR的映射，不对退化过程做任何假设。</p>\r\n<p>GAN-based的方法主要有以下两种：</p>\r\n<ul>\r\n<li><p>直接法</p>\r\n<ul>\r\n<li><p>generator网络用于把LR放大为一个“假的”HR图像，从而欺骗discriminator网络。在这种方法中，discriminator网络的职责是辨别其是否是真的HR图像</p></li>\r\n<li><p>缺点：训练generator时，无法使用像素级的损失函数。（我的理解：比如SRGAN的数值指标不好）而这种像素损失不仅在以失真为导向(distortion-oriented)、以感知为导向(perception-oriented)的方法中都起着重要作用。</p>\r\n<p><img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801103716.png\" alt=\"image-20200729230958756\" style=\"zoom:67%;\" /></p></li>\r\n</ul></li>\r\n<li><p>间接法</p>\r\n<ul>\r\n<li>generator网络用于把HR缩小为一个“假的”LR图像来欺骗discriminator网络。然后这个“假的”LR图像就可以以paired方式来训练一个SR网络。</li>\r\n<li>缺点：生成的LR图像的分布与真实的LR分布之间有偏差，会导致在测试集上的性能低下。</li>\r\n</ul></li>\r\n</ul>\r\n<p><img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801103737.png\" alt=\"image-20200729230625647\" style=\"zoom:67%;\" /></p></li>\r\n</ul>\r\n<p>作者基于Cycle-GAN提出了一种新的方法。这里简要了解了一下Cycle-GAN</p>\r\n<p>#### Cycle-GAN</p>\r\n<p>cycle-GAN是ICCV17的工作，是在条件图像生成领域，实现两个域(domain)的的图片的转化。传统的GAN是单向生成，而CycleGAN是互相生成，网络是个环形，所以命名为Cycle。并且CycleGAN一个非常实用的地方就是输入的两张图片可以是任意的两张图片，也就是可以是unpaired的。</p>\r\n<figure>\r\n<img src=\"http://media.paperweekly.site/LUOHAO_1513259309.1659012.png?imageView2/2/w/800/q/70%7Cimageslim\" alt=\"图片\" /><figcaption aria-hidden=\"true\">图片</figcaption>\r\n</figure>\r\n<p>X→Y的判别器损失为： <span class=\"math display\">\\[\r\n  L_{GAN}(G,D_Y,X,Y)=\\mathbb{E}_{y\\sim p_{data}(y)}[\\log{D_Y(y)}]+\\mathbb{E}_{x\\sim p_{data}(x)}[\\log{(1-D_Y(G(x)))}]\r\n\\]</span> Y→X的判别器损失为: <span class=\"math display\">\\[\r\n  L_{GAN}(F,D_X,Y,X)=\\mathbb{E}_{x\\sim p_{data}(x)}[\\log{D_X(x)}]+\\mathbb{E}_{y\\sim p_{data}(y)}[\\log{(1-D_X(F(y)))}]\r\n\\]</span> 而两个生成器的loss加起来表示为： <span class=\"math display\">\\[\r\n  L_{cyc}(G,F) = \\mathbb{E}_{x \\sim p_{data}(x)}[||F(G(x))-x||_1]+\\mathbb{E}_{y \\sim p_{data}(y)}[||G(F(y))-y||_1]\r\n\\]</span> 最终网络的所有损失加起来为： <span class=\"math display\">\\[\r\n  L(G,F,D_X,D_Y)=L_{GAN}(G,D_Y,X,Y)+L_{GAN}(F,D_X,Y,X)+L_{cyc}(G,F)\r\n\\]</span></p>\r\n<p>#### motivation</p>\r\n<p>既然cycle-GAN可以在unpair的条件下学习一个domain到另一个domain的映射，那么作者想到基于cycle-GAN引入一个correction network用来实现true LR domain ↔︎ clean LR domain 的转化。所谓Clean LR是作者提出的一个新概念，意思是对HR图像使用预先设定的降采样操作得到的LR图像；而true LR就是真实的自然场景下的LR图像。在这种意义下，由于先前的SR网络能在clean LR得到好的效果，那么利用这个cycle-GAN，把整个SR过程就变成true LR-&gt;clean LR-&gt;HR。</p>\r\n<p>### 主要方法</p>\r\n<p><strong>LR图像的域转换(domain transfer)</strong>：</p>\r\n<p>如上文所述，要实现true LR与clean LR的域转换，也利用就是cycle-GAN的思想，设置两个Generator网络，分别完成true LR-&gt;clean LR与clean LR-&gt;true LR任务。分别在clean LR、true LR两个域设置两个Discriminator网络，用来辨别其分布是否真实。同时，在clean LR-&gt;true LR-&gt;pseudo-clean LR上保证循环的一致性（起点和终点尽可能相同）。</p>\r\n<figure>\r\n<img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801103749.png\" alt=\"image-20200730161358150\" /><figcaption aria-hidden=\"true\">image-20200730161358150</figcaption>\r\n</figure>\r\n<p><strong>LR到HR的映射</strong>：</p>\r\n<p>当我们有一个HR图像时，可以首先利用特定的降采样方式，得到一张clean LR，再通过Cycle-GAN转一圈得到pseudo-clean LR。这时，设置一个网络U，学习一个pseudo-clean LR到原HR图像的映射。</p>\r\n<figure>\r\n<img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801103804.png\" alt=\"image-20200730161421917\" /><figcaption aria-hidden=\"true\">image-20200730161421917</figcaption>\r\n</figure>\r\n<p><strong>使用HR Discriminator进行调整</strong>：</p>\r\n<p>尽管在训练网络U时，是使用pseudo-clean LR来作为输入训练的(即图中的绿色实线)，但是在测试过程中，是通过图中的黑色实线生成最终的SR图片的。因此，再增加了一个HR Discriminator，用于判断<strong>是不是“黑线”的分布</strong>。值得注意的是，这个HR Discriminator的对抗损失只用于更新两个Generator的参数，而SR网络U的参数被固定。</p>\r\n<p>#### 损失函数</p>\r\n<p>用于优化2个Generator和3个Discriminator的损失函数如下：</p>\r\n<ul>\r\n<li><p><strong>对抗损失(Adversarial loss)</strong>：</p>\r\n<p>每个Discriminator即对应了一个对抗损失，损失函数就是GAN的经典形式：</p></li>\r\n</ul>\r\n<p><img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801105343.png\" alt=\"image-20200730162918528\" style=\"zoom:67%;\" /></p>\r\n<p><img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801105352.png\" alt=\"image-20200730162939508\" style=\"zoom:67%;\" /></p>\r\n<p><img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801105401.png\" alt=\"image-20200730162952467\" style=\"zoom:67%;\" /></p>\r\n<ul>\r\n<li><p><strong>循环一致性损失(Cycle consistency loss)</strong>：</p>\r\n<p>经典的Cycle-GAN本来需要两个循环一致损失的，但本文放松了这个约束，只用了其中一个:</p></li>\r\n</ul>\r\n<p><img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801105419.png\" alt=\"image-20200730163148166\" style=\"zoom:67%;\" /></p>\r\n<ul>\r\n<li><p><strong>恒等映射损失(Identity mapping loss)</strong>：</p>\r\n<p>在原始的Cycle-GAN中，对生成器进行正则化以接近恒等映射。这里同理，给true LR-&gt;clean LR的网络也添加一个类似的正则项：</p></li>\r\n</ul>\r\n<p><img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801105423.png\" alt=\"image-20200730174843176\" style=\"zoom:67%;\" /></p>\r\n<ul>\r\n<li><p><strong>几何整体损失(Geometric ensemble loss)</strong>：</p>\r\n<p>引入了一个简单的几何集合损失，它要求翻转和旋转输入图像不改变结果：</p></li>\r\n</ul>\r\n<p><img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801105920.png\" alt=\"image-20200730174955563\" style=\"zoom:67%;\" /></p>\r\n<p>最后把上述loss线性组合一下：</p>\r\n<p><img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801105414.png\" alt=\"image-20200730175411735\" style=\"zoom:67%;\" /></p>\r\n<p>而对于SR网络U，它是独立于Generator和Discriminator的，他的loss很简单，即重构损失，使用的是普通的L1 loss：</p>\r\n<p><img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801105835.png\" alt=\"image-20200730175500577\" style=\"zoom:67%;\" /></p>\r\n<p>#### 网络结构</p>\r\n<p>该篇的重点不在于其网络内部结构，因此简述</p>\r\n<ul>\r\n<li>对于SR网络U、true LR-&gt;clean LR网络，都用的是RCAN的结构</li>\r\n<li>而 clean LR-&gt;true LR网络，用的5x5卷积的ResBlock，用的LeakyReLU激活，加了BN层。值得一提的是，为了加入一些随机的扰动，给原始的RGB通道增加了一些高斯分布N(0, 1)的通道</li>\r\n<li>对于三个Discriminator网络，五层卷积层+LeakyReLU+BN</li>\r\n</ul>\r\n<p>### 实验结果</p>\r\n<p>#### 自然场景下的图片</p>\r\n<figure>\r\n<img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801103815.png\" alt=\"image-20200730180948340\" /><figcaption aria-hidden=\"true\">image-20200730180948340</figcaption>\r\n</figure>\r\n<figure>\r\n<img src=\"https://cdn.jsdelivr.net/gh/jamekuma/images/20200801115735.png\" alt=\"image-20200730181019859\" /><figcaption aria-hidden=\"true\">image-20200730181019859</figcaption>\r\n</figure>\r\n<p>#### 人脸</p>\r\n<p><img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801103920.png\" alt=\"image-20200730184840662\" style=\"zoom:67%;\" /></p>\r\n<p>#### 航空图像</p>\r\n<figure>\r\n<img src=\"https://raw.githubusercontent.com/jamekuma/images/master/20200801103930.png\" alt=\"image-20200730185747556\" /><figcaption aria-hidden=\"true\">image-20200730185747556</figcaption>\r\n</figure>\r\n<p>### 总结与思考</p>\r\n<ul>\r\n<li>以往SR问题中，我们都在思考，如何对每一个HR图像，构造更贴近自然场景的LR图像，从而生成更好的&lt;HR, LR&gt;的paired数据集（比如使用退化模型，对核进行各种估计，或是生成更自然的核等等）。既然普通SR网络，在“人造”的LR图像上表现良好，本文则提出了一个很新颖的思路，把重点放在如何把“自然“的LR图像，转换为”固定退化方式”的LR图像，进而得到更好的SR效果；</li>\r\n<li>作者开创性的把Cycle-GAN用到了SR领域。在unpaired数据集上，用于“自然“的LR图像域与”固定退化方式”的LR图像域的转换；</li>\r\n<li>这样做的好处是，不仅摈弃了对退化模式估计过程中的各种限制性的假设，也能对直接对SR结果做像素级别的限制。</li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Correction Filter for Single Image Super-Resolution：Robustifying Off-the-Shelf Deep Super-Resolvers","url":"/2020/09/18/2020-09-18-Correction%20Filter%20for%20Single%20Image%20Super-Resolution%EF%BC%9ARobustifying%20Off-the-Shelf%20Deep%20Super-Resolvers/","content":"<h3 id=\"论文背景\">论文背景</h3>\r\n<h4 id=\"motivation\">motivation</h4>\r\n<p>针对某个退化模型训练的SR网络，如果换了退化模型，性能就会有很大下降（比方说训练集用双三次下采样构造，而测试时遇到其他的退化模型）。于是作者从广义采样中受到了启发，出了一种改进现有的CNN框架的方法，即使用一个校正滤波器，能把一张LR图像变化到其他核模糊下的LR图像(如双三次核)，进而提高test时SR网络的性能，具体分为非盲SR和盲SR两种情况：</p>\r\n<ul>\r\n<li>在非盲SR中，LR图像的模糊核是已知的(但不一定和训练集的核匹配)，于是作者构造的滤波器，可以提供一个将其转换到指定退化核LR图像的校正滤波器，并且是<strong>闭合解</strong>。</li>\r\n<li>而在盲SR中，LR图像的模糊核是未知的，作者提出了一种能估计这张LR所需校正滤波器的算法。</li>\r\n</ul>\r\n<a id=\"more\"></a>\r\n<h4 id=\"相关知识\">相关知识</h4>\r\n<p>我查阅了相关文献，大致了解到广义采样的概念：</p>\r\n<p>所谓广义采样是相对于经典的Nyquist-Shannon采样理论的。</p>\r\n<h5 id=\"nyquist-shannon采样\">Nyquist-Shannon采样</h5>\r\n<p>传统的Shannon采样是一种针对带限信号的等距理想采样，其处理过程如图所示。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204156.png\" alt=\"image-20200919154641833\" style=\"zoom:67%;\" /></p>\r\n<p>输入的连续信号<span class=\"math inline\">\\(x(t)\\)</span>经过前置滤波器变为带限信号，以Nyquist采样率进行采样获得离散信号： <span class=\"math display\">\\[\r\n\\tilde{x}(t)=x(t) \\cdot \\delta(t)=\\sum_{n \\in \\mathbf{Z}} x(n T) \\delta(t-n T)\r\n\\]</span> 为了便于前置滤波器的实现，降低带外无用信号频谱重叠的影响，实际上信号的采样频率往往要比Nyquist采样率高。而信号重构可通过理想低通滤波器来实现，在时域等同于采用无限长的非因果冲激响应，即sinc函数插值重构得到： <span class=\"math display\">\\[\r\n\\hat{x}(t)=\\sum_{n \\in \\mathbf{Z}} x(n T) \\sin c(t / T-n)\r\n\\]</span> 物理上重构的实现只能通过非理想的低通滤波或时域上现在与过去时刻的采样值通过内插来实现，但无论是非理想的低通滤波或有限长度的插值均会产生重构误差。以线性调频信号为例，通过仿真说明采样与重构的关系。假设原始信号的脉宽为1 ms，带宽为30 kHz。采样频率取70 kHz,具体仿真结果见下图。</p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204157.png\" alt=\"image-20200919155138597\" /><figcaption aria-hidden=\"true\">image-20200919155138597</figcaption>\r\n</figure>\r\n<p>可以看出，当采样频率为70kHz时基本上能够无失真地恢复原始信号,有重构误差是因为在Matlab中Sinc函数取值必须进行截断,对应频谱是非理想低通滤波器,从而造成误差。由图2(b).上图可知，重构误差随采样频率的增大而减小,当采样频率低于Nyquist 采样率(60 kHz)时，重构误差将迅速上升。图2(b)下图则表示重构误差随Sinc函数加窗截断后长度的增加而减小,当点数取无限长时理论误差为零。<strong>因此，Shannon采样的重构精度同时受采样频率与插值内核的长度影响,而工程实现上不可能采用过高的采样频率与过长的插值长度,这正是Shannon采样局限性的体现。</strong></p>\r\n<h5 id=\"广义采样\">广义采样</h5>\r\n<p>由式(5)可以发现，<span class=\"math inline\">\\(\\{\\sin c(t-n), n \\in Z\\}\\)</span>其实是一个线性无关且相互正交的函数族。即sinc函数在时间轴上的平移函数族构成了所有带限函数组成的函数空间的一组正交基。这里定义一个基本近似空间<span class=\"math inline\">\\(V\\)</span>即 <span class=\"math display\">\\[\r\nV(\\varphi)=\\left\\{s(x)=\\sum_{k \\in \\mathbf{Z}} c(k) \\varphi(x-k): c \\in l_{2}\\right\\}\r\n\\]</span> 表示空间V内任意的连续函数s(x)都能够表示为系数c(k)的序列。</p>\r\n<p>信号的采样及重构，实际上就是对给定的信号，通过选取合适的基，使信号在这组基下的投影具有所需要的性质。如果在某个基下不符合要求，那么就将其变换到另一个基下表示。与Shannon采样对应，这里给出广义采样的处理框架如图所示：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204158.png\" alt=\"image-20200919155417433\" style=\"zoom:67%;\" /></p>\r\n<p><strong>将连续信号与基函数求内积、采样并经过一个数字校正滤波器（校正滤波器的作用是将与采样核相关联的采样系数，变换为与重构核相匹配的系数），得到其在该基底上的离散展开系数，再由广义上的重构公式即可恢复原始信号。</strong></p>\r\n<p><strong>广义采样理论提供了一种框架和条件，在这种框架和条件下，在一定的基采样后的信号可以在不同的基上重建。</strong></p>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<p>对于退化过程，<span class=\"math inline\">\\(\\mathbf{x} \\in \\mathbb{R}^{n}\\)</span>，<span class=\"math inline\">\\(\\mathbf{y} \\in \\mathbb{R}^{m}\\)</span>，<span class=\"math inline\">\\(n&gt;m\\)</span>： <span class=\"math display\">\\[\r\n\\mathbf{y}=(\\mathbf{x} * \\mathbf{k}) \\downarrow_\\alpha\r\n\\]</span> 作者写成一个线性变换的形式： <span class=\"math display\">\\[\r\n\\mathbf{y}=\\mathcal{S}^{*} \\mathbf{x}\r\n\\]</span> 其中，<span class=\"math inline\">\\(\\mathcal{S}^{*}: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{m}\\)</span>。即把模糊+下采样整合在一起，即<span class=\"math inline\">\\(\\mathcal{S}^{*}\\)</span>对应了真实的下采样核的退化过程：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204159.png\" alt=\"image-20200919164149529\" style=\"zoom:67%;\" /></p>\r\n<p>令<span class=\"math inline\">\\(\\mathcal{R}^{*}\\)</span>为双三次下采样退化过程对应的线性变换，即<span class=\"math inline\">\\(\\mathbf{y}_{b i c u b}=\\mathcal{R}^{*} \\mathbf{x}\\)</span>。</p>\r\n<h4 id=\"非盲sr时的闭合解\">非盲SR时的闭合解</h4>\r\n<p>定义<span class=\"math inline\">\\(\\mathcal{S}\\)</span>与<span class=\"math inline\">\\(\\mathcal{R}\\)</span>分别为为<span class=\"math inline\">\\(\\mathcal{S}^{*}\\)</span>与<span class=\"math inline\">\\(\\mathcal{R}^{*}\\)</span>的伴随算子。作者假设<span class=\"math inline\">\\(\\mathbf{x}\\)</span>能从<span class=\"math inline\">\\(\\mathcal{R}^{*} \\mathbf{x}\\)</span>使用算子<span class=\"math inline\">\\(\\mathcal{R}\\left(\\mathcal{R}^{*} \\mathcal{R}\\right)^{-1}\\)</span>恢复： <span class=\"math display\">\\[\r\n\\mathbf{x}=\\mathcal{R}\\left(\\mathcal{R}^{*} \\mathcal{R}\\right)^{-1} \\mathcal{R}^{*} \\mathbf{x}\r\n\\]</span> 即利用了<span class=\"math inline\">\\(\\mathcal{R}^{*}\\)</span>的伪逆，可从从<span class=\"math inline\">\\(\\mathbf{y}_{\\text {bicub}}=\\mathcal{R}^{*} \\mathbf{x}\\)</span>恢复出原HR图像。</p>\r\n<p>然后作者表示，对于不是双三次退化的LR图像<span class=\"math inline\">\\(\\mathbf y\\)</span>，可以引入一个估计过程： <span class=\"math display\">\\[\r\n\\hat{\\mathbf{x}}=\\mathcal{R} \\mathcal{H} \\mathbf{y}\r\n\\]</span> 即先对<span class=\"math inline\">\\(\\mathbf y\\)</span>作一个变换<span class=\"math inline\">\\(\\mathcal H\\)</span>，在经过原始的超分辨过程<span class=\"math inline\">\\(\\mathcal R\\)</span>。</p>\r\n<p>作者证明了<span class=\"math inline\">\\(\\mathcal{H}=\\left(\\mathcal{S}^{*} \\mathcal{R}\\right)^{-1}: \\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{m}\\)</span>，（前提是<span class=\"math inline\">\\(\\operatorname{null}\\left(\\mathcal{S}^{*}\\right) \\cap \\operatorname{range}(\\mathcal{R})=\\{0\\}\\)</span>）： <span class=\"math display\">\\[\r\n\\begin{aligned}\r\n\\hat{\\mathbf{x}} &amp;=\\mathcal{R} \\mathcal{H} \\mathbf{y} \\\\\r\n&amp;=\\mathcal{R} \\mathcal{H} \\mathcal{S}^{*} \\mathbf{x} \\\\\r\n&amp;=\\mathcal{R} \\mathcal{H} \\mathcal{S}^{*} \\mathcal{R}\\left(\\mathcal{R}^{*} \\mathcal{R}\\right)^{-1} \\mathcal{R}^{*} \\mathbf{x}\r\n\\end{aligned}\\\\\r\n\\begin{aligned}\r\n\\hat{\\mathbf{x}} &amp;=\\mathcal{R}\\left(\\mathcal{S}^{*} \\mathcal{R}\\right)^{-1} \\mathcal{S}^{*} \\mathcal{R}\\left(\\mathcal{R}^{*} \\mathcal{R}\\right)^{-1} \\mathcal{R}^{*} \\mathbf{x} \\\\\r\n&amp;=\\mathcal{R}\\left(\\mathcal{R}^{*} \\mathcal{R}\\right)^{-1} \\mathcal{R}^{*} \\mathbf{x}=\\mathbf{x}\r\n\\end{aligned}\r\n\\]</span></p>\r\n<p>据此，作者给出校正滤波器的初始版本<span class=\"math inline\">\\(\\mathbf h_0\\)</span>： <span class=\"math display\">\\[\r\n\\mathbf{h}_{0}=\\operatorname{IDFT}\\left\\{\\frac{1}{\\operatorname{DFT}\\left\\{\\left(\\mathbf{k} * \\operatorname{flip}\\left(\\mathbf{k}_{\\text {bicub}}\\right)\\right) \\downarrow_{\\alpha}\\right\\}}\\right\\}\r\n\\]</span> 但是对于<span class=\"math inline\">\\(\\hat{\\mathbf{x}}=\\mathcal{R} \\mathcal{H} \\mathbf{y}\\)</span>这个估计过程，是没有用到任何的自然图像的先验的。而对于一个使用双三次下采样的数据集训练好的CNN网络<span class=\"math inline\">\\(f\\)</span>，估计过程可以写为<span class=\"math inline\">\\(\\hat{\\mathbf{x}}=f(\\mathbf{h} * \\mathbf{y})\\)</span>。<span class=\"math inline\">\\(f\\)</span>学到了<span class=\"math inline\">\\(\\mathcal{R}\\left(\\mathcal{R}^{*} \\mathcal{R}\\right)^{-1}\\)</span>这一$^{<em>} <span class=\"math inline\">\\(的反过程作为先验。所以在网络\\)</span>f<span class=\"math inline\">\\(中，他其实隐含的完成了\\)</span>(^{</em>} )<sup>{-1}<span class=\"math inline\">\\(的过程，于是在对\\)</span>y<span class=\"math inline\">\\(进行滤波的时候，先要加上\\)</span></sup>{*} $的过程，即： <span class=\"math display\">\\[\r\n\\begin{aligned}\r\n\\mathbf{h} &amp;=\\operatorname{IDFT}\\left\\{\\frac{\\operatorname{DFT}\\left\\{\\left(\\mathbf{k}_{\\text {bicub}} * \\operatorname{flip}\\left(\\mathbf{k}_{\\text {bicub}}\\right)\\right) \\downarrow_{\\alpha}\\right\\}}{\\operatorname{DFT}\\left\\{\\left(\\mathbf{k} * \\operatorname{flip}\\left(\\mathbf{k}_{\\text {bicub}}\\right)\\right) \\downarrow_{\\alpha}\\right\\}}\\right\\} \\\\\r\n&amp; \\triangleq \\operatorname{IDFT}\\left\\{\\frac{F_{\\text {numer}}}{F_{\\text {denom}}}\\right\\}\r\n\\end{aligned}\r\n\\]</span> 作者表示，为了数值稳定性，式子改成了这样： <span class=\"math display\">\\[\r\n\\mathbf{h}=\\operatorname{IDFT}\\left\\{F_{n u m e r} \\cdot \\frac{F_{\\text {denom}}^{*}}{\\left|F_{\\text {denom}}\\right|^{2}+\\epsilon}\\right\\}\r\n\\]</span></p>\r\n<h4 id=\"盲sr的估计算法\">盲SR的估计算法</h4>\r\n<p>对于盲SR，作者表示，任务变成了既要估计模糊核<span class=\"math inline\">\\(\\mathbf k\\)</span>又要估计校正滤波器<span class=\"math inline\">\\(\\mathbf h\\)</span>。作者提出了一个估计<span class=\"math inline\">\\(\\mathbf k\\)</span>的目标函数： <span class=\"math display\">\\[\r\n\\xi(\\mathbf{k})=\\left\\|\\mathbf{y}-\\mathcal{S}^{*} f(\\mathcal{H} \\mathbf{y})\\right\\|_{\\mathrm{Hub}}+\\left\\|\\mathbf{m}_{\\mathrm{cen}} \\cdot \\mathbf{k}\\right\\|_{1}+\\|\\mathbf{k}\\|_{1}\r\n\\]</span> <span class=\"math inline\">\\(\\left\\|\\ \\right\\|_{\\mathrm{Hub}}\\)</span>表示Huber loss，<span class=\"math inline\">\\(\\mathcal H\\)</span>就对应的(12)式中的滤波器，<span class=\"math inline\">\\(\\mathbf{m}_{\\mathrm{cen}}(x, y)=1-\\mathrm{e}^{-\\frac{\\left(x^{2}+y^{2}\\right)}{32 \\alpha^{2}}}\\)</span>。最后两项是正则化因子:最后一项促进k的稀疏性，倒数第二项用于集中k的密度(？)。</p>\r\n<p>具体求<span class=\"math inline\">\\(\\mathbf k\\)</span>的过程，是把其作为一个线性CNN的参数去优化：<span class=\"math inline\">\\(\\mathbf{k}=\\mathbf{k}_{0} * \\mathbf{k}_{1} * \\mathbf{k}_{2} * \\mathbf{k}_{3}\\)</span>.</p>\r\n<p>具体算法如下：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204200.png\" alt=\"image-20200919174149913\" style=\"zoom:67%;\" /></p>\r\n<p>在每次迭代中，都得到了<span class=\"math inline\">\\(\\mathbf k\\)</span>和校正滤波器<span class=\"math inline\">\\(\\mathbf h\\)</span>的估计值。</p>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204201.png\" alt=\"image-20200919174356439\" /><figcaption aria-hidden=\"true\">image-20200919174356439</figcaption>\r\n</figure>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204202.png\" alt=\"image-20200919174411673\" /><figcaption aria-hidden=\"true\">image-20200919174411673</figcaption>\r\n</figure>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204203.png\" alt=\"image-20200919174337073\" style=\"zoom:67%;\" /></p>\r\n<p>盲的过程：</p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204204.png\" alt=\"image-20200919174438482\" /><figcaption aria-hidden=\"true\">image-20200919174438482</figcaption>\r\n</figure>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204205.png\" alt=\"image-20200919192138900\" style=\"zoom:67%;\" /></p>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li><p>校正滤波器就对应了广义采样中的数字校正滤波器；而不同的模糊核就视作了不同的采样基底。</p></li>\r\n<li><p>从整体来看，把LR转换成“干净”退化模式（比如双三次）的思路，和以前看的利用GAN转换domain的想法类似，但是是从完全不同的角度。</p></li>\r\n<li><p>本文把SR问题视作一种信号采样-恢复的过程，是我之前没见过的角度。而我之前没有学过信息论，对相关知识了解较少，花了大量时间去查阅相关资料与文献。以后应该把相关知识系统性的学一下。</p></li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Stochastic Frequency Masking to Improve Super-Resolution and Denoising Networks","url":"/2020/09/14/2020-09-14-Stochastic%20Frequency%20Masking%20to%20Improve%20Super-Resolution%20and%20Denoising%20Networks/","content":"<p>这篇算是一篇超分辨/去噪的数据增强方面的文章，与以往的数据增强不同的是，它是在频域的角度设置了数据增强方法。</p>\r\n<h3 id=\"论文背景\">论文背景</h3>\r\n<p>作者指出，基于学习的超分辨/去噪的CNN网络，总是基于一个庞大的数据集来训练。而这个数据集往往是通过把ground-truth图片经过一个模糊核/有限的模糊核集合进行退化构造出LR图片。但是在测试过程中，往往需要针对一个未知模糊核的LR图像来进行SR，或是对一个未知等级的噪声进行denoising。<strong>作者指出，现有的SR模型都对有限的退化模型产生了过拟合。</strong>作者在频域中分析了这一点。进一步地，作者更加形式化地揭示了SR过程中隐含的一种条件学习——“在已知低频的情况下学习高频”。据此，作者提出了本文的主要工作——随机频率掩蔽(Stochastic Frequency Masking, SFM)。</p>\r\n<a id=\"more\"></a>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204144.png\" alt=\"image-20200917205540371\" style=\"zoom:67%;\" /></p>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<h4 id=\"背景知识\">背景知识</h4>\r\n<p>在信号与系统中学习过，一个离散的信号x(n)，设它的DTFT(离散时间傅里叶变换)为X(ω)，则对x(n)的采样间隔。为T的采样信号z的DTFT为<span class=\"math inline\">\\(Z(\\omega)=\\frac{1}{T} \\sum_{k=0}^{T-1} X((\\omega+2 \\pi k) / T)\\)</span>。这T个X(ω)的副本会使得Z(ω)频谱的高频部分发生混叠。即如果想要从z恢复到x时，高频的混叠就会造成视觉扭曲。因此有时也在下采样的过程中使用一个(非理想的)低通滤波器，先把可能重叠的高频部分减弱，这个低通滤波器就对应了模糊核。</p>\r\n<blockquote>\r\n<p>这里我对这个逻辑还是有疑问，为什么是为了防止混叠才用这个模糊核。难道模糊核不是退化模型中客观存在的过程吗？</p>\r\n<p>原文如下：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204145.png\" alt=\"image-20200917212102189\" style=\"zoom:67%;\" /></p>\r\n</blockquote>\r\n<p>真实的模糊核毕竟只是所有数学上所有可能的核的一个子空间。但是，在以前的工作中，这个子空间并没有很好的定义，而总是定义为一个空域的卷积核，比如一个高斯核，即试图模拟原始捕获设备的点扩展函数(可以理解为冲激响应函数)。但是实际上，即使是单个成像设备也会产生多个模糊核，甚至不一定是高斯核。</p>\r\n<h4 id=\"sr过程在频域上的可视化实验\">SR过程在频域上的可视化实验</h4>\r\n<p>作者做了一个实验，先使用<span class=\"math inline\">\\(\\sigma=4.1\\)</span>的高斯核构造一个训练数据集，去训练一个RRDB网络。然后在测试过程，利用这个网络来SR一个由<span class=\"math inline\">\\(\\sigma=7.4\\)</span>的高斯核构造的LR图像。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204146.png\" alt=\"image-20200917220015573\" style=\"zoom: 50%;\" /></p>\r\n<p>对于测试过程，在频域分别分析了groud-truth、LR、SR图片的功率谱密度：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204147.png\" alt=\"image-20200917215907810\" style=\"zoom:67%;\" /></p>\r\n<ul>\r\n<li><p>对于一张自然图像，功率谱密度一般满足<span class=\"math inline\">\\(1/f^\\alpha\\)</span>的幂函数（绿色）</p></li>\r\n<li><p>而退化后的LR图像，会缺少大量的高频信息（粉色）</p></li>\r\n<li><p>而经过SR网络后，SR图像的部分高频强度会被恢复（红色）</p>\r\n<ul>\r\n<li>但是，从图中可以看出，恢复的主要是频率大于<span class=\"math inline\">\\(0.2\\pi\\)</span>的高频信息。也就是构造<strong>训练集</strong>时，原始的HR图像中被高斯低通滤波器滤掉的那一部分。</li>\r\n<li>而构造<strong>测试集</strong>时，其实使用的是一个更加“严格的”低通滤波器(空域上高斯核的<span class=\"math inline\">\\(\\sigma\\)</span>与频域上高斯滤波器的<span class=\"math inline\">\\(\\sigma\\)</span>是负相关的，<span class=\"math inline\">\\(g(x)=\\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} e^{-\\frac{x^{2}}{2 \\sigma^{2}}}\\)</span> &lt;-&gt;<span class=\"math inline\">\\(G(f)=e^{-\\frac{f^{2}}{2 / \\sigma^{2}}}\\)</span>)，所以它的最低截止频率比训练集中的低。</li>\r\n<li>这导致了在恢复的SR输出中没有得到的缺失频率分量（上图中的蓝色虚线圆）</li>\r\n</ul></li>\r\n<li><p>而作者表示，用了他提出的SFM就不会有这个问题：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204148.png\" alt=\"image-20200917221256524\" style=\"zoom:67%;\" /></p></li>\r\n</ul>\r\n<h4 id=\"隐含的条件学习\">隐含的条件学习</h4>\r\n<p>如果抗混叠时使用的滤波器是一个理想低通滤波器（高频全去掉，低频不受影响），那么SR网络对应如下的条件学习： <span class=\"math display\">\\[\r\nP\\left(I^{H R} \\otimes F^{H P} \\mid I^{H R} \\otimes F^{L P}\\right)\r\n\\]</span> 意为从低频信息中去学习高频信息。</p>\r\n<p>而对于实际上的非理想低通滤波器，它既不能全部去掉高频，又不能完全不衰减低频。于是对应了如下的条件学习： <span class=\"math display\">\\[\r\nP\\left(I^{H R} \\otimes F^{H P} \\mid I^{H R} \\otimes F_{o}^{L P}\\right), \\quad P\\left(I^{H R} \\otimes F^{L P}-I^{H R} \\otimes F_{0}^{L P} \\mid I^{H R} \\otimes F_{o}^{L P}\\right)\r\n\\]</span></p>\r\n<h4 id=\"把以上理论扩展到去噪\">把以上理论扩展到去噪</h4>\r\n<p>高斯白噪声的功率谱密度是一条水平线，噪声加在原始的图像上，形成了信噪比的变化。而每个频率上的信噪比，随着频率增加而降低(即<span class=\"math inline\">\\(1/f^\\alpha\\)</span>曲线)：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204149.png\" alt=\"image-20200918151017689\" style=\"zoom:67%;\" /></p>\r\n<p>换句话说，高频几乎完全被噪声所取代，而低频受噪声的影响则小得多。并且，当噪声水平越高时，启动频率(超过这个频率，信噪比就非常小)越低。这和上述SR的分析是一致的。</p>\r\n<p>综上，无论是SR还是denoising，都存在一种隐含条件学习，可以在低频部分受到较少影响的情况下，预测高频部分的损失。</p>\r\n<h4 id=\"随机频率掩蔽sfm\">随机频率掩蔽(SFM)</h4>\r\n<p>把图片使用离散余弦变换到频域上，然后在通道级别上进行频率掩蔽。频率掩蔽带都是一个四分之一的圆环，即只需确定掩蔽带的频率上下界即可。具体确定掩蔽带的方法有两种模式：中心模式、目标模式</p>\r\n<h5 id=\"中心模式\">中心模式</h5>\r\n<p>中心模式是指，掩蔽带的上下界都是<span class=\"math inline\">\\([0,r_M]\\)</span>的均匀分布，<span class=\"math inline\">\\(r_M\\)</span>是最大半径。于是根据概率论的知识很容易推出，给定一个频率<span class=\"math inline\">\\(r_\\omega\\)</span>，被掩蔽的概率是： <span class=\"math display\">\\[\r\nP\\left(r_{I}&lt;r_{\\omega}&lt;r_{O}\\right)=2\\left(\\frac{r_{\\omega}}{r_{M}}-\\left(\\frac{r_{\\omega}}{r_{M}}\\right)^{2}\\right)\r\n\\]</span> 这个是一个凸的二次函数，也就是在中心部位的频率最容易被掩蔽。</p>\r\n<h5 id=\"目标模式\">目标模式</h5>\r\n<p>选定一个目标频率<span class=\"math inline\">\\(r_C\\)</span>以及另一个参数<span class=\"math inline\">\\(\\sigma_{\\Delta}\\)</span>，定义掩蔽的范围是<span class=\"math inline\">\\(\\left[r_{C}-\\delta_{I}, r_{C}+\\delta_{O}\\right]\\)</span>，<span class=\"math inline\">\\(\\delta_{I}\\)</span>与<span class=\"math inline\">\\(\\delta_{O}\\)</span>都是服从一个高斯分布<span class=\"math inline\">\\(f_{\\Delta}(\\delta)=\\sqrt{2} / \\sqrt{\\pi \\sigma_{\\Delta}^{2}} e^{-\\delta^{2} /\\left(2 \\sigma_{\\Delta}^{2}\\right)}, \\forall \\delta \\geq 0\\)</span>。在这种模式下，频率<span class=\"math inline\">\\(r_C\\)</span>总是被掩蔽，远离<span class=\"math inline\">\\(r_C\\)</span>的频率越来越不可能被掩蔽，并具有正态分布的衰减。</p>\r\n<p>中心模式用于SR任务，而目标模式用于denoising。前者有一个缓慢的凹概率衰减，允许覆盖更宽的波段，而后者有一个指数衰减适应于目标非常狭窄的波段。在这两种情况下，最高的频率最有可能被掩盖，较低的频率被衰减概率掩盖。（这句话我没理解，中心模式下，不应该是<span class=\"math inline\">\\(\\frac {r_M} 2\\)</span>下才是最高概率吗）</p>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<p>实际应用中，作者对50%的数据集进行了SFM，得到的效果都比原来好了很多。</p>\r\n<p>这是使用双三次退化、高斯模糊的LR图片测试结果：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204150.png\" alt=\"image-20200918162037612\" style=\"zoom:67%;\" /></p>\r\n<p>使用真实场景下的退化数据集RealSR和SR-RAW：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204151.png\" alt=\"image-20200918162301410\" style=\"zoom:67%;\" /></p>\r\n<p>加性高斯白噪声的去噪：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204152.png\" alt=\"image-20200918162336339\" style=\"zoom:67%;\" /></p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204153.png\" alt=\"image-20200918162357197\" style=\"zoom:67%;\" /></p>\r\n<p>真实的泊松-高斯噪声图片：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204154.png\" alt=\"image-20200918162500452\" style=\"zoom:67%;\" /></p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204155.png\" alt=\"image-20200918162517579\" style=\"zoom:67%;\" /></p>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li>这篇工作本身并没有特别复杂，但是从频域角度进行数据增强的思路倒是比较新颖</li>\r\n<li>作者设置了巧妙的实验，并通过功率谱密度图，说明了频域下图像复原的条件学习，进而引导出随机频率掩蔽的方法</li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Density estimation using Real NVP","url":"/2020/11/03/2020-11-03-DENSITY%20ESTIMATION%20USING%20REAL%20NVP/","content":"<h3 id=\"论文背景\">论文背景</h3>\r\n<p>RealNVP的全称，real-valued non-volume preserving ，可以翻译为“真实值非体积保持”。对于无监督学习来说，感兴趣的数据通常是高维的、高度结构化的，因此该领域的挑战是构建足够强大的模型，以捕获其复杂性，但仍然是可训练的。作者通过引入实值非体积保持(real NVP)转换来解决这一挑战，这是一种易于处理但表现能力强的高维数据建模方法。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images2020/12/12/12:21:48.png\" alt=\"image-20201106194258145\" style=\"zoom:67%;\" /></p>\r\n<p>基本思想是把数据空间映射到隐空间z，如上图所示。</p>\r\n<a id=\"more\"></a>\r\n<p>以前的相关工作：</p>\r\n<ul>\r\n<li>受限玻尔兹曼机、深度玻尔兹曼机\r\n<ul>\r\n<li>通过利用两方的条件独立性来训练模型结构，可以对潜在变量进行有效的精确或近似后验推断。然而，由于潜在变量的相关边际分布的难处理性。训练、评估和抽样程序必须使用Mean Field inference 和马尔可夫链蒙特卡洛法。对于此类复杂模型，收敛时间往往是不确定的。另外，各种近似也限制了其性能</li>\r\n</ul></li>\r\n<li>有向概率图模型\r\n<ul>\r\n<li>在推理过程中的各种近似，限制了性能</li>\r\n</ul></li>\r\n<li>自回归模型\r\n<ul>\r\n<li>避免引入隐变量，从而消除各种近似。</li>\r\n<li>RNN、LSTM</li>\r\n<li>非并行，慢</li>\r\n</ul></li>\r\n<li>GAN\r\n<ul>\r\n<li>度量生成样本的多样性的指标不明确</li>\r\n<li>训练不稳定</li>\r\n</ul></li>\r\n</ul>\r\n<p>而作者提出的方法，可以训练这样一个生成网络<span class=\"math inline\">\\(g\\)</span>，它将潜在变量<span class=\"math inline\">\\(z \\sim p_Z\\)</span>映射到样本<span class=\"math inline\">\\(x \\sim p_{X}\\)</span>，理论上不需要像GANs那样使用鉴别器网络，也不需要像变分自编码器那样使用近似推理。的确，如果g是双射，可以利用变量的变化公式，通过极大似然对其进行训练： <span class=\"math display\">\\[\r\np_{X}(x)=p_{Z}(z)\\left|\\operatorname{det}\\left(\\frac{\\partial g(z)}{\\partial z^{T}}\\right)\\right|^{-1}\r\n\\]</span></p>\r\n<h3 id=\"主要方法\">主要方法</h3>\r\n<p>上周读的NICE，也是这个作者之前的工作，作者表示，自己在NICE的基础上，定义了一个更强大的双射函数类，它支持精确和可处理的概率密度评估与推理。代价函数不依赖于固定的形式重构代价（比如L2损失等），因此可以产生更加非平滑的样本。另外，这次提出的方法可以使用batch normalization、ResBlock等，从而构建一个具有多个抽象层次的深度多尺度架构（a very deep multi-scale architecture with multiple levels of abstraction）。</p>\r\n<h4 id=\"耦合层\">耦合层</h4>\r\n<p>Real NVP的耦合层相较于NICE的有很大的不同：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images2020/12/12/12:21:48-1.png\" alt=\"image-20201106203733407\" style=\"zoom:67%;\" /></p>\r\n<p>写成式子： <span class=\"math display\">\\[\r\n\\begin{aligned}\r\n\\left\\{\\begin{array}{l}\r\ny_{1: d}=x_{1: d} \\\\\r\ny_{d+1: D}=x_{1: 1: D} \\odot \\exp \\left(s\\left(x_{1: d}\\right)\\right)+t\\left(x_{1: d}\\right)\r\n\\end{array}\\right.\\\\\r\n\\Leftrightarrow\\left\\{\\begin{array}{l}\r\nx_{1: d}=y_{1: d} \\\\\r\nx_{d+1: D}=\\left(y_{d+1: D}-t\\left(y_{1: d}\\right)\\right) \\odot \\exp \\left(-s\\left(y_{1: d}\\right)\\right)\r\n\\end{array}\\right.\r\n\\end{aligned}\r\n\\]</span></p>\r\n<p>与NICE同理，其雅克比行列式也是易于计算的： <span class=\"math display\">\\[\r\n\\frac{\\partial y}{\\partial x^{T}}=\\left[\\begin{array}{cc}\r\n\\mathbb{I}_{d} &amp; 0 \\\\\r\n\\frac{\\partial y_{d+1: D}}{\\partial x_{1: d}^{T}} &amp; \\operatorname{diag}\\left(\\exp \\left[s\\left(x_{1: d}\\right)\\right]\\right)\r\n\\end{array}\\right]=\\exp \\left[\\sum_{j} s\\left(x_{1: d}\\right)_{j}\\right]\r\n\\]</span> <strong>计算耦合层的逆并不需要计算s或t的逆，因此这些函数可以任意复杂且难以求逆。</strong></p>\r\n<h4 id=\"mask-convolution\">Mask Convolution</h4>\r\n<p>另外，在实际实现中，可以使用一个Masked convolution，即使用一个二值化的mask <span class=\"math inline\">\\(b\\)</span>： <span class=\"math display\">\\[\r\ny=b \\odot x+(1-b) \\odot(x \\odot \\exp (s(b \\odot x))+t(b \\odot x))\r\n\\]</span> 对于mask，有以下两种模式：</p>\r\n<ul>\r\n<li>棋盘格掩蔽(checkerboard masking)</li>\r\n<li>通道掩蔽(channel-wise masking)</li>\r\n</ul>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images2020/12/12/12:21:48-2.png\" alt=\"image-20201106212224230\" style=\"zoom: 50%;\" /></p>\r\n<h4 id=\"耦合层的整合\">耦合层的整合</h4>\r\n<p>尽管耦合层功能强大，但它们的前向转换保留了一些组件(比如<span class=\"math inline\">\\(x_{1: d}\\)</span>)。可以通过将耦合层组合为<strong>交替模式</strong>来克服这一困难，这样，在一个耦合层中保持不变的组件，将在下一个耦合层中更新:</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images2020/12/12/12:21:48-3.png\" alt=\"image-20201106212608981\" style=\"zoom: 50%;\" /></p>\r\n<p>另外，多个耦合层的雅克比行列式只需累乘即可： <span class=\"math display\">\\[\r\n\\begin{aligned}\r\n\\frac{\\partial\\left(f_{b} \\circ f_{a}\\right)}{\\partial x_{a}^{T}}\\left(x_{a}\\right) &amp;=\\frac{\\partial f_{a}}{\\partial x_{a}^{T}}\\left(x_{a}\\right) \\cdot \\frac{\\partial f_{b}}{\\partial x_{b}^{T}}\\left(x_{b}=f_{a}\\left(x_{a}\\right)\\right) \\\\\r\n\\operatorname{det}(A \\cdot B) &amp;=\\operatorname{det}(A) \\operatorname{det}(B)\r\n\\end{aligned}\r\n\\]</span></p>\r\n<h4 id=\"多尺度结构multi-scale-architecture\">多尺度结构(Multi-scale architecture)</h4>\r\n<p>(这一部分我看的不是很懂)</p>\r\n<p>作者通过squeeze操作实现了一个多尺度的架构:对于每个通道，将图像分割成形状为2×2×c的子正方形，然后将其重新塑形为形状为1×1×4c的子正方形。squeeze操作将一个s×s×c张量转化为一个2s×2s×4c张量，有效地交换了通道数与空间大小的关系。</p>\r\n<p>在每个尺度上，将几个操作组合成如下序列：我们首先应用三个耦合层，交替使用checkerboard masking，然后执行squeeze操作，最后应用三个耦合层，交替使用channel-wise masking。</p>\r\n<p>在所有耦合层中传播一个D维向量将是很麻烦的，因为计算和内存成本，以及需要训练的参数的数量。由于这个原因，作者遵循VGG中的设计选择，并定期提出一半的尺寸：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images2020/12/12/12:21:48-4.png\" alt=\"image-20201106214810116\" style=\"zoom:67%;\" /></p>\r\n<h4 id=\"batch-normalization\">Batch normalization</h4>\r\n<p>批处理归一化的影响很容易包含在雅可比矩阵的计算中，因为它是对每个维度的线性调整。也就是说，给定估计的批处理统计量： <span class=\"math display\">\\[\r\nx \\mapsto \\frac{x-\\tilde{\\mu}}{\\sqrt{\\tilde{\\sigma}^{2}+\\epsilon}}\r\n\\]</span> 我们具有雅克比矩阵： <span class=\"math display\">\\[\r\n\\left(\\prod_{i}\\left(\\tilde{\\sigma}_{i}^{2}+\\epsilon\\right)\\right)^{-\\frac{1}{2}}\r\n\\]</span></p>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images2020/12/12/12:21:48-5.png\" alt=\"image-20201106220750676\" style=\"zoom:67%;\" /></p>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li><p>这篇是作者在本人的NICE工作的基础上的一篇完善工作，主要进步在于：</p>\r\n<ul>\r\n<li><p>改善了仿射层的结构</p></li>\r\n<li><p>使用了mask卷积保证了推理过程中所有信息都被处理</p></li>\r\n<li><p>考虑了多尺度的结构</p></li>\r\n<li><p>RealNVP 的雅可比行列式不再恒等于 1，行列式的几何意义就是体积，所以行列式等于 1 就意味着体积没有变化，而仿射耦合层的行列式不等于 1 就意味着体积有所变化，所谓“非体积保持”。</p></li>\r\n</ul></li>\r\n<li><p>第一篇 NICE 中，作者提出了加性耦合层。后面也提到了乘性耦合层，只不过没有用上；而在 RealNVP 中，加性和乘性耦合层结合在一起，成为一个一般的“仿射耦合层”。</p></li>\r\n<li><p>本文的mask卷积实质上就是对两个耦合层直接的信息实施一种可逆的打乱，比NICE中的单纯交换分区中两个子集的角色的做法要更优</p></li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：SRFlow：Learning the Super-Resolution Space with Normalizing Flow","url":"/2020/09/04/2020-09-04-SRFlow%EF%BC%9ALearning%20the%20Super-Resolution%20Space%20with%20Normalizing%20Flow/","content":"<h3 id=\"论文背景\">论文背景</h3>\r\n<p>作者表示，SR问题本来就是一个ill-posed的问题，可是大多数工作忽略了这一点，只致力于去学一个单图像到单图像的映射。而作者利用了基于标准化流(Normalizing Flow)的方法，去学一个LR到<strong>HR分布</strong>的映射（学习与输入LR图像相对应的真实HR图像的分布，即可以看做是给定LR图像，HR的条件概率分布），同时还表明在去噪、复原的任务中也能发挥作用。</p>\r\n<p>所谓标准化流(Normalizing Flow)的方法，是用来拟合一些复杂概率分布的。实际上就是学一个可逆神经网络<span class=\"math inline\">\\(f_{\\theta}\\)</span>，使用它的逆过程<span class=\"math inline\">\\(f_{\\theta}^{- 1}\\)</span>把一个简单的分布(比如高斯分布、均匀分布等)<span class=\"math inline\">\\(p_{\\mathbf{z}}(\\mathbf{z})\\)</span>变成<span class=\"math inline\">\\(\\mathbf{y} = f_{\\theta}^{- 1}(\\mathbf{z})\\)</span>。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"主要方法\">主要方法</h3>\r\n<h4 id=\"sr中的条件标准化流\">SR中的条件标准化流</h4>\r\n<p>设<span class=\"math inline\">\\(\\mathbf{x}\\)</span>是LR图像，<span class=\"math inline\">\\(\\mathbf{y}\\)</span>是HR图像。本文要求确定LR图像下，HR图像的条件概率分布<span class=\"math inline\">\\(p_{\\mathbf{y|x}}(\\mathbf{y|x,\\theta})\\)</span>。提供的训练数据是LR-HR图像对<span class=\"math inline\">\\(\\{(\\mathbf{x}_{i},\\mathbf{y}_{i})\\}_{i = 1}^{M}\\)</span></p>\r\n<p>根据标准化流的思想，要使用一个可逆神经网络<span class=\"math inline\">\\(f_{\\theta}\\)</span>去拟合这个分布<span class=\"math inline\">\\(p_{\\mathbf{y|x}}\\)</span>，<span class=\"math inline\">\\(f_{\\theta}\\)</span>把一个HR-LR图像对映射到一个隐变量<span class=\"math inline\">\\(z\\)</span>上：<span class=\"math inline\">\\(\\mathbf{z} = f_{\\theta}(\\mathbf{y;x})\\)</span>。而要求这个网络在任意<span class=\"math inline\">\\(\\mathbf{x}\\)</span>的条件下，对于<span class=\"math inline\">\\(\\mathbf{y}\\)</span>是可逆的，即<span class=\"math inline\">\\(\\mathbf{y} = f_{\\theta}^{- 1}(\\mathbf{z;x})\\)</span>。使用概率论中的随机变量代换，可以得到以下式子：</p>\r\n<p><span class=\"math display\">\\[\r\np_{\\mathbf{y} \\mid \\mathbf{x}}(\\mathbf{y} \\mid \\mathbf{x},\\mathbf{\\theta}) = p_{\\mathbf{z}}\\left( f_{\\mathbf{\\theta}}(\\mathbf{y};\\mathbf{x}) \\right)\\left| \\det\\frac{\\partial f_{\\mathbf{\\theta}}}{\\partial\\mathbf{y}}(\\mathbf{y};\\mathbf{x}) \\right|\r\n\\]</span> 也就是给定HR图像<span class=\"math inline\">\\(\\mathbf{y}\\)</span>和LR图像<span class=\"math inline\">\\(\\mathbf{x}\\)</span>，最大化这个<span class=\"math inline\">\\(p_{\\mathbf{y} \\mid \\mathbf{x}}(\\mathbf{y} \\mid \\mathbf{x},\\mathbf{\\theta})\\)</span>就可。写成负对数：</p>\r\n<p><span class=\"math display\">\\[\r\n\\mathcal{L}(\\mathbf{\\theta};\\mathbf{x},\\mathbf{y}) = - \\log p_{\\mathbf{y} \\mid \\mathbf{x}}(\\mathbf{y} \\mid \\mathbf{x},\\mathbf{\\theta}) = - \\log p_{\\mathbf{z}}\\left( f_{\\mathbf{\\theta}}(\\mathbf{y};\\mathbf{x}) \\right) - \\log\\left| \\det\\frac{\\partial f_{\\mathbf{\\theta}}}{\\partial\\mathbf{y}}(\\mathbf{y};\\mathbf{x}) \\right|\r\n\\]</span></p>\r\n<p>即可作为损失函数进行训练了。要想在拟合的分布中采样也很简单，就使用符合预定的分布的<span class=\"math inline\">\\(\\mathbf{z}\\)</span>代入<span class=\"math inline\">\\(\\mathbf{y} = f_{\\mathbf{\\theta}}^{- 1}(\\mathbf{z};\\mathbf{x})\\)</span>即可。</p>\r\n<p>把以上(3)式的第二项改写成每一层可逆模块串接的形式：</p>\r\n<p><span class=\"math display\">\\[\r\n\\mathcal{L}(\\mathbf{\\theta};\\mathbf{x},\\mathbf{y}) = - \\log p_{\\mathbf{z}}(\\mathbf{z}) - \\sum_{n = 0}^{N - 1}\\log\\left| \\det\\frac{\\partial f_{\\mathbf{\\theta}}^{n}}{\\partial\\mathbf{h}^{n}}\\left( \\mathbf{h}^{n};g_{\\mathbf{\\theta}}(\\mathbf{x}) \\right) \\right|\r\n\\]</span></p>\r\n<p>其中，<span class=\"math inline\">\\(\\mathbf{h}^{n + 1} = f_{\\mathbf{\\theta}}^{n}\\left( \\mathbf{h}^{n};g_{\\mathbf{\\theta}}(\\mathbf{x}) \\right)\\)</span>，且<span class=\"math inline\">\\(\\mathbf{h}^{0} = \\mathbf{y}\\)</span>、<span class=\"math inline\">\\(\\mathbf{h}^{N} = \\mathbf{z}\\)</span>。这样，只需在每一层上计算特定的雅克比行列式，而不是全体一起计算。而且加入了一个CNN网络<span class=\"math inline\">\\(g_{\\theta}\\)</span>来学习LR图像最适合作为条件的表示。</p>\r\n<h4 id=\"条件流层conditional-flow-layers\">条件流层(Conditional Flow Layers)</h4>\r\n<h5 id=\"条件仿射耦合conditional-affine-coupling\">条件仿射耦合(Conditional Affine Coupling)</h5>\r\n<p><span class=\"math display\">\\[\r\n\\mathbf{h}_{A}^{n + 1} = \\mathbf{h}_{A}^{n},\\quad\\mathbf{h}_{B}^{n + 1} = \\exp\\left( f_{\\mathbf{\\theta},\\mathbf{s}}^{n}\\left( \\mathbf{h}_{A}^{n};\\mathbf{u} \\right) \\right) \\cdot \\mathbf{h}_{B}^{n} + f_{\\mathbf{\\theta},\\mathbf{b}}^{n}\\left( \\mathbf{h}_{A}^{n};\\mathbf{u} \\right)\r\n\\]</span></p>\r\n<p><span class=\"math inline\">\\(\\mathbf{h}^{n} = \\left( \\mathbf{h}_{A}^{n},\\mathbf{h}_{B}^{n} \\right)\\)</span>是特征图，A和B是其通道上的分离。这样就能通过仿射变换实现可逆。同时，雅克比矩阵是一个三角阵，他的行列式的对数形式容易写成<span class=\"math inline\">\\(\\sum_{\\text{ijk}}^{}f_{\\mathbf{\\theta},s}^{n}\\left( \\mathbf{h}_{A}^{n};\\mathbf{u} \\right)_{\\text{ijk}}\\)</span></p>\r\n<h5 id=\"仿射注入affine-injector\">仿射注入(Affine Injector)</h5>\r\n<p>对于上一节的设计，要求<span class=\"math inline\">\\(f_{\\mathbf{\\theta}}^{n}\\)</span>是可逆的，而且可以处理雅克比行列式。于是作者做了以下设计，称之为仿射注入器(Affine Injector)：</p>\r\n<p><span class=\"math display\">\\[\r\n\\mathbf{h}^{n + 1} = \\exp\\left( f_{\\mathbf{\\theta},s}^{n}(\\mathbf{u}) \\right) \\cdot \\mathbf{h}^{n} + f_{\\mathbf{\\theta},b}(\\mathbf{u})\r\n\\]</span></p>\r\n<p>其中<span class=\"math inline\">\\(\\mathbf{u} = g_{\\theta}(\\mathbf{x})\\)</span>，易得其实可逆的：<span class=\"math inline\">\\(\\mathbf{h}^{n} = \\exp\\left( - f_{\\mathbf{\\theta},s}^{n}(\\mathbf{u}) \\right) \\cdot \\left( \\mathbf{h}^{n + 1} - f_{\\mathbf{\\theta},b}^{n}(\\mathbf{u}) \\right)\\)</span></p>\r\n<p>同时，雅克比矩阵是一个三角阵，他的行列式的对数形式容易写成<span class=\"math inline\">\\(\\sum_{\\text{ijk}}^{}f_{\\mathbf{\\theta},s}^{n}\\left( \\mathbf{h}_{A}^{n};\\mathbf{u} \\right)_{\\text{ijk}}\\)</span></p>\r\n<h4 id=\"网络结构\">网络结构</h4>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204120.png\" alt=\"image-20200917170228257\" /><figcaption aria-hidden=\"true\">image-20200917170228257</figcaption>\r\n</figure>\r\n<h4 id=\"其他的应用\">其他的应用</h4>\r\n<h5 id=\"lr一致的style-transfer\">LR一致的Style Transfer</h5>\r\n<p>即把一张HR图像下采样成LR图像，进而控制隐变量<span class=\"math inline\">\\(\\mathbf{z}\\)</span>转移成不同风格的HR图像</p>\r\n<h5 id=\"latent-space-normalization\">Latent Space Normalization</h5>\r\n<p>在上述的SR任务中，核心是：把<strong>任意</strong>符合<strong>给定要求</strong>（\"要求\"即LR图像）的HR图像映射到一个隐含空间(即z)，而为了匹配LR图像中那些\"共有的低频特征\"，这个z被\"标准化\"为某一分布。</p>\r\n<p>作者提出，原始的<span class=\"math inline\">\\(\\widetilde{\\mathcal{Z}}\\)</span>可以被标准化为另外一个分布<span class=\"math inline\">\\(\\widehat{\\mathcal{Z}}\\)</span>：</p>\r\n<p><span class=\"math display\">\\[\r\n\\widehat{z} = \\frac{\\widehat{\\sigma}}{\\widetilde{\\sigma}}(\\widetilde{z} - \\widetilde{\\mu}) + \\widehat{\\mu},\\quad\\forall\\widetilde{z} \\in \\widetilde{\\mathcal{Z}}\r\n\\]</span></p>\r\n<p>其中<span class=\"math inline\">\\(\\widetilde{\\sigma}\\)</span>与<span class=\"math inline\">\\(\\widetilde{\\mu}\\)</span>是原始分布的经验标准差和经验均值。进而通过逆过程实现图像风格的迁移<span class=\"math inline\">\\(\\widehat{\\mathbf{y}} = f_{\\mathbf{\\theta}}^{- 1}(\\widehat{\\mathbf{z}},\\mathbf{x})\\)</span></p>\r\n<p>后面是这种标准化的两个具体应用。</p>\r\n<h5 id=\"image-content-transfer\">Image Content Transfer</h5>\r\n<p>首先有一张待迁移的HR图片<span class=\"math inline\">\\(\\mathbf{y}\\)</span>，我们把它下采样<span class=\"math inline\">\\(\\mathbf{x} = d_{\\downarrow}(\\mathbf{y})\\)</span>。然后我们可以直接在<span class=\"math inline\">\\(\\mathbf{y}\\)</span>上进行篡改（或许改的很拙劣），得到<span class=\"math inline\">\\(\\widetilde{\\mathbf{y}}\\)</span>。现在我们为了使<span class=\"math inline\">\\(\\widetilde{\\mathbf{y}}\\)</span>看起来不那么拙劣，我们首先把其对应的隐分布表示出来<span class=\"math inline\">\\(\\widetilde{\\mathbf{z}} = f_{\\mathbf{\\theta}}(\\widetilde{\\mathbf{y}};\\mathbf{x})\\)</span>（注意，这里用到的\"要求\"是原始的<span class=\"math inline\">\\(\\mathbf{y}\\)</span>的下采样版本），再使用上述的Latent Space Normalization，从而得到迁移后的图片</p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204121.png\" alt=\"image-20200917170248004\" /><figcaption aria-hidden=\"true\">image-20200917170248004</figcaption>\r\n</figure>\r\n<h5 id=\"image-restoration\">Image Restoration</h5>\r\n<p>一种使用SR实现图像复原的朴素思想是，利用一些下采样方法，把噪声图像中的噪声去除，再使用SR方法进行复原。但是在下采样的过程中丢失了很多细节。</p>\r\n<p>而使用上述的思想就可以避免这种问题。可以把退化的图像、退化图像的下采样版本都放进<span class=\"math inline\">\\(f_{\\theta}\\)</span>里：<span class=\"math inline\">\\(\\widetilde{\\mathbf{z}} = f_{\\mathbf{\\theta}}(\\widetilde{\\mathbf{y}};\\mathbf{x})\\)</span>，然后对<span class=\"math inline\">\\(\\widetilde{\\mathbf{z}}\\)</span>进行标准化为<span class=\"math inline\">\\(\\widehat{\\mathbf{z}}\\)</span>，进而得到复原的图像<span class=\"math inline\">\\(\\widehat{\\mathbf{y}} = f_{\\mathbf{\\theta}}^{- 1}(\\widehat{\\mathbf{z}},\\mathbf{x})\\)</span>。完整的复原过程描述为：<span class=\"math inline\">\\(\\widehat{\\mathbf{y}} = f_{\\mathbf{\\theta}}^{- 1}\\left( \\phi\\left( f_{\\mathbf{\\theta}}\\left( \\widetilde{\\mathbf{y}};d_{\\downarrow}(\\widetilde{\\mathbf{y}}) \\right) \\right),d_{\\downarrow}(\\widetilde{\\mathbf{y}}) \\right)\\)</span>.</p>\r\n<p>直观来说，这个方法是把一个退化图像映射到了分布<span class=\"math inline\">\\(p_{\\mathbf{y} \\mid \\mathbf{x}}(\\mathbf{y} \\mid \\mathbf{x},\\mathbf{\\theta})\\)</span>中最接近的图片，因为这个分布训练的时候，是没有引入退化的，所以就能得到对应的\"干净\"的HR图片。</p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204122.png\" alt=\"image-20200917170257774\" /><figcaption aria-hidden=\"true\">image-20200917170257774</figcaption>\r\n</figure>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204123.png\" alt=\"image-20200917170303654\" /><figcaption aria-hidden=\"true\">image-20200917170303654</figcaption>\r\n</figure>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204124.png\" alt=\"image-20200917170309522\" /><figcaption aria-hidden=\"true\">image-20200917170309522</figcaption>\r\n</figure>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200921204125.png\" alt=\"image-20200917170315063\" /><figcaption aria-hidden=\"true\">image-20200917170315063</figcaption>\r\n</figure>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<p>这篇文章与以往大多数超分不一样，它产生的是一个HR图片的分布，而不是单张图片。让我第一次了解到了标准化流的思想，收获很大。</p>\r\n<p>感觉这篇和那篇Invertible Image Rescaling有异曲同工的地方，都使用了一个可逆网络，都是把信息隐藏在一个隐变量中。不同的是，Invertible Image Rescaling是把图像缩小时的丢失的<strong>高频信息</strong>放在了z中；而本文所求得的\"HR图片分布\"中的不同样本却对应了同一种z分布，这反映了不同HR样本中的相同的低频内容，从某种意义上是把LR图像中的<strong>低频特征</strong>放在了z中。</p>\r\n<p>我觉得这篇文章很惊艳的部分在于，利用隐变量的标准化，把这个超分框架推广到了图像风格迁移、图像复原上面。其中\"寻找分布<span class=\"math inline\">\\(p_{\\mathbf{y} \\mid \\mathbf{x}}(\\mathbf{y} \\mid \\mathbf{x},\\mathbf{\\theta})\\)</span>中，与目标图像最接近的干净图片\"的思想，也非常亮眼。</p>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Unfolding the Alternating Optimization for Blind Super Resolution","url":"/2020/10/23/2020-10-16-Unfolding%20the%20Alternating%20Optimization%20for%20Blind%20Super%20Resolution/","content":"<h3 id=\"论文背景\">论文背景</h3>\r\n<p>对于一般的盲超分方法，一般都分为两步：</p>\r\n<ol type=\"1\">\r\n<li>从LR图像中估计一个模糊核</li>\r\n<li>基于估计的模糊核，估计SR图像</li>\r\n</ol>\r\n<ul>\r\n<li>这两步通常是使用两个不同的模型（各自独立训练出来的）。而第一步的微小误差会给第二步的超分结果造成很大的损失。</li>\r\n<li>第一步只是通过LR中的信息去估计模糊核，信息来源比较有限，模糊核估计的不准</li>\r\n</ul>\r\n<p>因此，虽然这两个模型各自都能表现良好，但当它们组合在一起时，最终结果可能不是最优的。作者的思路是用一个交替迭代的优化算法。Restorer基于给定的模糊核，把LR图像超分辨为SR图像；而Estimator从LR、SR中估计模糊核，如此循环往复即可迭代。然后把这个网络展开，形成一个端到端的可训练的网络，作者称为DAN(Deep Alternating Network)。</p>\r\n<p>这样，从LR和SR中，估计模糊核更合理一些。更重要的是，在展开网络之后，相当于Restorer是使用Estimator生成的核做训练，而不是ground-truth的核。所以Restorer更能容忍Estimator的估计误差。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<h4 id=\"问题抽象\">问题抽象</h4>\r\n<p>盲超分的过程可以形式化为： <span class=\"math display\">\\[\r\n\\underset{\\mathbf{k}, \\mathbf{x}}{\\arg \\min }\\left\\|\\mathbf{y}-(\\mathbf{x} \\otimes \\mathbf{k}) \\downarrow_{s}\\right\\|_{1}+\\phi(\\mathbf{x})\r\n\\]</span></p>\r\n<p>而对于以往的“两步”盲超分，其实质上是解以下优化过程： <span class=\"math display\">\\[\r\n\\left\\{\\begin{array}{l}\r\n\\mathbf{k}=M(\\mathbf{y}) \\\\\r\n\\mathbf{x}=\\underset{\\mathbf{x}}{\\arg \\min }\\left\\|\\mathbf{y}-(\\mathbf{x} \\otimes \\mathbf{k}) \\downarrow_{s}\\right\\|_{1}+\\phi(\\mathbf{x})\r\n\\end{array}\\right.\r\n\\]</span> 而本文的迭代过程，其实为： <span class=\"math display\">\\[\r\n\\left\\{\\begin{array}{l}\r\n\\mathbf{k}_{i+1}=\\underset{\\mathbf{k}}{\\arg \\min }\\left\\|\\mathbf{y}-\\left(\\mathbf{x}_{i} \\otimes \\mathbf{k}\\right) \\downarrow_{s}\\right\\|_{1} \\\\\r\n\\mathbf{x}_{i+1}=\\underset{\\mathbf{x}}{\\arg \\min }\\left\\|\\mathbf{y}-\\left(\\mathbf{x} \\otimes \\mathbf{k}_{i}\\right) \\downarrow_{s}\\right\\|_{1}+\\phi(\\mathbf{x})\r\n\\end{array}\\right.\r\n\\]</span> 第一行为Estimator的过程，第二行为Restorer的过程。其实对于Estimator过程，k是存在解析解的，但是作者发现，解析解的计算更费时，而且微小的噪声将很大程度上影响其鲁棒性。</p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201027204727.png\" alt=\"image-20201018214857683\" /><figcaption aria-hidden=\"true\">image-20201018214857683</figcaption>\r\n</figure>\r\n<p>如图所示，先把模糊核k初始化为一个中心为1，其他都为0的狄拉克函数。然后将其重新排列为一个向量，接着使用PCA进行降维，输入到网络中。由于两个模块的参数在不同的迭代之间（迭代次数为4）是共享的，因此整个网络可以很好地训练，对中间结果没有任何限制。</p>\r\n<p>比较特别的是，当scale=1时，SAN就变成了一个去噪网络。</p>\r\n<h4 id=\"网络结构\">网络结构</h4>\r\n<p>Estimator的输入是LR+SR，Restorer的输入是LR+k。所以把LR看成基础输入，而SR或者模糊核看成条件输入。在迭代的时候，基础输入LR保持不变，而条件输入交替迭代更新。</p>\r\n<p>为了保证Estimator和Restorer的输出都和其条件输出相关，作者提出了一个条件残差块(CRB)，应用于Estimator和Restorer中：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201027204728.png\" alt=\"image-20201018222645162\" style=\"zoom: 67%;\" /></p>\r\n<p>形式化表述为： <span class=\"math display\">\\[\r\nf_{\\text {out}}=R\\left(\\text {Concat}\\left(\\left[f_{\\text {basic}}, f_{\\text {cond}}\\right]\\right)\\right)+f_{\\text {basic}}\r\n\\]</span> 进而Estimator和Restorer的结构如图：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201027204729.png\" alt=\"image-20201024092015011\" style=\"zoom:67%;\" /></p>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201027204730.png\" alt=\"image-20201025220633176\" style=\"zoom:67%;\" /><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201027204731.png\" alt=\"image-20201025220652067\" /></p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201027204731.png\" alt=\"image-20201025220652067\" /><figcaption aria-hidden=\"true\">image-20201025220652067</figcaption>\r\n</figure>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li>其实盲超分是一个“先有鸡还是先有蛋”的问题。一方面，需要知道模糊核，才能更好的把LR转换为HR(即已知模糊核，非盲超分)；而另一方面，要知道模糊核，则最好需要HR与对应的LR图像（只通过LR估计模糊核其实是信息不够的）。于是作者提出把这个“鸡生蛋、蛋生鸡”的问题一直迭代下去<del>（鸡生蛋生鸡生蛋生鸡生蛋……这样最后得到了更好的鸡和更好的蛋）</del>，把整个迭代过程展开为网络，从而端到端地训练。</li>\r\n<li>这篇文章乍一看和CVPR 2019的同为迭代方法的IKC很像，但是仔细分析也有很多的不同：\r\n<ul>\r\n<li>IKC分为三个模型，SFTMD模型用于k+LR--&gt;HR，Predictor用于LR--&gt;k，Corrector用于HR+k--&gt;∆k。训练过程中，<strong>SFTMD单独训练</strong>，而Predictor与Corrector迭代训练。正向推理过程中，Predictor只在最开始用到，而之后交替使用SFTMD与Corrector迭代。</li>\r\n<li>而本文只有两个模型，Restorer用于k+LR--&gt;HR，Estimator用于HR+LR--&gt;k，二者可以互相迭代。之所以少一个Predictor模型，是因为作者将k直接初始化为一个δ核。</li>\r\n<li>IKC的训练不是端到端的，而是在每个迭代中，都使用一次反向传播算法去更新参数；而本文的网络框架本质上和RNN的模型很像，训练过程是端到端的，只不过传播过程是循环的（即模型参数是共享的）。</li>\r\n<li>观察这两个工作，本质上SFTMD ≈ Restorer，而Predictor+Corrector≈Estimator （前者为IKC中的模块，后者为本文的模块）。从本篇文章的描述，对于Estimator来说，LR是basic input，HR是conditional input。如此倒过头来看IKC，似乎把Estimator拆分成只推理一次的Predictor和不断矫正的Corrector是有一定道理的（LR作为basic input只需输入一次，而HR作为不断变化的conditional input需要不断迭代矫正）。</li>\r\n<li>IKC的训练过程，每次迭代都是要使Corrector尽可能将k矫正到ground-truth。而本文的端到端的训练过程，每一次迭代并不一定要使Estimator估计出ground-truth，而最终能估计出ground-truth即可。</li>\r\n</ul></li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读综述：Deep Learning for Image Super-resolution：A Survey","url":"/2020/08/28/2020-08-28-Deep%20Learning%20for%20Image%20Super-resolution%EF%BC%9AA%20Survey/","content":"<p>从入组到现在，读了十余篇SR相关的最新论文了，但是感觉自己对整个SR问题还没有一个特别清晰的脉络，特别是在读一些论文的related work部分的时候感受尤为明显。于是这几周我找来的这篇2019年的SR综述来阅读，想借此全面地了解一下SR领域的工作，并挑一些经典工作深入理解。</p>\r\n<p>如题目所示，这篇论文就是一个领域综述，主要调研了基于深度学习的图像超分辨方法。作者把现有的方法归为三大类：有监督的SR、无监督的SR和特定领域的SR。另外总结了目前SR领域公开可用的基准数据集和性能评估指标。最后提出了未来的几个可能的SR方向和有待进一步解决的问题。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"问题定义与相关术语\">问题定义与相关术语</h3>\r\n<p>整个综述的结构如图：</p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200827205612.png\" alt=\"image-20200827205612235\" /><figcaption aria-hidden=\"true\">image-20200827205612235</figcaption>\r\n</figure>\r\n<h4 id=\"问题定义\">问题定义</h4>\r\n<p>LR图像都是由对应的HR图像由某个退化过程得到的： <span class=\"math display\">\\[\r\nI_x=\\mathcal {D}(I_y;\\delta)\r\n\\]</span> 其中<span class=\"math inline\">\\(I_x\\)</span>是LR图像，<span class=\"math inline\">\\(I_y\\)</span>是HR图像，<span class=\"math inline\">\\(\\delta\\)</span>是退化过程中的参数（比如放缩倍数、噪声等）。当<span class=\"math inline\">\\(\\mathcal D\\)</span>与<span class=\"math inline\">\\(\\delta\\)</span>都是未知的时候，就是盲SR(blind SR)，即从一个LR图像<span class=\"math inline\">\\(I_x\\)</span>去求一个对应HR图像<span class=\"math inline\">\\(I_y\\)</span>的估计值<span class=\"math inline\">\\(\\hat I_y\\)</span>： <span class=\"math display\">\\[\r\n\\hat I_y = \\mathcal F(I_x;\\theta)\r\n\\]</span> <span class=\"math inline\">\\(\\mathcal F\\)</span>是SR模型，<span class=\"math inline\">\\(\\theta\\)</span>是<span class=\"math inline\">\\(\\mathcal F\\)</span>的参数。</p>\r\n<p>退化过程是未知的，并且可能被很多因素影响，比如图像压缩时产生的伪影(artifacts)、各向异性退化(anisotropic degradations)、传感器噪声、斑点噪声(speckle noise)等。</p>\r\n<p>但是研究者们都尝试去给退化过程建一个特定的模型。大多数的工作都是使用一个简单的下采样的操作作为退化模型： <span class=\"math display\">\\[\r\n\\mathcal D(I_y;\\delta)=(I_y){\\downarrow_s},{s}\\subset\\delta\r\n\\]</span> 其中<span class=\"math inline\">\\(\\downarrow_s\\)</span>是使用缩放因子s的下采样。<strong>大多数的SR数据集都是按照这种模式建立的。</strong>而常用的下采样操作是抗锯齿的双三次插值(bicubic interpolation with antialiasing)。但是也有工作(<a href=\"https://arxiv.org/pdf/1712.06116.pdf\" target=\"_blank\" rel=\"noopener\">SRMD</a>)是使用另外的退化模型： <span class=\"math display\">\\[\r\n\\mathcal D(I_y;\\delta)=(I_y \\otimes \\kappa)\\downarrow_s+n_\\varsigma,\\{\\kappa,s,\\varsigma\\}\\subset\\delta\r\n\\]</span></p>\r\n<p><span class=\"math inline\">\\(\\kappa\\)</span>是模糊核(blur kernel)，<span class=\"math inline\">\\(n_\\varsigma\\)</span>是一个标准差为<span class=\"math inline\">\\(\\varsigma\\)</span>的高斯噪声。这种退化模型更接近于真实世界的情况。</p>\r\n<p>最后，SR模型的优化目标如下： <span class=\"math display\">\\[\r\n\\hat\\theta = \\mathop {\\arg \\min}_{\\theta} \\mathcal L(\\hat I_y,I_y)+\\lambda\\Phi(\\theta)\r\n\\]</span> 其中，<span class=\"math inline\">\\(\\mathcal L(\\hat I_y,I_y)\\)</span>代表生成的HR图像与GT(ground-truth)图像<span class=\"math inline\">\\(I_y\\)</span>的损失函数。<span class=\"math inline\">\\(\\Phi(\\theta)\\)</span>是正则项，<span class=\"math inline\">\\(\\lambda\\)</span>是trade-off参数。</p>\r\n<h4 id=\"sr的相关数据集\">SR的相关数据集</h4>\r\n<p>各种数据集的不同主要体现在图像数量、质量、分辨率、多样性等。有的提供LR-HR图像对，有的只提供HR图像（在这种情况下，LR图像通常通过MATLAB中的imresize函数的默认设置(即，抗走样的双三次插值)获得）。</p>\r\n<p>作者总结了常用的SR图像数据集如下表，主要体现了图像数量、平均分辨率、平均像素数、图像格式、图像类别的关键词。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200827210011.png\" alt=\"image-20200827210011863\" style=\"zoom:67%;\" /></p>\r\n<h4 id=\"图像的质量评价标准image-quality-assessment-iqa\">图像的质量评价标准(Image Quality Assessment, IQA)</h4>\r\n<p>图像的质量评价标准主要分为两大类：基于人类感知的主观方法、客观的计算方法。前者非常耗时比起昂贵，所以后者成为主流。但是这两类方法并不总是一致的，因为客观的方法往往不能很准确地捕捉到人类的视觉感知，这可能会导致IQA结果存在较大差异。基于客观计算的方法又分为了三类：</p>\r\n<ul>\r\n<li>基于人类感知的主观方法</li>\r\n<li>客观的计算方法\r\n<ul>\r\n<li>使用参考图像进行评估的全参考方法(full-reference methods)</li>\r\n<li>基于提取特征比较的约简参考方法(reduced-reference methods)</li>\r\n<li>无参考图像的无参考方法(no-reference methods)，即盲IQA</li>\r\n</ul></li>\r\n</ul>\r\n<h5 id=\"峰值信噪比peak-signal-to-noise-ratio-psnr\">峰值信噪比(Peak Signal-to-Noise Ratio, PSNR)</h5>\r\n<p>峰值信噪比(PSNR)是有损变换中最常用的重构质量测量方法之一。对于图像超分辨率来说，PSNR由最大像素值(记作<span class=\"math inline\">\\(L\\)</span>)和图像间的均方误差(mean squared error, MSE)定义。给定<span class=\"math inline\">\\(N\\)</span>个像素的图像<span class=\"math inline\">\\(I\\)</span>，重构图像的<span class=\"math inline\">\\(\\hat I\\)</span>的PSNR定义如下： <span class=\"math display\">\\[\r\n{PSNR} = 10\\cdot \\log_{10}(\\frac{L^2}{\\frac 1 N \\sum^N_{i=1}(I(i)-\\hat I(i))^2})\r\n\\]</span> 在8-bit的灰度图像中，<span class=\"math inline\">\\(L=255\\)</span>。由于PSNR只与像素级的MSE有关，往往会导致在真实场景中重建质量表现不佳，而在真实场景中我们通常更关心人的感知。然而，由于缺乏完全准确的感知度量，且一般提出的方法都需要与其他文献进行比较，所以PSNR仍是目前SR模型使用最广泛的评价标准</p>\r\n<h5 id=\"结构相似性structural-similarity-ssim\">结构相似性(Structural Similarity, SSIM)</h5>\r\n<p>SSIM是根据人类视觉系统(Human Vision System, HVS)提取图片结构的特点设计的，它基于亮度(luminance)、对比度(contrast)、结构(structures)三者的独立比较。</p>\r\n<p>对于<span class=\"math inline\">\\(N\\)</span>个像素的图像<span class=\"math inline\">\\(I\\)</span>，亮度<span class=\"math inline\">\\(\\mu_I\\)</span>是像素值的均值，对比度<span class=\"math inline\">\\(\\sigma_I\\)</span>是像素值的标准差。定义亮度、对比度的独立比较如下： <span class=\"math display\">\\[\r\n\\mathcal C_l(I,\\hat I)=\\frac {2\\mu_I\\mu_{\\hat I} + C_1} {\\mu_I^2+\\mu_{\\hat I}^2+C_1}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\mathcal C_c(I,\\hat I)=\\frac {2\\sigma_I\\sigma_{\\hat I} + C_1} {\\sigma_I^2+\\sigma_{\\hat I}^2+C_1}\r\n\\]</span></p>\r\n<p>其中，<span class=\"math inline\">\\(C_1=(k_1L)^2,\\ C_2=(k_2L)^2,\\ k1\\ll 1,\\ k2\\ll1\\)</span>。</p>\r\n<p>结构的独立比较定义如下： <span class=\"math display\">\\[\r\n\\sigma_{I\\hat I}=\\frac 1 {N-1}\\sum_{i=1}^N{(I(i)-\\mu_I)(\\hat I(i)-\\mu_{\\hat I})}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\mathcal C_s(I,\\hat I)=\\frac {\\sigma_{I\\hat I}+C_3}{\\sigma_I\\sigma_{\\hat I} + C_3}\r\n\\]</span></p>\r\n<p>最后的SSIM定义如下： <span class=\"math display\">\\[\r\n{ SSIM}(I,\\hat I)=[\\mathcal C_l(I,\\hat I)]^\\alpha[\\mathcal C_c(I,\\hat I)]^\\beta[\\mathcal C_s(I,\\hat I)]^\\gamma\r\n\\]</span> 于SSIM是从HVS的角度来评价重建质量，因此较好地满足了感知评估的要求，也得到了广泛的应用。</p>\r\n<h5 id=\"平均意见得分mean-opinion-score-mos\">平均意见得分（Mean Opinion Score, MOS）</h5>\r\n<p>在这种方法中，人类评分者被要求给被测试图像分配感知质量分数。通常，分数是1(差)到5(好)。最后的MOS是计算所有评级的算术平均值。</p>\r\n<h5 id=\"基于学习的感知质量\">基于学习的感知质量</h5>\r\n<p>研究者们尝试通过在大数据集上学习来评估感知质量 。比如Ma和Talebi分别提出了无参考的评价方法Ma和NIMA，它们根据视觉感知分数直接预测质量分数，而不考虑地面真实图像。Zhang收集了一个大规模的感知相似度数据集，通过训练过的深度网络，根据深度特征的差异对感知图像patch相似度(LPIPS)进行评估，通过CNNs学习到的深度特征对感知相似度的模型要比不使用CNNs的测度好得多。</p>\r\n<p>虽然这些方法在捕捉人眼视觉感知方面表现出了更好的表现，但是<strong>需要什么样的感知质量(例如更真实的图像，或者与原始图像的一致性)仍然是一个有待探索的问题，</strong>因此客观的IQA方法(例如PSNR, SSIM)仍然是目前的主流。</p>\r\n<h5 id=\"基于任务的评估\">基于任务的评估</h5>\r\n<p>由于SR模型总是可以用来帮助其他视觉任务，所以通过其他任务来评估重建效果也是一种有效方法。具体说就是，研究人员分别把原始的图像、重构的HR图像喂给某个任务的已训练好的模型，通过比较结果的性能来评估重构的质量。常用的任务由目标检测、面部识别、面部对齐与解析等。</p>\r\n<h5 id=\"其他的iqa方法\">其他的IQA方法</h5>\r\n<ul>\r\n<li>多尺度结构相似性(MS-SSIM)考虑到观察条件的变化，提供了比单一尺度结构相似性规模更大的灵活性。</li>\r\n<li>特征相似度(FSIM)基于相位一致性和图像梯度大小提取人类感兴趣的特征点来评价图像质量。</li>\r\n<li>自然图像质量评估器(NIQE)利用在自然图像中观察到的统计规律的可测量偏差</li>\r\n</ul>\r\n<p><strong>CVPR 2018的一篇工作(<a href=\"https://arxiv.org/pdf/1711.06077\" target=\"_blank\" rel=\"noopener\">The Perception-Distortion Tradeoff</a>)用数学方法证明了这种数值特征(如PSNR、SSIM)和感知质量(如MOS)是彼此不一致的（即不可兼得）。</strong>因此，如何准确地测量SR质量仍然是一个迫切需要解决的问题。</p>\r\n<h4 id=\"sr的操作通道operating-channels\">SR的操作通道(Operating Channels)</h4>\r\n<ul>\r\n<li>常用的RGB色彩空间</li>\r\n<li>YCbCr颜色空间：Y、Cb、Cr通道分别表示亮度、蓝差和红差色度分量</li>\r\n</ul>\r\n<p>早期的工作经常使用前者，而近年的工作一般对后者操作。值得注意的是，对不同的颜色空间或通道进行操作(训练或评估)会使评估结果差异很大(有时候甚至高达4 dB)</p>\r\n<h4 id=\"sr问题中的两个最大的挑战\">SR问题中的两个最大的挑战</h4>\r\n<h5 id=\"ntirethe-new-trends-in-image-restoration-and-enhancement\">NTIRE(The New Trends in Image Restoration and Enhancement)</h5>\r\n<p>NTIRE一般是CVPR的热点（？），包括了SR、去噪、着色等多个任务。对于SR来说，NTIRE挑战体现在DIV2K数据集上，因为DIV2K数据集由双三次下采样和具有实际未知退化的下采样组成，NTIRE挑战的实质即是<strong>在理想的条件和现实的不利情况下的SR研究。</strong></p>\r\n<h5 id=\"pirmthe-perceptual-image-restoration-and-manipulation\">PIRM(The Perceptual Image Restoration and Manipulation)</h5>\r\n<p>PIRM一般是ECCV的热点（？）。PIRM的<strong>一个子挑战是生成精度和感知质量平衡</strong>；另一个是<strong>智能手机的SR</strong>。</p>\r\n<p>(<a href=\"https://arxiv.org/pdf/1711.06077\" target=\"_blank\" rel=\"noopener\">The Perception-Distortion Tradeoff</a>)证明了，以失真为目标的模型经常会产生视觉上欠佳的结果，而以感知质量为目标的模型在信息保真度方面表现较差，下面是这篇工作的一副插图：</p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200828222502.png\" alt=\"image-20200828222501977\" /><figcaption aria-hidden=\"true\">image-20200828222501977</figcaption>\r\n</figure>\r\n<p>在另一个子挑战，智能手机上的SR中，参与者被要求在有限的智能手机硬件上进行SR(包括CPU、GPU、RAM等)，评估指标包括PSNR、MS-SSIM、MOS测试。</p>\r\n<h3 id=\"有监督的sr\">有监督的SR</h3>\r\n<p>有监督的SR，即：<strong>可使用LR与其对应的HR图像进行训练</strong>。虽然有监督SR模型各不相同，但它们本质上都是一些组件的组合，比如模型框架、上采样方法、网络设计、学习策略等。下文中作者对于每种组件进行了集中的总结。</p>\r\n<h4 id=\"sr框架\">SR框架</h4>\r\n<p>对于SR这个病态问题，如何体现上采样过程是一个关键问题。作者根据上采样操作的位置，把SR框架分为了四类。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200828225054.png\" alt=\"image-20200828225053739\" style=\"zoom:67%;\" /></p>\r\n<h5 id=\"预上采样pre-upsampling\">预上采样(Pre-upsampling)</h5>\r\n<p>由于学一个从低维空间(像素少的LR图像)到一个高维空间(像素多的HR图像)的映射比较困难，预上采样框架先使用传统的上采样算法获得HR图像，再使用深度网络将其改进。比如最早的SRCNN就是使用这种框架。</p>\r\n<p>由于最复杂的上采样操作已经完成了，CNN只需要细化粗糙的图像，这就显著的减小了学习的难度。此外，该模型可以将任意尺寸和缩放因子的插值图像作为输入，得到与单尺度SR性能相当的结果。</p>\r\n<p>然而，预先定义的上采样通常会引入副作用(例如，噪声放大和模糊)，而且由于大多数操作都是在高维空间中执行的，时间和空间成本要比其他框架高得多。</p>\r\n<h5 id=\"后上采样post-upsampling\">后上采样(Post-upsampling)</h5>\r\n<p>为了提高计算效率，充分利用深度学习技术自动提高分辨率，研究者提出<strong>将预先定义的上采样替换为在模型末端集成的端到端可学习的层，在低维空间中进行大部分计算。</strong>比如最早使用这种框架的有<a href=\"https://arxiv.org/pdf/1608.00367\" target=\"_blank\" rel=\"noopener\">FSRCNN</a>(使用转置卷积)、<a href=\"https://arxiv.org/pdf/1609.05158\" target=\"_blank\" rel=\"noopener\">ESPCN</a>(亚像素卷积)。</p>\r\n<p>由于计算量大的特征提取过程只发生在低维空间，直到网络末尾分辨率才会提高，这使得计算量和空间复杂度大大降低。所以近年很多工作都是采用这种框架，比如<a href=\"https://arxiv.org/pdf/1609.04802\" target=\"_blank\" rel=\"noopener\">SRGAN</a>、<a href=\"https://arxiv.org/pdf/1707.02921\" target=\"_blank\" rel=\"noopener\">EDSR</a>、<a href=\"https://openaccess.thecvf.com/content_ICCV_2017/papers/Tong_Image_Super-Resolution_Using_ICCV_2017_paper.pdf\" target=\"_blank\" rel=\"noopener\">SRDenseNet</a>、<a href=\"https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/3225.pdf\" target=\"_blank\" rel=\"noopener\">DSRN</a>等。</p>\r\n<h5 id=\"逐步上采样progressive-upsampling\">逐步上采样(Progressive Upsampling)</h5>\r\n<p>虽然Post-upsampling的SR框架极大地降低了计算量，但仍存在一些不足：一方面，上采样只进行了一步，大大增加了大尺度因子(如4、8)的学习难度；另一方面，每个比例因子都需要训练一个单独的SR模型，不能满足多尺度SR的需求。为了解决这些缺点，<a href=\"http://vision.ai.illinois.edu/publications/Deep%20Laplacian%20Pyramid%20Networks%20for%20Fast%20and%20Accurate%20Super-Resolution.pdf\" target=\"_blank\" rel=\"noopener\">LapSRN</a>首先采用了<strong>逐步上采样框架</strong>。具体来说，该框架下就是基于<strong>串联的</strong>CNN，逐步重构出更高分辨率的图像。其余的还有<a href=\"https://arxiv.org/pdf/1710.01992\" target=\"_blank\" rel=\"noopener\">MS-LapSRN</a>、<a href=\"https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Wang_A_Fully_Progressive_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">ProSR</a>。</p>\r\n<p>通过把一个复杂的任务分解成简单的任务，这类框架<strong>在不引入过多的空间和时间成本的前提下，大大减小了大尺度、多尺度的学习难度</strong>。此外，有一些特别的学习策略被应用在这个框架中，比如curriculum learning、multi-supervision，进一步降低学习难度，提高最终的性能。</p>\r\n<p>但这些模型也存在着多阶段模型设计复杂、训练稳定性差等问题，需要更多的建模指导和更高级的训练策略。</p>\r\n<h5 id=\"迭代的上-下采样\">迭代的上-下采样</h5>\r\n<p>迭代的上采样是为了更好地捕捉<em>LR-HR对</em>的相互依赖性，首先在CVPR 2016的<a href=\"https://arxiv.org/pdf/1511.02228\" target=\"_blank\" rel=\"noopener\">Seven ways to improve example-based single image super resolution</a>这篇工作中首先提出把反向投影(back-projection)引入到SR中，即迭代的计算重构误差，再将其融合回网络的开始，继续调整后续的HR图像。</p>\r\n<p><a href=\"https://openaccess.thecvf.com/content_cvpr_2018/papers/Haris_Deep_Back-Projection_Networks_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">DBPN</a>采用的就是这种框架，即交替连接上采样层和下采样层，利用所有中间重构结果去重构最终的HR结果。<a href=\"https://arxiv.org/pdf/1903.09814\" target=\"_blank\" rel=\"noopener\">SRFBN</a>采用了一个具有更密集skip连接的迭代上-下采样反馈块；视频超分辨率的一篇工作<a href=\"https://openaccess.thecvf.com/content_CVPR_2019/papers/Haris_Recurrent_Back-Projection_Network_for_Video_Super-Resolution_CVPR_2019_paper.pdf\" target=\"_blank\" rel=\"noopener\">RBPN</a>从连续视频帧中提取上下文，并通过反向投影模块将这些上下文组合起来。</p>\r\n<p><strong>此框架可以更好地挖掘LR-HR图像对之间的深层关系，从而提供更高质量的重建结果。</strong>然而，反向投影模块的设计标准尚不明确。由于该机制刚刚被引入到基于深度学习的SR中，<strong>因此该框架具有巨大的潜力，需要进一步探索。</strong></p>\r\n<h4 id=\"各类上采样方法\">各类上采样方法</h4>\r\n<p>作者介绍了一些传统的基于插值的算法和基于深度学习的上采样层。</p>\r\n<h5 id=\"基于插值的上采样\">基于插值的上采样</h5>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829005324.png\" alt=\"image-20200829005323923\" style=\"zoom:67%;\" /></p>\r\n<ul>\r\n<li>最近邻插值</li>\r\n<li>双线性插值</li>\r\n<li>双三次插值</li>\r\n</ul>\r\n<p><strong>基于插值的上采样方法仅根据自身的图像信号来提高图像分辨率，而不提供其他额外的任何信息。所以它们经常引入一些副作用，如计算复杂度、噪声放大、结果模糊等。</strong>因此，目前的趋势是用可学习的上采样层代替基于插值的方法。</p>\r\n<h5 id=\"基于学习的上采样\">基于学习的上采样</h5>\r\n<ul>\r\n<li>转置卷积层(Transposed Convolution Layer)\r\n<ul>\r\n<li><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829005823.png\" alt=\"image-20200829005823015\" style=\"zoom: 67%;\" /></li>\r\n<li>转置卷积在保持与普通卷积兼容的连通性模式的同时，以端到端的方式增大了图像的大小</li>\r\n<li>使用这种上采样方式的工作：<a href=\"https://openaccess.thecvf.com/content_ICCV_2017/papers/Tong_Image_Super-Resolution_Using_ICCV_2017_paper.pdf\" target=\"_blank\" rel=\"noopener\">SRDenseNet</a>、<a href=\"https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/3225.pdf\" target=\"_blank\" rel=\"noopener\">DSRN</a>、<a href=\"https://openaccess.thecvf.com/content_cvpr_2018/papers/Haris_Deep_Back-Projection_Networks_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">DBPN</a></li>\r\n<li>然而，这一层很容易导致每个轴上的“不均匀重叠”(？)。</li>\r\n</ul></li>\r\n<li>亚像素层(Sub-pixel Layer)\r\n<ul>\r\n<li><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829085616.png\" alt=\"image-20200829085556128\" style=\"zoom: 67%;\" /></li>\r\n<li>使用这种上采样方式的工作：<a href=\"https://arxiv.org/pdf/1609.04802\" target=\"_blank\" rel=\"noopener\">SRGAN</a>、<a href=\"https://arxiv.org/pdf/1803.08664\" target=\"_blank\" rel=\"noopener\">CARN</a>、<a href=\"https://arxiv.org/pdf/1712.06116\" target=\"_blank\" rel=\"noopener\">SRMD</a>、<a href=\"https://arxiv.org/pdf/1802.08797\" target=\"_blank\" rel=\"noopener\">RDN</a></li>\r\n<li>与转置卷积相比，亚像素层具有<strong>更大的感受野</strong>，进而提供了更多的上下文信息，帮助生成更真实的细节。</li>\r\n<li>然而，由于感受野的分布不平坦（？）并且每个block(上图的1234)<strong>共享同一个感受野</strong>，所以在每个block之间会有artifact；另外，在同一个block中，<strong>独立地</strong>计算相邻像素，会导致输出不平滑。</li>\r\n<li>所以Gao在<a href=\"https://openreview.net/pdf?id=B1spAqUp-\" target=\"_blank\" rel=\"noopener\">Pixel transposed convolutional networks</a>中提出了PixelTCL，将同一个block中各个像素的独立预测改为相互依赖的顺序预测，得到更平滑、更一致的结果。</li>\r\n</ul></li>\r\n<li>Meta Upscale 模块\r\n<ul>\r\n<li><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829092835.png\" alt=\"image-20200829092835100\" style=\"zoom: 67%;\" /></li>\r\n<li>由于之前的两种上采样都需要预先设定放大因子(为不同的因子训练不同的上采样模型)，于是<a href=\"https://arxiv.org/pdf/1903.00875\" target=\"_blank\" rel=\"noopener\">Meta-SR</a>提出了Meta Upscale模块，利用元学习解决了任意因子的SR</li>\r\n<li>但是，该方法基于几个独立于图像内容的值（？），对每个目标像素预测了大量的卷积权值，因此在面对较大的放大时，预测结果可能不稳定，效率较低</li>\r\n</ul></li>\r\n</ul>\r\n<h4 id=\"网络设计\">网络设计</h4>\r\n<h5 id=\"残差学习residual-learning\">残差学习(Residual Learning)</h5>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829094141.png\" alt=\"image-20200829094141729\" style=\"zoom:67%;\" /></p>\r\n<p>分为以下两类：</p>\r\n<ul>\r\n<li>全局残差学习\r\n<ul>\r\n<li>由于SR本质上是一个“图像”到“图像”的转换过程，LR图像和HR图像是高度相关的，所以研究者们想只学一个他们之间的残差。由于大部分区域的残差接近于零，大大降低了模型的复杂性和学习难度。</li>\r\n</ul></li>\r\n<li>局部残差学习\r\n<ul>\r\n<li>这和何凯明原始的ResNet中很像，用于缓解网络深度不断增加带来的梯度消失问题</li>\r\n</ul></li>\r\n</ul>\r\n<h5 id=\"递归学习recursive-learning\">递归学习(Recursive Learning)</h5>\r\n<p>即递归地使用同样的模块多次，从而<strong>在学到更高级的特征的同时不引入过多的参数</strong>：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829102024.png\" alt=\"image-20200829102024267\" style=\"zoom:67%;\" /></p>\r\n<p>例子：<a href=\"https://arxiv.org/pdf/1501.00092.pdf\" target=\"_blank\" rel=\"noopener\">DRCN</a>、<a href=\"https://openaccess.thecvf.com/content_cvpr_2017/papers/Tai_Image_Super-Resolution_via_CVPR_2017_paper.pdf\" target=\"_blank\" rel=\"noopener\">DRRN</a>、<a href=\"https://arxiv.org/pdf/1708.02209\" target=\"_blank\" rel=\"noopener\">MemNet</a>、<a href=\"https://arxiv.org/pdf/1803.08664\" target=\"_blank\" rel=\"noopener\">CARN</a>、<a href=\"https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Feedback_Network_for_Image_Super-Resolution_CVPR_2019_paper.pdf\" target=\"_blank\" rel=\"noopener\">SRFBN</a>、<a href=\"https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/3225.pdf\" target=\"_blank\" rel=\"noopener\">DSRN</a>、<a href=\"https://arxiv.org/pdf/1710.01992\" target=\"_blank\" rel=\"noopener\">MS-LapSRN</a></p>\r\n<p>但递归学习仍然不能避免高昂的计算成本，一定程度上造成了梯度爆炸/消失，因此残差学习和多监督(multi-supervision)经常和递归学习一起使用。</p>\r\n<h5 id=\"多路径学习multi-path-learning\">多路径学习(Multi-path Learning)</h5>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829103458.png\" alt=\"image-20200829103458501\" style=\"zoom:67%;\" /></p>\r\n<p>多路径学习利用多条路径提取特征，然后融合起来，从而<strong>获得更好的模型容量</strong>。多路径学习可以分为以下：</p>\r\n<ul>\r\n<li>全局多路径学习(Global Multi-path Learning)\r\n<ul>\r\n<li>使用多条路径去提取<strong>图像不同方面的特征</strong></li>\r\n<li>在传播过程中可以相互交叉，从而极大地提高学习能力</li>\r\n</ul></li>\r\n<li>局部多路径学习(Local Multi-path Learning)\r\n<ul>\r\n<li>是从inception模块中产生的启发，在<a href=\"https://openaccess.thecvf.com/content_ECCV_2018/papers/Juncheng_Li_Multi-scale_Residual_Network_ECCV_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">MSRN</a>中首先使用</li>\r\n<li>不同的路径使用concat操作连接起来，最后加个额外的1x1卷积</li>\r\n<li>能较好地从<strong>多个尺度提取图像特征</strong></li>\r\n</ul></li>\r\n<li>特定尺度的多路径学习(Scale-specific Multi-path Learning)\r\n<ul>\r\n<li>代表工作是<a href=\"https://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Lim_Enhanced_Deep_Residual_CVPR_2017_paper.pdf\" target=\"_blank\" rel=\"noopener\">EDSR</a>，多条路径共享了模型的主要部件（比如特征提取），但<strong>分别在网络的开始和结束附加特定尺度的预处理路径和上采样路径</strong>。在训练过程中，只启用和更新与选择尺度相对应的路径。</li>\r\n<li><a href=\"https://arxiv.org/pdf/1803.08664\" target=\"_blank\" rel=\"noopener\">CARN</a>和<a href=\"https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Wang_A_Fully_Progressive_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">ProSR</a>也采用了类似的特定尺度的多路径学习</li>\r\n</ul></li>\r\n</ul>\r\n<h5 id=\"稠密连接dense-connections\">稠密连接(Dense Connections)</h5>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829121543.png\" alt=\"image-20200829121543638\" style=\"zoom:67%;\" /></p>\r\n<ul>\r\n<li>融合低层和高层特征，为重构高质量细节提供更丰富的信息</li>\r\n<li><a href=\"https://openaccess.thecvf.com/content_ICCV_2017/papers/Tong_Image_Super-Resolution_Using_ICCV_2017_paper.pdf\" target=\"_blank\" rel=\"noopener\">SRDenseNet</a>、<a href=\"https://arxiv.org/pdf/1708.02209\" target=\"_blank\" rel=\"noopener\">MemNet</a>、<a href=\"https://arxiv.org/pdf/1803.08664\" target=\"_blank\" rel=\"noopener\">CARN</a>、<a href=\"https://arxiv.org/pdf/1802.08797\" target=\"_blank\" rel=\"noopener\">RDN</a>、<a href=\"https://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Wang_ESRGAN_Enhanced_Super-Resolution_Generative_Adversarial_Networks_ECCVW_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">ESRGAN</a>、<a href=\"https://openaccess.thecvf.com/content_cvpr_2018/papers/Haris_Deep_Back-Projection_Networks_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">DBPN</a></li>\r\n</ul>\r\n<h5 id=\"注意力机制attention-mechanism\">注意力机制(Attention Mechanism)</h5>\r\n<ul>\r\n<li>通道注意力机制(Channel Attention)\r\n<ul>\r\n<li><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829122502.png\" style=\"zoom: 80%;\" /></li>\r\n<li>考虑到不同通道间特征表征的相互依赖和相互作用，<a href=\"https://arxiv.org/pdf/1709.01507\" target=\"_blank\" rel=\"noopener\">SENet</a>首先提出了这种机制：使用全局平均池化(GAP)，每个输入通道被压缩到一个通道描述符(即一个常数)中，然后这些描述符被送入两个Dense层，产生输入通道的信道尺度因子</li>\r\n<li><a href=\"https://arxiv.org/pdf/1807.02758\" target=\"_blank\" rel=\"noopener\">RCAN</a>首次把通道注意力机制引入SR</li>\r\n<li><a href=\"https://www4.comp.polyu.edu.hk/~cslzhang/paper/CVPR19-SAN.pdf\" target=\"_blank\" rel=\"noopener\">SOCA</a>使用二阶特征统计量而不是全局平均池化，自适应地调整信道方向的特征</li>\r\n</ul></li>\r\n<li>非局部注意力机制(Non-local Attention)\r\n<ul>\r\n<li>现有的SR模型具有非常有限的局部感受野。然而，一些比较远的物体或纹理可能对局部patch的生成可能比较重要</li>\r\n<li><a href=\"https://arxiv.org/pdf/1903.10082\" target=\"_blank\" rel=\"noopener\">RNAN</a>首先提出这种机制，提出了一个提取特征的主干分支了，以及一个非局部/局部掩模分支，用于自适应地调整主干分支的特征。\r\n<ul>\r\n<li>非局部分支利用嵌入的高斯函数对特征图中每两个位置指标之间的成对关系进行评估，预测标度权重</li>\r\n<li>该方法很好地捕捉了空域注意力</li>\r\n</ul></li>\r\n<li><a href=\"https://www4.comp.polyu.edu.hk/~cslzhang/paper/CVPR19-SAN.pdf\" target=\"_blank\" rel=\"noopener\">SOCA</a>也引入了非局部注意机制</li>\r\n</ul></li>\r\n</ul>\r\n<h5 id=\"高级卷积\">高级卷积</h5>\r\n<ul>\r\n<li>空洞卷积(Dilated Convolution)\r\n<ul>\r\n<li><a href=\"https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Learning_Deep_CNN_CVPR_2017_paper.pdf\" target=\"_blank\" rel=\"noopener\">IRCNN</a>首先在CVPR 2017把空洞卷积引入SR模型，将感受野增加了两倍以上，获得了更好的表现</li>\r\n</ul></li>\r\n<li>分组卷积(Group Convolution)\r\n<ul>\r\n<li>分组卷积减少了参数和操作的数量，但损失了一点性能</li>\r\n</ul></li>\r\n<li>Depthwise Separable Convolution：\r\n<ul>\r\n<li><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829151640.png\" alt=\"image-20200829151639982\" style=\"zoom: 33%;\" /></li>\r\n<li><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829151701.png\" alt=\"image-20200829151701733\" style=\"zoom: 33%;\" /></li>\r\n<li>它由一个分解的深度卷积和一个点态卷积(即1x1卷积)组成，因此减少了大量的参数和操作</li>\r\n</ul></li>\r\n</ul>\r\n<h5 id=\"region-recursive-learning\">Region-recursive Learning</h5>\r\n<ul>\r\n<li>大多数SR模型将SR视为一个与像素无关的任务，因此无法正确地获取生成的像素之间的依赖关系。</li>\r\n<li>受到PixelCNN的启发，<a href=\"https://openaccess.thecvf.com/content_ICCV_2017/papers/Dahl_Pixel_Recursive_Super_ICCV_2017_paper.pdf\" target=\"_blank\" rel=\"noopener\">Pixel recursive super resolution</a>首先提出了像素递归学习来进行逐像素生成图片。它在非常低的像素面部图片SR中得到了很好的MOS结果。</li>\r\n<li><a href=\"https://arxiv.org/pdf/1708.03132\" target=\"_blank\" rel=\"noopener\">Attention-FH</a>也使用了循环策略网络(recurrent policy network)，按顺序地发现参与补丁，实现局部patch增强。这样就能够<strong>根据每幅图像自身的特点自适应地采用最优的搜索路径</strong>，从而充分利用图像的全局差异性。</li>\r\n<li>但由于递归过程需要较长的传播路径，大大增加了计算量和训练难度</li>\r\n</ul>\r\n<h5 id=\"金字塔池化\">金字塔池化</h5>\r\n<p>受何凯明的空间金字塔池化层的启发，Zhao提出了<a href=\"https://arxiv.org/pdf/1612.01105.pdf\" target=\"_blank\" rel=\"noopener\">金字塔池化模块(pyramid pooling module)</a>:</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829160126.png\" alt=\"image-20200829160126731\" style=\"zoom:67%;\" /></p>\r\n<p>有效地集成了全局和局部上下文信息。<a href=\"https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Park_Efficient_Module_Based_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">EDSR-PP</a>也利用了这种模块。</p>\r\n<h5 id=\"小波变换wavelet-transformation\">小波变换(Wavelet Transformation)</h5>\r\n<ul>\r\n<li>小波变换(WT)是一种高效的图像表示方法，将图像信号分解为表示纹理细节的高频子带和包含全局拓扑信息的低频子带。</li>\r\n<li>在2016年，<a href=\"https://arxiv.org/pdf/1611.06345\" target=\"_blank\" rel=\"noopener\">Beyond deep residual learning for image restoration: Persistent homology-guided manifold simplification</a>这篇工作首次把小波变换和深度学习结合在一起，应用到了SR模型中，以插值的LR小波子带为输入，预测相应HR子带的残差。</li>\r\n<li>在SR中，小波变换常用于分解LR图像；而小波逆变换常用于重构HR的过程</li>\r\n<li>由于小波变换的表示比较高效，在兼顾性能的同时，<strong>往往大大降低了模型的规模和计算量</strong>。</li>\r\n</ul>\r\n<h5 id=\"逆亚像素desubpixel\">逆亚像素(Desubpixel)</h5>\r\n<ul>\r\n<li>顾名思义，就是亚像素卷积层的逆过程</li>\r\n<li>Desubpixel对图像进行空间分割，将其作为额外的通道堆叠，从而避免了信息的丢失。</li>\r\n<li>通过这种方式，他们在模型的开始通过Desubpixel向下采样输入图像，学习低维空间的表示，并在最后向上采样到目标大小。</li>\r\n<li>这种方法的主要目的是提升推理速度，应用于智能手机等性能受限的场景。</li>\r\n</ul>\r\n<h5 id=\"xunit\">xUnit</h5>\r\n<p><a href=\"https://arxiv.org/pdf/1711.06445.pdf\" target=\"_blank\" rel=\"noopener\">xUnit</a>的本质是在每个卷积的激活函数处增加参数，相比于原来只是使用一个relu的没有参数的激活函数，其表现力更强大：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829162407.png\" alt=\"image-20200829162407019\" style=\"zoom:67%;\" /></p>\r\n<p>通过这种方式，作者在没有任何性能下降的情况下将模型大小减少了近50%。</p>\r\n<h4 id=\"学习策略\">学习策略</h4>\r\n<h5 id=\"损失函数\">损失函数</h5>\r\n<p>早期，研究者们总是用像素级别的L2损失，但后来发现这不能准确的衡量重构的质量，于是又提出了content loss、adversarial loss等</p>\r\n<ul>\r\n<li><p>像素损失(Pixel Loss)</p>\r\n<ul>\r\n<li><p>通常的L1、L2：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829162934.png\" alt=\"image-20200829162934038\" style=\"zoom: 67%;\" /></p></li>\r\n<li><p>Charbonnier损失：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829163058.png\" alt=\"image-20200829163058705\" style=\"zoom:67%;\" /></p></li>\r\n<li><p><strong>相较于L1损失，L2损失惩罚更大的误差，容忍较小的误差</strong>。实践表明L1 loss能得到更好的性能</p></li>\r\n<li><p>像素损失实际上并不影响图像质量(比如感知质量)，因此，结果往往缺乏高频细节，而且纹理经常过于光滑</p></li>\r\n</ul></li>\r\n<li><p>内容损失(Content Loss)</p>\r\n<ul>\r\n<li><p>使用一个预训练的图像分类网络来衡量：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829163552.png\" alt=\"image-20200829163552200\" style=\"zoom: 67%;\" /></p></li>\r\n<li><p>内容损失实质上是将从分类网络中学到的图像层次特征转移到了SR网络上</p></li>\r\n<li><p>VGG和ResNet最常用</p></li>\r\n</ul></li>\r\n<li><p>纹理损失(Texture Loss)</p>\r\n<ul>\r\n<li><p>重构的图像需要有相同的\"style\"（颜色、纹理、对比度）</p></li>\r\n<li><p>图像的“纹理”被视作<strong>不同特征通道的相关性</strong>，于是定义为格拉姆矩阵(Gram Matrix)<span class=\"math inline\">\\(G^{(l)} \\in \\R^{c_l\\times c_l}\\)</span>，<span class=\"math inline\">\\(G^{(l)}_{ij}\\)</span>定义为第<span class=\"math inline\">\\(l\\)</span>层中，被向量化的特征通道<span class=\"math inline\">\\(i\\)</span>和<span class=\"math inline\">\\(j\\)</span>的内积：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829164637.png\" alt=\"image-20200829164637262\" style=\"zoom:67%;\" /></p></li>\r\n<li><p>于是纹理损失定义为：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829164737.png\" alt=\"image-20200829164737450\" style=\"zoom:67%;\" /><br />\r\n</p>\r\n<p><strong>（下面这段我不是很理解，为什么突然冒出了patch size）</strong></p>\r\n<blockquote>\r\n<p>Despite this, determining the patch size to match textures is still empirical. Too small patches lead to artifacts in textured regions, while too large patches lead to artifacts throughout the entire image because texture statistics are averaged over regions of varying textures.</p>\r\n</blockquote></li>\r\n</ul></li>\r\n<li><p>对抗损失(Adversarial Loss)</p>\r\n<ul>\r\n<li><p>在SR领域，将SR模型作为生成器，再额外定义一个鉴别器来判断输入图像是否生成的。</p></li>\r\n<li><p><a href=\"https://arxiv.org/pdf/1609.04802\" target=\"_blank\" rel=\"noopener\">SRGAN</a>首先提出了如下的对抗损失函数：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829165723.png\" alt=\"image-20200829165723902\" style=\"zoom:67%;\" /></p>\r\n<p><span class=\"math inline\">\\(I_s\\)</span>是从ground-truth中随机采样的图像</p></li>\r\n<li><p><a href=\"https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Yuan_Unsupervised_Image_Super-Resolution_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">Unsupervised image super-resolution using cycle-in-cycle generative adversarial networks</a>利用基于最小二乘误差的对抗式损失可以使训练过程更稳定，结果质量更高:</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829170219.png\" alt=\"image-20200829170219251\" style=\"zoom:67%;\" /></p></li>\r\n<li><p><a href=\"https://faculty.ucmerced.edu/mhyang/papers/iccv2017_gan_super_deblur.pdf\" target=\"_blank\" rel=\"noopener\">Learning to Super-Resolve Blurry Face and Text Images</a>一文中使用了由一个生成器和多个类特定判别器组成的多类GAN</p></li>\r\n<li><p><a href=\"https://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Wang_ESRGAN_Enhanced_Super-Resolution_Generative_Adversarial_Networks_ECCVW_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">ESRGAN</a>采用<a href=\"https://arxiv.org/pdf/1807.00734\" target=\"_blank\" rel=\"noopener\">relativistic GAN</a>来预测真实图像比虚假图像更真实的概率，而不是输入图像真实或虚假的概率，从而恢复更详细的纹理。</p></li>\r\n<li><p>虽然对抗性损失和内容损失训练的SR模型的PSNR比损失像素训练的模型要低，但在<strong>感知质量上有显著的提高</strong>。</p></li>\r\n<li><p><strong>本质上说，判别器提取出了HR图像的一些很难学习到的隐含模式(latent patterns)，进而迫使生成器去适配这种模式</strong></p></li>\r\n<li><p>然而，目前GAN的训练过程仍然困难而且不稳定，如何确保整合到SR模型中的GANs得到正确的训练，仍然是一个待解决的问题</p></li>\r\n</ul></li>\r\n<li><p>循环一致损失(Cycle Consistency Loss)</p>\r\n<ul>\r\n<li><p><a href=\"https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Yuan_Unsupervised_Image_Super-Resolution_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">Unsupervised image super-resolution using cycle-in-cycle generative adversarial networks</a>这篇工作首先把CycleGAN应用到了SR领域</p></li>\r\n<li><p>不仅有LR-&gt;HR，也把HR重新下采样到LR。需要重新生成的LR图像与输入LR图像的相同，因此引入循环一致性损失：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829172252.png\" alt=\"image-20200829172252334\" style=\"zoom:67%;\" /></p></li>\r\n</ul></li>\r\n<li><p>TV损失(Total variation loss)</p>\r\n<ul>\r\n<li><p>目的是<strong>抑制生成图像中的噪声</strong></p></li>\r\n<li><p>定义为相邻像素之间的绝对差之和，用于测量图像中噪声的大小：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829172430.png\" alt=\"image-20200829172430778\" style=\"zoom:67%;\" /></p></li>\r\n</ul></li>\r\n<li><p>基于先验的损失(Prior-Based Loss)</p>\r\n<ul>\r\n<li>比如在脸部SR任务中，引入面部对齐网络(face alignment network, FAN)，作为先验与SR联合进行训练，从而提高了LR人脸对齐和人脸图像SR的性能。</li>\r\n<li>本质上，<strong>内容损失和纹理损失也都引入了一个图像分类网络，也是提供了图像层次特征的先验知识</strong></li>\r\n</ul></li>\r\n</ul>\r\n<p>在实际应用中，研究人员经常采用加权平均的方法将以上多个损失函数组合起来。<strong>然而，不同损失函数的权重需要大量的实证探索，如何合理有效地组合仍是一个问题。</strong></p>\r\n<h5 id=\"批标准化batch-normalization-bn\">批标准化(Batch Normalization, BN)</h5>\r\n<ul>\r\n<li>由于BN校准中间特征的分布，并且缓解了梯度消失现象，它允许使用更高的学习率和比较粗糙的初始化。因此该技术被广泛应用于SR模型</li>\r\n<li>然而，<a href=\"https://arxiv.org/pdf/1707.02921\" target=\"_blank\" rel=\"noopener\">Lim等人</a>认为BN丢失了每张图像的尺度信息，并且去掉了网络的范围灵活性。删除了BN并使用节省下来的内存成本(高达40%)来开发更大的模型，从而大幅提高了性能。</li>\r\n</ul>\r\n<h5 id=\"curriculum-learning\">Curriculum Learning(？)</h5>\r\n<ul>\r\n<li>Curriculum learning是指从较容易的任务开始，逐步增加难度。</li>\r\n<li>由于超分辨率是一个ill-posed问题，经常会遇到尺度因子大、噪声和模糊等不利条件，因此采用Curriculum learning来降低学习难度。</li>\r\n<li>例子：<a href=\"https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Wang_A_Fully_Progressive_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">ProSR</a>、<a href=\"https://arxiv.org/pdf/1805.03383.pdf\" target=\"_blank\" rel=\"noopener\">ADRSR</a>等</li>\r\n<li>与一般的训练程序相比，Curriculum learning大大降低了训练难度，缩短了总训练时间，特别是在scale factor较大的情况下。</li>\r\n</ul>\r\n<h5 id=\"多监督multi-supervision\">多监督(Multi-supervision)</h5>\r\n<ul>\r\n<li>多监督是指在模型中加入多个监督信号(？)，以增强梯度传播，避免梯度的消失和爆炸。</li>\r\n<li><a href=\"https://arxiv.org/pdf/1501.00092.pdf\" target=\"_blank\" rel=\"noopener\">DRCN</a>就使用了多监督来对抗递归学习的梯度问题\r\n<ul>\r\n<li>把每个递归单元的输出作为重建模块的输入，以生成HR图像，并通过<strong>合并所有中间重建</strong>来构建最终的预测。</li>\r\n<li>类似的还有<a href=\"https://arxiv.org/pdf/1708.02209\" target=\"_blank\" rel=\"noopener\">MemNet</a>、<a href=\"https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/3225.pdf\" target=\"_blank\" rel=\"noopener\">DSRN</a></li>\r\n</ul></li>\r\n<li>另外，对于<a href=\"http://vision.ai.illinois.edu/publications/Deep%20Laplacian%20Pyramid%20Networks%20for%20Fast%20and%20Accurate%20Super-Resolution.pdf\" target=\"_blank\" rel=\"noopener\">LapSRN</a>这种逐步上采样框架，传播过程中产生不同尺度的中间结果，也能采用多监督策略<strong>(即期望中间结果与从ground truth HR图像中下采样的中间图像相同)</strong></li>\r\n<li>在实践中，这种多监督技术通常通过在损失函数中添加一些项来实现，这样可以更有效地将监督信号反向传播，从而降低训练难度，增强模型训练。(？这里没有例子，不是很理解)</li>\r\n</ul>\r\n<h4 id=\"其他的一些提升\">其他的一些提升</h4>\r\n<p>除了网络设计和学习策略，还有其他技术可以进一步改进SR模型。</p>\r\n<h5 id=\"基于上下文的网络融合context-wise-network-fusion-cnf\">基于上下文的网络融合(Context-wise Network Fusion, CNF)</h5>\r\n<ul>\r\n<li>上下文感知网络融合(CNF)指的是一种叠加技术，将来自多个SR网络的预测进行融合（<strong>也可以看做上文中提到的多路径学习的一个特例</strong>）</li>\r\n<li>分别训练具有不同架构的单个SR模型，将每个模型的预测输入到单独的卷积层中，最后将输出相加，成为最终的预测结果。</li>\r\n</ul>\r\n<h5 id=\"数据增广data-augmentation\">数据增广(Data Augmentation)</h5>\r\n<p>裁剪、翻转、缩放、旋转、颜色抖动(cropping, flipping, scaling, rotation, color jittering)</p>\r\n<p>值得注意的是<a href=\"https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w13/Bei_New_Techniques_for_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">Bei的一篇工作</a>还使用了对RGB通道进行随机洗牌的数据增广方法。</p>\r\n<h5 id=\"多任务学习multi-task-learning\">多任务学习(Multi-task Learning)</h5>\r\n<ul>\r\n<li><p>多任务学习是指利用某些相关任务(比如如目标检测和语义分割、头部姿态估计和面部属性推断等任务)训练中包含的特定领域的信息，从而提高泛化能力</p></li>\r\n<li><p>比如在SR中，<a href=\"https://arxiv.org/pdf/1804.02815\" target=\"_blank\" rel=\"noopener\">SFTGAN</a>使用了一个语义分割网络，用于提供语义知识和生成语义特定细节。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829183906.png\" alt=\"image-20200829183905919\" style=\"zoom:67%;\" /></p>\r\n<ul>\r\n<li>加入了空域特征变换(Spatial Feature Transform, SFT)，以利用语义分割的结果</li>\r\n</ul></li>\r\n<li><p>考虑到直接超分辨有噪图像可能会导致噪声放大，<a href=\"https://arxiv.org/pdf/1805.03383\" target=\"_blank\" rel=\"noopener\">DNSR</a>提出分别训练去噪网络和SR网络，然后将其拼接并进行微调。</p></li>\r\n<li><p>将相关的任务与SR模型结合起来，通常可以通过提供额外的信息和知识来提高SR性能。</p></li>\r\n</ul>\r\n<h5 id=\"网络插值network-interpolation\">网络插值(Network Interpolation)</h5>\r\n<ul>\r\n<li><p>基于PSNR的模型产生的图像更接近地面事实，但引入了模糊问题；而基于GAN的模型带来了更好的感知质量，但引入了artifacts</p></li>\r\n<li><p>为了平衡失真和感知损失，Wang等[103]，<a href=\"http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Deep_Network_Interpolation_for_Continuous_Imagery_Effect_Transition_CVPR_2019_paper.pdf\" target=\"_blank\" rel=\"noopener\">DIN</a>提出了一种网络插值策略</p>\r\n<ul>\r\n<li>分别训练一个基于PSNR的模型和一个基于GAN的模型，然后对两个网络的所有相应参数进行插值，得到中间模型。</li>\r\n</ul></li>\r\n<li><p><strong>通过调整插值权值而无需对网络进行再训练。</strong></p></li>\r\n</ul>\r\n<h5 id=\"自集成self-ensemble\">自集成(Self-Ensemble)</h5>\r\n<ul>\r\n<li>自集成，又称增强预测</li>\r\n<li>在LR图像上加以不同角度(0,90,180,270)的旋转和水平翻转，得到一组8张图像。然后将这些图像输入到SR模型中，对重构后的HR图像进行相应的逆变换得到输出结果</li>\r\n<li>我的理解：数据增强是制造多个训练数据，而这些训练数据之间没有关系；而自集成是在训练、测试过程中均制造多个数据输入，且把这些数据整合起来(取平均、中值等)生成最终的结果</li>\r\n</ul>\r\n<h4 id=\"sota-sr模型有监督\">SOTA SR模型(有监督)</h4>\r\n<p>作者把截止19年的SOTA的有监督SR模型总结如下表：</p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200829185728.png\" alt=\"image-20200829185728350\" /><figcaption aria-hidden=\"true\">image-20200829185728350</figcaption>\r\n</figure>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20200902210034.png\" alt=\"image-20200902204945728\" /><figcaption aria-hidden=\"true\">image-20200902204945728</figcaption>\r\n</figure>\r\n<h3 id=\"无监督sr\">无监督SR</h3>\r\n<p>有监督SR都是使用LR-HR图片对进行学习的。然而，对于同一个场景，很难获取两个不同分辨率的图像（想象一下使用两个摄像机拍摄同一个场景的照片），所以SR数据集中的LR图像总是通过把HR图像经过预定的退化方法得到的。<strong>因此在这种情况下，SR模型实际上学到的只是预定好的退化模型的反向过程。</strong></p>\r\n<p>因此，为了不人工引入任何的退化先验，从而学到真实世界的LR-HR映射，即无监督的SR，也就是在训练过程中只提供不成对的LR-HR图像。</p>\r\n<p>下面介绍几个典型的无监督SR</p>\r\n<h4 id=\"zssrzero-shot-super-resolution\">ZSSR(Zero-shot Super-resolution)</h4>\r\n<p><a href=\"https://arxiv.org/pdf/1712.06087.pdf\" target=\"_blank\" rel=\"noopener\">ZSSR</a>顾名思义就是一个零样本学习，即只使用待超分辨的LR图像，在test time训练一个image-specific的网络，从而完成SR任务。具体而言，就是使用了<a href=\"http://openaccess.thecvf.com/content_iccv_2013/papers/Michaeli_Nonparametric_Blind_Super-resolution_2013_ICCV_paper.pdf\" target=\"_blank\" rel=\"noopener\">ICCV 2013的一篇工作</a>估计了退化核，然后使用这个退化核，利用不同的尺度(scaling factors)完成一个数据增强，建立一个小数据集，进而学到一个小的CNN网络用于最后的预测。</p>\r\n<p>这样一来，ZSSR利用了图像内部的跨尺度信息，在非理想的情况下(比如LR不是由双三次退化得到/图像加了模糊、噪声、压缩伪影)得到了比先前的模型更好的效果(若已知模糊核，提高2db；模糊核未知，提高1db)。但是每张图片都需要训练不同的网络，因此需要更多的时间。</p>\r\n<h4 id=\"弱监督的sr\">弱监督的SR</h4>\r\n<p>所谓弱监督就是使用不成对的HR-LR图片(unpaired LR-HR images)进行学习。有两种思路：</p>\r\n<ul>\r\n<li>学习退化过程：\r\n<ul>\r\n<li><a href=\"https://arxiv.org/pdf/1807.11458\" target=\"_blank\" rel=\"noopener\">ECCV 2018</a>的一篇就提出了一个方法，分两步：\r\n<ul>\r\n<li>首先从一个unpaired LR-HR图像中学一个退化过程。即给Generator输入一个HR，产生LR，不仅要与输入的平均池化下采样匹配，还要符合真实的LR的分布(由Discriminator完成)</li>\r\n<li>然后使用上述学好的Generator，作为一个“真实的”退化模型，去构造LR-HR对，从而再训一个LR to HR的GAN，完成超分辨过程</li>\r\n</ul></li>\r\n</ul></li>\r\n<li>Cycle-in-cycle超分辨率：\r\n<ul>\r\n<li>也就是<a href=\"https://arxiv.org/pdf/1703.10593\" target=\"_blank\" rel=\"noopener\">CycleGAN</a>的思想，把LR空间和HR空间开着两个域(domain)，使用“cycle-in-cycle”结构去学彼此之间的映射。即不仅要符合目标域的分布，也要使图像能映射回原来的域。</li>\r\n<li><a href=\"https://arxiv.org/pdf/1809.00437\" target=\"_blank\" rel=\"noopener\">CinCGAN</a>就是利用这种思想，使用了4个Generator，2个Discriminator，构造了两个Cycle-GAN：LR&lt;--&gt;clean LR，clean LR &lt;--&gt; clean HR</li>\r\n<li>然鹅，由于训练的病态本质和CinCGAN的复杂架构，需要一些先进的策略来降低训练的难度和不稳定性</li>\r\n</ul></li>\r\n</ul>\r\n<h4 id=\"深度图像先验deep-image-prior-dip\">深度图像先验(Deep Image Prior, DIP)</h4>\r\n<p><a href=\"https://arxiv.org/pdf/1711.10925\" target=\"_blank\" rel=\"noopener\">DIP</a>中认为，CNN结构本身就足够捕获大量的低级图像信息，并应用于反问题上(比如去噪、图像超分辨等)，于是作者使用了一个随机初始化的CNN作为SR问题的先验。具体来说就是，建立了一个生成器网络，输入一个随机噪声z，生成HR图像。直接在训练过程中要求这张HR图像的下采样版本需要与LR图像相同。虽然这种方法的性能仍然比有监督的方法差(2 db)，其性能明显优于传统的双三次上采样(1 dB)。</p>\r\n<h3 id=\"特定领域的应用\">特定领域的应用</h3>\r\n<h4 id=\"深度图depth-maps的图像超分辨\">深度图(depth maps)的图像超分辨</h4>\r\n<p>深度图记录了视点与物体对象在实际场景中的距离，在姿势估计和语义分割中有重要作用。然而，由于经济和生产方面的限制，深度传感器制作的深度图往往分辨率低，并受到噪声、量化和缺失值等退化影响。因此，引入超分辨率来提高深度图的空间分辨率。</p>\r\n<p>深度地图的SR现在最流行的做法之一是使用另一个经济的RGB相机来获得HR图像的相同场景，用于指导超分辨LR深度地图</p>\r\n<h3 id=\"结论与未来可能的方向\">结论与未来可能的方向</h3>\r\n<p>在本节，作者指出一些SR领域尚未解决的问题。</p>\r\n<h4 id=\"网络设计-1\">网络设计</h4>\r\n<p>一些网络设计的可能的方向：</p>\r\n<ul>\r\n<li>结合局部和全局的信息</li>\r\n<li>结合低级(low-level)和高级(high-level)的信息\r\n<ul>\r\n<li>CNN的浅层提取颜色和边缘之类的低级信息</li>\r\n<li>深层提取目标检测之类的高级信息</li>\r\n</ul></li>\r\n<li>上下文相关的注意力机制\r\n<ul>\r\n<li>在不同的上下文，人们往往会关注图像的不同方面\r\n<ul>\r\n<li>举个例子：在草地区域，人们可能更关注当地的颜色和纹理；而在动物身体区域，人们可能更关注物种和相应的毛发细节。</li>\r\n</ul></li>\r\n</ul></li>\r\n<li>效率更高的架构\r\n<ul>\r\n<li>现有的SR模式倾向于追求最终的性能，而忽略了模型大小和推理速度</li>\r\n<li>比如对于<a href=\"https://arxiv.org/pdf/1707.02921\" target=\"_blank\" rel=\"noopener\">EDSR</a>，使用Titan GTX GPU，一张照片进行x4的SR，需要20s；<a href=\"https://openaccess.thecvf.com/content_cvpr_2018/papers/Haris_Deep_Back-Projection_Networks_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">DBPN</a>需要35s。</li>\r\n<li>如此长的预测时间在实际应用中是不可接受的，因此更高效的体系结构势在必行。</li>\r\n</ul></li>\r\n<li>上采样方法\r\n<ul>\r\n<li>插值方法计算开销大，不能端到端学习；</li>\r\n<li>转置卷积产生棋盘状伪像；</li>\r\n<li>亚像素层带来接受场分布不均；</li>\r\n<li>Meta Upscale模块可能造成不稳定或效率低下。</li>\r\n</ul></li>\r\n</ul>\r\n<p>另外，近年来，用于深度学习的神经结构搜索(neural architecture search, NAS)技术越来越流行，在很少人工干预的情况下极大地提高了性能或效率。对于SR领域，将上述方向与NAS结合探索具有很大的潜力。</p>\r\n<h4 id=\"学习策略-1\">学习策略</h4>\r\n<ul>\r\n<li>损失函数：现有的损失函数可以看作是建立LR/HR/SR图像之间的约束，并根据这些约束条件是否满足进行引导优化。在实际应用中，这些损失函数往往是加权组合的，对于SR的最佳损失函数仍然不清楚。</li>\r\n<li>标准化(Normalization)：既然BN不大行，那有其他的标准化方法吗？</li>\r\n</ul>\r\n<h4 id=\"评价指标\">评价指标</h4>\r\n<ul>\r\n<li>更准确的指标\r\n<ul>\r\n<li>PSNR倾向于导致过度平滑，可能会在几乎无法区分的图像之间有很不同的PSNR结果</li>\r\n<li>SSIM对亮度、对比度和结构进行了评价，但仍不能准确地测量感知质量。</li>\r\n<li>MOS是最接近人类视觉反馈的，但需要付出大量的成本，而且不可复制。</li>\r\n</ul></li>\r\n<li>盲IQA方法\r\n<ul>\r\n<li>现在SR的大多数度量都是全参考(all-reference)方法，也就是说，假设我们已经有Paired方法。但是有时候数据是难以取得的，并且常用的评价数据集往往是通过人工退化的方式构建的，我们执行的评估任务实际上是预定义降级的逆过程。</li>\r\n</ul></li>\r\n</ul>\r\n<h4 id=\"无监督的超分辨\">无监督的超分辨</h4>\r\n<h4 id=\"对真实世界场景的超分辨\">对真实世界场景的超分辨</h4>\r\n<ul>\r\n<li>多样的退化过程：已经一些工作，如CinCGAN等，但这些方法存在固有的缺陷，如训练难度大，假设过完美等。这个问题迫切需要解决。</li>\r\n<li>特定应用场景的超分辨：视频监控，目标跟踪，医学成像和场景渲染</li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Guided Image Generation with Conditional Invertible Neural Networks","url":"/2020/10/27/2020-10-27-GUIDED%20IMAGE%20GENERATION%20WITH%20CONDITIONAL%20INVERTIBLE%20NEURAL%20NETWORKS/","content":"<p>这篇文章也是INN系列的论文中经常引用的一篇文章，只在arxiv上看到，貌似没有被哪个会议接收，读下来确实发现idea的创新性不是特别足。但是发现其introduction中的对生成模型的归纳还是挺到位的，所以学习学习。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"论文背景\">论文背景</h3>\r\n<p>作者回顾了几个典型的条件生成模型的缺点：</p>\r\n<ul>\r\n<li>cGAN：训练不够稳定，容易模式坍塌</li>\r\n<li>cVAE：L2 loss的引入，使得生成的图像比较模糊</li>\r\n</ul>\r\n<p>但是可逆神经网络（INN）就可以克服上述的一些问题，利用双向传递、雅克比行列式易于计算的特点，建立一个“待生成的分布”与一个“易于取样的潜在分布”之间的双向映射。在训练过程中，待生成的分布<span class=\"math inline\">\\(p(\\mathbf x)\\)</span>的最大似然在隐空间中优化（这样看来，那篇Analyzing Inverse Problems其实用的不只是隐空间中优化）；而在推理过程中，隐变量<span class=\"math inline\">\\(\\mathbf z\\)</span>即可逆向映射到待生成的数据。</p>\r\n<p>对于非条件的INN来说，看上去和VAE的方法很一致，但是值得注意的是，他克服了VAE方法的好几个弱点：</p>\r\n<ul>\r\n<li>不再需要L2 重构损失，避免了图像模糊</li>\r\n<li><strong>每一个<span class=\"math inline\">\\(\\mathbf x\\)</span>都映射到一个唯一的<span class=\"math inline\">\\(\\mathbf z\\)</span>，所以并不再需要后验概率<span class=\"math inline\">\\(p(\\mathbf z|\\mathbf x)\\)</span>了，这样就避免了VAE中各个样本的潜空间区域不相交或重叠的问题</strong></li>\r\n</ul>\r\n<p>在训练稳定性和样本多样性方面，INN表现出与VAE架构相同的优势，但具有更加优越的图像质量。</p>\r\n<p>但是同时，INN也有一些相较于传统神经网络的缺失之处，比如池化层、Batch normalization层等（这句话我存疑，感觉是作者为了批判而批判，明明那个affine coupling block中的网络部分并不需要可逆，凭啥不能加池化或者BN呢）。</p>\r\n<p>于是作者声称提出了一个新的网络结构——cINN（条件可逆神经网络）。</p>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<h4 id=\"网络结构\">网络结构</h4>\r\n<p>我觉得其实这篇工作的亮点乏善可陈，用下面这一张图就可以概括：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201103165849.png\" alt=\"image-20201101002057198\" style=\"zoom: 67%;\" /></p>\r\n<p>仿射耦合层的结构，与我的另一篇<a href=\"/2020-10-11-Analyzing%20Inverse%20Problems%20with%20Invertible%20Neural%20Networks\">阅读Analyzing Inverse Problems</a>中的结构并无差别，只不过在两个不可逆的子网络的输入处，连接上条件特征。</p>\r\n<h4 id=\"训练过程\">训练过程</h4>\r\n<p>训练过程主要就是最大化似然概率(MAXIMUM LIKELIHOOD TRAINING)。具体就是，首先<span class=\"math inline\">\\(\\mathbf x\\)</span>域的样本是已知的，在<span class=\"math inline\">\\(\\mathbf x\\)</span>域中采样，<span class=\"math inline\">\\(\\mathbf z\\)</span>域的概率密度函数是已知的，利用利用易于计算的雅克比行列式，使用以下公式可以表示出，<span class=\"math inline\">\\(\\mathbf x\\)</span>域中的样本的出现概率： <span class=\"math display\">\\[\r\np_{X}(\\mathbf{x} ; \\mathbf{c}, \\theta)=p_{Z}(f(\\mathbf{x} ; \\mathbf{c}, \\theta))\\left|\\operatorname{det}\\left(\\frac{\\partial f}{\\partial \\mathbf{x}}\\right)\\right|\r\n\\]</span> 又因为似然概率<span class=\"math inline\">\\(p(\\theta ; \\mathbf{x}, \\mathbf{c}) \\propto p_{X}(\\mathbf{x} ; \\mathbf{c}, \\theta) \\cdot p_{\\theta}(\\theta)\\)</span>，因此，取负对数后，损失函数如下： <span class=\"math display\">\\[\r\n\\mathcal{L}=\\mathbb{E}_{i}\\left[-\\log \\left(p_{X}\\left(\\mathbf{x}_{i} ; \\mathbf{c}_{i}, \\theta\\right)\\right)\\right]-\\log \\left(p_{\\theta}(\\theta)\\right)\r\n\\]</span> 把(1)式代入，<span class=\"math inline\">\\(p_Z()\\)</span>利用标准高斯分布代入，而对<span class=\"math inline\">\\(\\theta\\)</span>的先验也看做高斯，则可以得到： <span class=\"math display\">\\[\r\n\\mathcal{L}=\\mathbb{E}_{i}\\left[\\frac{\\left\\|f\\left(\\mathbf{x}_{i} ; \\mathbf{c}_{i}, \\theta\\right)\\right\\|_{2}^{2}}{2}-\\log \\left|J_{i}\\right|\\right]+\\tau\\|\\theta\\|_{2}^{2}\r\n\\]</span></p>\r\n<h4 id=\"某些重要的细节部分\">某些重要的细节部分</h4>\r\n<ul>\r\n<li><p>通道随机排列：在每个仿射耦合层之间，使用随机正交矩阵实现通道的随机排列，这使得耦合块中的两个信息流之间有更多的交互。矩阵在整个训练过程中都是固定的，并且保证它是可逆的。</p></li>\r\n<li><p>哈尔小波变换：相比于先前的INN都用到的棋牌格式的下采样方式，作者发现使用哈尔小波变换比较适合。本质上是将图像分解为<strong>平均、垂直、水平和对角四个特征通道</strong>。垂直、水平和对角这三个导数通道包含了高分辨率的信息，我们可以在早期分离掉这些信息，在cINN的后期将剩余的信息进一步转化。Haar wavelet也能用作在中间混合不同流的信息，可以看做是对上述的通道随机排列的补充。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201103165850.png\" alt=\"image-20201101154454768\" style=\"zoom:67%;\" /></p></li>\r\n</ul>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<p>作者主要拿这个模块做了两个实验，一个是条件生成MNIST、另一个是图像上色。两个网络结构如下：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201103165851.png\" alt=\"image-20201101161439283\" style=\"zoom:67%;\" /></p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201103165852.png\" alt=\"image-20201101161513778\" style=\"zoom:67%;\" /></p>\r\n<p>CC conv代表条件仿射耦合层的子网络s和t用的是卷积层。而CC fully connected是用的全连接层。</p>\r\n<p>MINST的结果如下：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201103165853.png\" alt=\"image-20201101163451349\" style=\"zoom:67%;\" /></p>\r\n<p>使用PCA在z域上找主轴，可以发现不同轴上控制的不同的特征：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201103165854.png\" alt=\"image-20201101163549014\" style=\"zoom:67%;\" /></p>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li>在阅读这篇的时候，我把cGAN与cVAE的特点又重新的理解了一篇，收获颇丰。cGAN不易造成模糊，但容易出现模型坍塌，且训练不稳定；cVAE使用了L2重构，造成图像模糊。</li>\r\n<li>对于INN体系的训练方式来说，Analyzing Inverse Problems那篇的使用的是MMD（最大均值差异）方法，不需要显示的计算雅克比行列式，所以模型的重点在于保证双向传播的高效性，直接在样本上进行MMD最小化；而本文使用的是最大似然，需要显式地计算雅克比矩阵。我觉得最大似然的可解释性更强，但是在Invertible Image Rescaling中也没有使用最大似然的训练方法，而是把Analyzing Inverse Problems的MMD改成了JS散度。</li>\r\n<li>另外，相对于Invertible Image Rescaling和Analyzing Inverse Problems把“条件”也放在网络中进行可逆的传播，本文是粗暴地将其插入INN的不可逆模块中。难怪在Invertible Image Rescaling中作者表示，这篇文章“x和z之间的可逆建模以y为条件，在给定x时模型不能生成y，因此不适用于图像的缩放任务”其实是有道理的。</li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：NICE：Non-linear Independent Components Estimation","url":"/2020/11/01/2020-11-01-NICE%EF%BC%9ANON-LINEAR%20INDEPENDENT%20COMPONENTS%20ESTIMATION/","content":"<p>为了使自己对流模型、可逆网络有更深刻的理解，选择了NICE这篇流模型开山之作（之一）来读。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"引言\">引言</h3>\r\n<p>如何捕获具有未知结构的复杂数据分布，是无监督学习里的重要任务。而本文考虑了这样一种特殊情况，即要求学习者寻找数据到一个新的空间的变换<span class=\"math inline\">\\(h = f(x)\\)</span>，且<span class=\"math inline\">\\(h\\)</span>的各个分布组件<span class=\"math inline\">\\(h_d\\)</span>是独立的。</p>\r\n<p>考虑变量的变化h = f(x)，假设f是可逆的，h的维数与x的维数相同，来拟合一个分布ph。变量的变化规律为： <span class=\"math display\">\\[\r\np_{X}(x)=p_{H}(f(x))\\left|\\operatorname{det} \\frac{\\partial f(x)}{\\partial x}\\right|\r\n\\]</span></p>\r\n<p>这样，我们就能通过可逆结构<span class=\"math inline\">\\(f\\)</span>来在<span class=\"math inline\">\\(x\\)</span>域中采样： <span class=\"math display\">\\[\r\n\\begin{array}{l}\r\nx \\sim p_{H}(h) \\\\\r\nx=f^{-1}(h)\r\n\\end{array}\r\n\\]</span> 这篇论文的一个关键的idea是设计了这样一个变换<span class=\"math inline\">\\(f\\)</span>，它可以得到的这两个性质</p>\r\n<ul>\r\n<li>能够简单得到雅可比行列式</li>\r\n<li>能够简单得到其逆过程</li>\r\n</ul>\r\n<h3 id=\"学习连续概率的双向变化\">学习连续概率的双向变化</h3>\r\n<p>通过最大似然，学习一个连续的，几乎处处可微的非线性转换<span class=\"math inline\">\\(f\\)</span>的参数分布，公式如下： <span class=\"math display\">\\[\r\n\\log \\left(p_{X}(x)\\right)=\\log \\left(p_{H}(f(x))\\right)+\\log \\left(\\left|\\operatorname{det}\\left(\\frac{\\partial f(x)}{\\partial x}\\right)\\right|\\right)\r\n\\]</span> 在此公式中，变换<span class=\"math inline\">\\(f\\)</span>的雅可比行列式在高密度区域(即在数据点处)惩罚收缩，鼓励扩张。（意思是保证生成的多样性）</p>\r\n<h3 id=\"网络结构\">网络结构</h3>\r\n<h4 id=\"三角结构\">三角结构</h4>\r\n<p>如果把变化<span class=\"math inline\">\\(f\\)</span>看做多个变换的合成<span class=\"math inline\">\\(f=f_{L} \\circ \\ldots \\circ f_{2} \\circ f_{1}\\)</span>，则最终的雅克比行列式就是这些子变换的雅克比的乘积，于是作者优先设计这些子变换的结构。</p>\r\n<p>首先，作者考虑仿射变换。对于仿射变换的系数矩阵来说，三角矩阵的行列式易于计算。许多方阵M也可以表示为上下三角矩阵的M = LU的乘积。由于这些变换可以组合，所以有效的雅可比矩阵是对角的、下三角形的或上三角形的。</p>\r\n<p>基于上述观察，一种方法是用三角权矩阵和可逆的激活函数建立一个神经网络，但这高度限制了架构，限制了对深度和非线性的选择。</p>\r\n<p>所以换一种思路，我们可以考虑具有三角雅可比矩阵的函数族。通过保证雅可比矩阵的对角元素易于计算，使得雅可比矩阵的行列式也易于计算。</p>\r\n<h4 id=\"耦合层\">耦合层</h4>\r\n<p>在本节中，描述了一类具有三角形雅可比矩阵的双射变换，因此雅可比行列式是可处理的。它将成为变换<span class=\"math inline\">\\(f\\)</span>的基础。</p>\r\n<h5 id=\"耦合层的一般表示形式general-coupling-layer\">耦合层的一般表示形式（General coupling layer）</h5>\r\n<p><span class=\"math display\">\\[\r\n\\begin{array}{l}\r\ny_{I_{1}}=x_{I_{1}} \\\\\r\ny_{I_{2}}=g\\left(x_{I_{2}} ; m\\left(x_{I_{1}}\\right)\\right)\r\n\\end{array}\r\n\\]</span></p>\r\n<p>这样一来，雅克比矩阵变成： <span class=\"math display\">\\[\r\n\\frac{\\partial y}{\\partial x}=\\left[\\begin{array}{cc}\r\nI_{d} &amp; 0 \\\\\r\n\\frac{\\partial y_{I_{2}}}{\\partial x_{I_{1}}} &amp; \\frac{\\partial y_{I_{2}}}{\\partial x_{I_{2}}}\r\n\\end{array}\\right]=\\operatorname{det} \\frac{\\partial y_{I_{2}}}{\\partial x_{I_{2}}}\r\n\\]</span> 我们需要保证，变换<span class=\"math inline\">\\(g\\)</span>是可逆的，那么逆过程可以表示为： <span class=\"math display\">\\[\r\n\\begin{array}{l}\r\nx_{I_{1}}=y_{I_{1}} \\\\\r\nx_{I_{2}}=g^{-1}\\left(y_{I_{2}} ; m\\left(y_{I_{1}}\\right)\\right)\r\n\\end{array}\r\n\\]</span></p>\r\n<h5 id=\"加法耦合层additive-coupling-layer\">加法耦合层（Additive coupling layer）</h5>\r\n<p>将一般形式中的<span class=\"math inline\">\\(g\\)</span>变换写成如下的形式： <span class=\"math display\">\\[\r\nx_{I_{1}}=y_{I_{1}} \\\\\r\ny_{I_{2}}=x_{I_{2}}+m\\left(x_{I_{1}}\\right)\r\n\\]</span> 由于<span class=\"math inline\">\\(\\frac{\\partial y_{I_{2}}}{\\partial x_{I_{2}}}=1\\)</span>，代表其雅克比行列式为1.</p>\r\n<p>其实除了加法之外，还能使用其他的耦合层，比如乘法耦合层<span class=\"math inline\">\\(g(a ; b)=a \\odot b, b \\neq 0\\)</span>，仿射耦合层<span class=\"math inline\">\\(g(a ; b)=a \\odot b_{1}+b_{2}, b_{1} \\neq 0\\)</span>等</p>\r\n<p>由于耦合层保留其部分输入不变，因此我们需要在交替层中交换分区中两个子集的角色，以便两个耦合层的组合可以修改每个维度。（也就是通道随机排列的思想）</p>\r\n<h4 id=\"h域的分布选择\">H域的分布选择</h4>\r\n可以选高斯分布、逻辑斯提分布等： $$\r\n<span class=\"math display\">\\[\\begin{aligned}\r\n&amp;\\log \\left(p_{H_{d}}\\right)=-\\frac{1}{2}\\left(h_{d}^{2}+\\log (2 \\pi)\\right)\\\\\r\n\r\n&amp;\\log \\left(p_{H_{d}}\\right)=-\\log \\left(1+\\exp \\left(h_{d}\\right)\\right)-\\log \\left(1+\\exp \\left(-h_{d}\\right)\\right)\r\n\\end{aligned}\\]</span>\r\n<p>$$</p>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<p>作者分别在MNIST、TFD、SVHN、CIFAR-10中执行生成任务：</p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201103165925.png\" alt=\"image-20201101220130658\" /><figcaption aria-hidden=\"true\">image-20201101220130658</figcaption>\r\n</figure>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li>这篇文章算是流模型与可逆网络的最初的雏形，但是后面工作的大体思想都是基于这篇工作的，只不过改善了耦合层的结构、增加了损失函数等</li>\r\n<li>这个最初的耦合层结构比较简单，在者限于当时2015年网络结构的发展，这个可逆网络的表示能力也不是很强，但是后面follow的工作的确有很多，算是一个比较有开创性的有意义的工作（比如Glow、Real NVP等，下周也打算找来精读一下）</li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Analyzing Inverse Problems with Invertible Neural Networks","url":"/2020/10/11/2020-10-11-Analyzing%20Inverse%20Problems%20with%20Invertible%20Neural%20Networks/","content":"<h3 id=\"论文背景\">论文背景</h3>\r\n<p>在分析一个复杂物理系统时，常见的问题是不能直接测量我们感兴趣的<strong>系统参数</strong>。对于许多这样的系统，科学家们已经发展出复杂的理论来解释，测量值y是如何从隐藏的系统参数x中产生的。我们将把这种映射称为<strong>前向过程</strong>。然而，其<strong>逆过程</strong>需要从测量中推断出系统的隐藏状态。然而，因为关键信息在正向过程中丢失了，逆过程是不适定问题(ill-posed，即许多种系统参数x都可产生同一个测量值y)。</p>\r\n<p>给定一个测量值时，这种逆过程的解往往有多个，所以作者提出，解决逆过程时，<strong>必须给出一个在以某个观察为条件的，系统参数的条件后验概率分布，即<span class=\"math inline\">\\(p(\\mathbf{x|y})\\)</span>。</strong>针对这一任务本文提出了可逆神经网络(invertible neural networks, INNs)。</p>\r\n<a id=\"more\"></a>\r\n<p>可逆神经网络有3个特点：</p>\r\n<ul>\r\n<li>输入到输出是双射的(bijective)，即他的逆存在。</li>\r\n<li>前向映射和逆映射都是可以被有效计算的。</li>\r\n<li>两个映射都有一个可处理的雅可比矩阵，允许显式地计算后验概率。</li>\r\n</ul>\r\n<p>因此就可以只训练一个易于理解的前向过程，即可在预测过程中计算反向过程。</p>\r\n<p>为了抵消前向过程的固有信息损失，引入了额外的潜在输出变量<span class=\"math inline\">\\(\\mathbf z\\)</span>，它捕获了<span class=\"math inline\">\\(\\mathbf y\\)</span>中的不包含的关于x的信息。即INN把输入<span class=\"math inline\">\\(\\mathbf x\\)</span>与一个二元组<span class=\"math inline\">\\([\\mathbf y,\\mathbf z]\\)</span>联系在一起。前向过程为<span class=\"math inline\">\\([\\mathbf{y}, \\mathbf{z}]=f(\\mathbf{x})\\)</span>；逆过程为<span class=\"math inline\">\\(\\mathbf{x}=f^{-1}(\\mathbf{y}, \\mathbf{z})=g(\\mathbf{y}, \\mathbf{z})\\)</span>。</p>\r\n<p><strong>另外，INN保证<span class=\"math inline\">\\(\\mathbf z\\)</span>的分布是一个高斯分布。</strong>这样就能把待求的<strong>分布</strong><span class=\"math inline\">\\(p(\\mathbf{x|y})\\)</span>用一个<strong>确定的函数</strong><span class=\"math inline\">\\(\\mathbf{x}=g(\\mathbf{y}, \\mathbf{z})\\)</span>把<span class=\"math inline\">\\(\\mathbf z\\)</span>的高斯分布<span class=\"math inline\">\\(p(\\mathbf z)\\)</span>转换到<span class=\"math inline\">\\(\\mathbf x\\)</span>空间上，并且以<span class=\"math inline\">\\(\\mathbf y\\)</span>作为条件。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201030213828.png\" alt=\"image-20201003172529958\" style=\"zoom: 67%;\" /></p>\r\n<p>如上图所示，是在学习逆过程汇总，传统网络与本文提出的可逆网络的对比。</p>\r\n<ul>\r\n<li>左边的图是代表用通常的网络去学习逆过程，使用一个真实<span class=\"math inline\">\\(\\mathbf x\\)</span>与预测<span class=\"math inline\">\\(\\hat {\\mathbf x}\\)</span>之间的监督损失(supervised loss，SL)来约束。</li>\r\n<li>右边的图是使用INN去学习逆过程，在两个方向上都有loss</li>\r\n</ul>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<h4 id=\"问题描述\">问题描述</h4>\r\n<p>研究人员对描述某一现象的一组参数<span class=\"math inline\">\\(\\mathbf{x} \\in \\mathbb{R}^{D}\\)</span>感兴趣，但是却观测不到。能观测到的是<span class=\"math inline\">\\(\\mathbf{y} \\in \\mathbb{R}^{M}\\)</span>。对应的理论已经能提供一个模型<span class=\"math inline\">\\(\\mathbf{y}=s(\\mathbf{x})\\)</span>来描述这一前向过程了。但是由<span class=\"math inline\">\\(\\mathbf x\\)</span>到<span class=\"math inline\">\\(\\mathbf y\\)</span>的转换过程中遭受了信息损失，即<span class=\"math inline\">\\(\\mathbf y\\)</span>的本征维度(intrinsic dimension)小于<span class=\"math inline\">\\(D\\)</span>。因此，把逆过程建模成一个条件概率模型：<span class=\"math inline\">\\(p(\\mathbf{x} \\mid \\mathbf{y})\\)</span></p>\r\n<p><strong>我们的目标就是，使用由前向过程<span class=\"math inline\">\\(s\\)</span>以及一个<span class=\"math inline\">\\(\\mathbf x\\)</span>的先验<span class=\"math inline\">\\(p(\\mathbf x)\\)</span>，构造的数据集<span class=\"math inline\">\\(\\left\\{\\left(\\mathbf{x}_{i}, \\mathbf{y}_{i}\\right)\\right\\}_{i=1}^{N}\\)</span>，学习一个模型<span class=\"math inline\">\\(q(\\mathbf{x} \\mid \\mathbf{y})\\)</span>去拟合这个<span class=\"math inline\">\\(p(\\mathbf{x} \\mid \\mathbf{y})\\)</span>。</strong></p>\r\n<p>对于这样的数据集，其实也可以训练一个标准的回归模型。但是我们的目的是拟合一个完整的概率分布，为此，我们引入了一个符合标准正态分布的隐变量<span class=\"math inline\">\\(\\mathbf{z} \\in \\mathbb{R}^{K}\\)</span>，从而把<span class=\"math inline\">\\(q(\\mathbf{x} \\mid \\mathbf{y})\\)</span>重新参数化为一个输入为<span class=\"math inline\">\\(\\mathbf y\\)</span>与<span class=\"math inline\">\\(\\mathbf z\\)</span>，输出<span class=\"math inline\">\\(\\mathbf x\\)</span>的一个确定函数<span class=\"math inline\">\\(g\\)</span>，其中<span class=\"math inline\">\\(g\\)</span>的参数为<span class=\"math inline\">\\(\\theta\\)</span>： <span class=\"math display\">\\[\r\n\\mathbf{x}=g(\\mathbf{y}, \\mathbf{z} ; \\theta) \\quad \\text { with } \\quad \\mathbf{z} \\sim p(\\mathbf{z})=\\mathcal{N}\\left(\\mathbf{z} ; 0, I_{K}\\right)\r\n\\]</span> 值得注意的是，<span class=\"math inline\">\\(\\mathbf x\\)</span>是代表现实世界中不可观察的属性；而<span class=\"math inline\">\\(\\mathbf z\\)</span>是为我们的模型携带一个固有的信息。非线性独立分量分析理论(non-lineari ndependent component analysis )证明，一个高斯先验对z没有额外的限制。（？这段我不是太理解）</p>\r\n<p>与常规的神经网络方法相对比，我们不是直接学习<span class=\"math inline\">\\(\\mathbf{x}=g(\\mathbf{y}, \\mathbf{z} ; \\theta)\\)</span>这一映射，而是通过把其逆过程<span class=\"math inline\">\\(f(\\mathbf{x} ; \\theta)\\)</span>拟合为原始的前向过程<span class=\"math inline\">\\(s(\\mathbf x)\\)</span>： <span class=\"math display\">\\[\r\n[\\mathbf{y}, \\mathbf{z}]=f(\\mathbf{x} ; \\theta)=\\left[f_{\\mathbf{y}}(\\mathbf{x} ; \\theta), f_{\\mathbf{z}}(\\mathbf{x} ; \\theta)\\right]=g^{-1}(\\mathbf{x} ; \\theta) \\quad \\text { with } \\quad f_{\\mathbf{y}}(\\mathbf{x} ; \\theta) \\approx s(\\mathbf{x})\r\n\\]</span> <span class=\"math inline\">\\(f=g^{-1}\\)</span>是由INN的网络结构保证的。</p>\r\n<p>值得一提的是，设<span class=\"math inline\">\\(\\mathbf y\\)</span>的本征维数为<span class=\"math inline\">\\(m\\le M\\)</span>，则需要隐变量<span class=\"math inline\">\\(\\mathbf z\\)</span>的维度为<span class=\"math inline\">\\(K=D-m\\)</span>。如果<span class=\"math inline\">\\(m&lt;M\\)</span>时,则<span class=\"math inline\">\\(\\mathbf y\\)</span>的实际维度<span class=\"math inline\">\\(M\\)</span>加上<span class=\"math inline\">\\(\\mathbf z\\)</span>的维度<span class=\"math inline\">\\(K\\)</span>则大于了原始的<span class=\"math inline\">\\(\\mathbf x\\)</span>的维度<span class=\"math inline\">\\(D\\)</span>，那么就给原始的<span class=\"math inline\">\\(\\mathbf x\\)</span>加上一些值为0的维度<span class=\"math inline\">\\(\\mathbf{x}_{0} \\in \\mathbb{R}^{M+K-D}\\)</span>，以<span class=\"math inline\">\\([\\mathbf{x},\\mathbf{x_0}]\\)</span>作为输入即可。</p>\r\n<blockquote>\r\n<p>这里复习一个概率论的简单知识，已知随机变量<span class=\"math inline\">\\(X \\sim P_{X}(x), Y=f(X)\\)</span>，求 <span class=\"math inline\">\\(Y\\)</span> 的概率密度函数 <span class=\"math inline\">\\(P_{Y}(y)\\)</span>：</p>\r\n<p><strong>解：</strong>当 <span class=\"math inline\">\\(f\\)</span> 为递增函数时, 考察 Y 的累计分布函数 <span class=\"math inline\">\\(F_{Y}(y)\\)</span> : <span class=\"math display\">\\[\r\nF_{Y}(y)=\\operatorname{Pr}(Y \\leq y)=\\operatorname{Pr}\\left(X \\leq f^{-1}(y)\\right)=F_{X}\\left(f^{-1}(y)\\right)\r\n\\]</span> 故 <span class=\"math display\">\\[\r\nP_{Y}(y)=\\frac{d F_{Y}(y)}{d y}=P_{X}\\left(f^{-1}(y)\\right) \\frac{d f^{-1}(y)}{d y}\r\n\\]</span> 当 f 为递减函数时, <span class=\"math display\">\\[\r\nF_{Y}(y)=\\operatorname{Pr}(Y \\leq y)=\\operatorname{Pr}\\left(X \\geq f^{-1}(y)\\right)=1-F_{X}\\left(f^{-1}(y)\\right)\r\n\\]</span> 故 <span class=\"math display\">\\[\r\nP_{Y}(y)=\\frac{d F_{Y}(y)}{d y}=-P_{X}\\left(f^{-1}(y)\\right) \\frac{d f^{-1}(y)}{d y}\r\n\\]</span> 综上所述, <span class=\"math display\">\\[\r\nP_{Y}(y)=\\frac{d F_{Y}(y)}{d y}=P_{X}\\left(f^{-1}(y)\\right)\\left|\\frac{d f^{-1}(y)}{d y}\\right|=\\frac {P_{X}\\left(f^{-1}(y)\\right)}{\\left|\\left.\\frac{d f(x)}{d x}\\right|_{f^{-1}(y)}\\right|}\r\n\\]</span></p>\r\n</blockquote>\r\n<p>容易把<span class=\"math inline\">\\(q(\\mathbf x|\\mathbf y)\\)</span>写为：</p>\r\n<p><span class=\"math display\">\\[\r\nq(\\mathbf{x}=g(\\mathbf{y}, \\mathbf{z} ; \\theta) \\mid \\mathbf{y})=p(\\mathbf{z})\\left|J_{\\mathbf{x}}\\right|^{-1}, \\quad J_{\\mathbf{x}}=\\operatorname{det}\\left(\\left.\\frac{\\partial g(\\mathbf{y}, \\mathbf{z} ; \\theta)}{\\partial[\\mathbf{y}, \\mathbf{z}]}\\right|_{\\mathbf{y}, f_{\\mathbf{z}}(\\mathbf{x})}\\right)\r\n\\]</span></p>\r\n<p><span class=\"math inline\">\\(J_{\\mathbf{x}}\\)</span>为雅克比行列式。</p>\r\n<h4 id=\"可逆的网络结构\">可逆的网络结构</h4>\r\n<p>这里作者使用了2016年Real NVP中提出的结构(<a href=\"https://arxiv.org/pdf/1605.08803\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://arxiv.org/pdf/1605.08803</a>)。这种网络的基本单元是由两个互补的仿射耦合层组成的<strong>可逆块</strong>。</p>\r\n<p>在前向过程对于输入的向量<span class=\"math inline\">\\(\\mathbf u\\)</span>，拆分为两等分<span class=\"math inline\">\\(\\mathbf u_1\\)</span>与<span class=\"math inline\">\\(\\mathbf u_2\\)</span>，分别通过由<span class=\"math inline\">\\(\\exp \\left(s_{i}\\right)\\)</span>和<span class=\"math inline\">\\(t_{i}\\)</span>（<span class=\"math inline\">\\(i \\in\\{1,2\\}\\)</span>，即两层）决定系数的仿射映射层： <span class=\"math display\">\\[\r\n\\mathbf{v}_{1}=\\mathbf{u}_{1} \\odot \\exp \\left(s_{2}\\left(\\mathbf{u}_{2}\\right)\\right)+t_{2}\\left(\\mathbf{u}_{2}\\right), \\quad \\mathbf{v}_{2}=\\mathbf{u}_{2} \\odot \\exp \\left(s_{1}\\left(\\mathbf{v}_{1}\\right)\\right)+t_{1}\\left(\\mathbf{v}_{1}\\right)\r\n\\]</span> <img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201030213827.png\" alt=\"image-20201002110300782\" style=\"zoom: 67%;\" /></p>\r\n<p>而对于上式，如果给定<span class=\"math inline\">\\(\\mathbf{v}=\\left[\\mathbf{v}_{1}, \\mathbf{v}_{2}\\right]\\)</span>，容易得到其逆过程： <span class=\"math display\">\\[\r\n\\mathbf{u}_{2}=\\left(\\mathbf{v}_{2}-t_{1}\\left(\\mathbf{v}_{1}\\right)\\right) \\odot \\exp \\left(-s_{1}\\left(\\mathbf{v}_{1}\\right)\\right), \\quad \\mathbf{u}_{1}=\\left(\\mathbf{v}_{1}-t_{2}\\left(\\mathbf{u}_{2}\\right)\\right) \\odot \\exp \\left(-s_{2}\\left(\\mathbf{u}_{2}\\right)\\right)\r\n\\]</span> <img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201030213830.png\" alt=\"image-20201009170933331\" style=\"zoom: 67%;\" /></p>\r\n<p><strong>最重要的是，<span class=\"math inline\">\\(s_i\\)</span>和<span class=\"math inline\">\\(t_i\\)</span>的映射可以是任意复杂的<span class=\"math inline\">\\(\\mathbf v_1\\)</span>和<span class=\"math inline\">\\(\\mathbf u_2\\)</span>的函数，它们本身不需要是可逆的。</strong>在本文的实现中，它们是通过一系列全连接层+Leaky ReLU激活函数组成的。</p>\r\n<p>对于这种网络结构，作者在实际使用的时候加了两个小扩展：</p>\r\n<ul>\r\n<li>这种映射方式，是无法改变向量的维数的。当输入的维度<span class=\"math inline\">\\(D\\)</span>过小而不足以满足复杂的映射关系时，可以在输入端(对于逆过程则是输出端)扩展一些值为0的维度来实现维度的增加。而“扩展一些值为0的维度”这一操作，是不会改变向量的本征维度的。</li>\r\n<li>在各个上述的基本单元之间，加入一些层，这些层的操作是<strong>以固定的操作</strong>打乱输入向量的各个元素的排列。这使得<span class=\"math inline\">\\(\\mathbf{u}=\\left[\\mathbf{u}_{1}, \\mathbf{u}_{2}\\right]\\)</span>的操作在不同层之间是变化的，从而增强元素之间的相互作用。</li>\r\n</ul>\r\n<h4 id=\"双向训练过程\">双向训练过程</h4>\r\n<p>可逆网络使得训练过程中可以以交替的方式执行前向和逆向迭代，从两个方向进行梯度传播，进而进行参数更新。从而有三个损失函数，其中<span class=\"math inline\">\\(\\mathcal{L_y}\\)</span>、<span class=\"math inline\">\\(\\mathcal{L_z}\\)</span>是针对前向传播的损失函数；而<span class=\"math inline\">\\(\\mathcal{L_x}\\)</span>是针对逆向传播的损失函数。</p>\r\n<h5 id=\"损失函数mathcall_y\">损失函数<span class=\"math inline\">\\(\\mathcal{L_y}\\)</span></h5>\r\n<p>这个损失函数是对实际前向过程<span class=\"math inline\">\\(\\mathbf{y}_{i}=s\\left(\\mathbf{x}_{i}\\right)\\)</span>与网络预测值<span class=\"math inline\">\\(f_{\\mathbf{y}}\\left(\\mathbf{x}_{i}\\right)\\)</span>进行约束，即<span class=\"math inline\">\\(\\mathcal{L}_{\\mathbf{y}}\\left(\\mathbf{y}_{i}, f_{\\mathbf{y}}\\left(\\mathbf{x}_{i}\\right)\\right)\\)</span>，这个非常好理解。之所以下标为<span class=\"math inline\">\\(\\mathbf y\\)</span>，是对网络中与<span class=\"math inline\">\\(\\mathbf y\\)</span>生成有关的参数进行更新。<span class=\"math inline\">\\(\\mathcal{L_y}\\)</span>的形式可以是任意的监督损失，比如回归中的平方损失、或是分类中的交叉熵损失。</p>\r\n<h5 id=\"损失函数mathcall_z\">损失函数<span class=\"math inline\">\\(\\mathcal{L_z}\\)</span></h5>\r\n<p>对于与隐变量<span class=\"math inline\">\\(\\mathbf z\\)</span>生成有关的网络参数，使用一个损失函数<span class=\"math inline\">\\(\\mathcal{L_z}\\)</span>，这个损失函数要让“网络输出的<span class=\"math inline\">\\(\\mathbf y,\\mathbf z\\)</span>的联合概率分布”与“训练数据中的<span class=\"math inline\">\\(\\mathbf y\\)</span>的分布<span class=\"math inline\">\\(p(\\mathbf y)\\)</span>与<span class=\"math inline\">\\(\\mathbf z\\)</span>的期望的分布<span class=\"math inline\">\\(p(\\mathbf z)\\)</span>的乘积”尽可能一致。直观上，<strong>这个损失函数不仅要使得网络生成的<span class=\"math inline\">\\(\\mathbf z\\)</span>的分布尽可能为<span class=\"math inline\">\\(p(\\mathbf z)\\)</span>，而且使<span class=\"math inline\">\\(\\mathbf y\\)</span>与<span class=\"math inline\">\\(\\mathbf z\\)</span>是独立的（即不能让<span class=\"math inline\">\\(\\mathbf y\\)</span>与<span class=\"math inline\">\\(\\mathbf z\\)</span>编码了同样的信息）。</strong></p>\r\n<p>形式上写为：<span class=\"math inline\">\\(\\mathcal{L}_{\\mathbf{z}}(q(\\mathbf{y}, \\mathbf{z}), p(\\mathbf{y}) p(\\mathbf{z}))\\)</span></p>\r\n<p><span class=\"math inline\">\\(q(\\mathbf{y}, \\mathbf{z})\\)</span>为网络输出的联合概率分布，实际上<span class=\"math inline\">\\(q\\left(\\mathbf{y}=f_{\\mathbf{y}}(\\mathbf{x}), \\mathbf{z}=f_{\\mathbf{z}}(\\mathbf{x})\\right)=p(\\mathbf{x}) /\\left|J_{\\mathbf{y z}}\\right|\\)</span>，其中<span class=\"math inline\">\\(J_{\\mathbf{y z}}=\\operatorname{det}\\left(\\left.\\frac{\\partial f(\\mathbf x ; \\theta)}{\\partial\\mathbf x}\\right|_{g(\\mathbf{y}, \\mathbf z)}\\right)\\)</span>。</p>\r\n<p><span class=\"math inline\">\\(p(\\mathbf y)\\)</span>为训练数据的<span class=\"math inline\">\\(\\mathbf y\\)</span>的分布。因为训练数据中的<span class=\"math inline\">\\(\\mathbf y_i\\)</span>是由前向模型<span class=\"math inline\">\\(\\mathbf y_i=s(\\mathbf x_i)\\)</span>生成的，所以实际上满足<span class=\"math inline\">\\(p(\\mathbf{y}=s(\\mathbf{x}))=p(\\mathbf{x}) / \\left| J_{s}\\right|\\)</span>，其中<span class=\"math inline\">\\(J_s=\\operatorname{det}\\left(\\left.\\frac{\\partial s(\\mathbf x )}{\\partial\\mathbf x}\\right|_{s^{-1}(\\mathbf y)}\\right)\\)</span>.</p>\r\n<p>但是，这里作者使用了<strong>最大均值差异(Maximum Mean Discrepancy，MMD)</strong>的方法来实现<span class=\"math inline\">\\(\\mathcal{L_z}\\)</span>，从而只需要从分布中采样即可作比较，而<strong>不需要显式地计算两个雅克比行列式<span class=\"math inline\">\\(J_s\\)</span>与<span class=\"math inline\">\\(J_{\\mathbf {yz}}\\)</span>。</strong>具体MMD的方法在后面介绍。</p>\r\n<p>对于以上两个损失函数。作者证明了一个定理：</p>\r\n<blockquote>\r\n<p>Theorem: If an <span class=\"math inline\">\\(I N N f(\\mathbf{x})=[\\mathbf{y}, \\mathbf{z}]\\)</span> is trained as proposed, and both the supervised loss <span class=\"math inline\">\\(\\mathcal{L}_{\\mathbf{y}}=\\mathbb{E}\\left[\\left(\\mathbf{y}-f_{\\mathbf{y}}(\\mathbf{x})\\right)^{2}\\right]\\)</span> and the unsupervised loss <span class=\"math inline\">\\(\\mathcal{L}_{\\mathbf{z}}=D(q(\\mathbf{y}, \\mathbf{z}), p(\\mathbf{y}) p(\\mathbf{z}))\\)</span> reach zero, sampling <span class=\"math inline\">\\(g\\)</span> according to <span class=\"math inline\">\\(E q .\\)</span> 1 with <span class=\"math inline\">\\(g=f^{-1}\\)</span> returns the true posterior <span class=\"math inline\">\\(p\\left(\\mathbf{x} \\mid \\mathbf{y}^{*}\\right)\\)</span> for any measurement <span class=\"math inline\">\\(\\mathbf{y}^{*}\\)</span>.</p>\r\n<p>证明过程：</p>\r\n</blockquote>\r\n<h5 id=\"损失函数mathcall_x\">损失函数<span class=\"math inline\">\\(\\mathcal{L_x}\\)</span></h5>\r\n<p>虽然定理表明<span class=\"math inline\">\\(\\mathcal{L_y}\\)</span>、<span class=\"math inline\">\\(\\mathcal{L_z}\\)</span>基本已经够用了，但是因为训练的迭代次数毕竟是有限的，因此<span class=\"math inline\">\\(\\mathbf y\\)</span>和<span class=\"math inline\">\\(\\mathbf z\\)</span>之间仍然存在少量残留的依赖关系，这使得<span class=\"math inline\">\\(q(\\mathbf{x} \\mid \\mathbf{y})\\)</span>难以准确拟合<span class=\"math inline\">\\(p(\\mathbf{x} \\mid \\mathbf{y})\\)</span>。为了加速收敛，作者又提出了一个<span class=\"math inline\">\\(\\mathcal{L_x}\\)</span>。</p>\r\n<p>直观上解释，这个loss就是把原本的<span class=\"math inline\">\\(\\mathbf x\\)</span>代入网络前向传播，得到<span class=\"math inline\">\\(\\mathbf y\\)</span>与<span class=\"math inline\">\\(\\mathbf z\\)</span>，然后把得到的分布<span class=\"math inline\">\\(p(\\mathbf y)\\)</span>与<span class=\"math inline\">\\(p(\\mathbf z)\\)</span>看做独立的，分别在其中采样，并逆向传播回来，得到分布<span class=\"math inline\">\\(q(\\mathbf x)\\)</span>，使其尽量和原始的<span class=\"math inline\">\\(p(\\mathbf x)\\)</span>相似（这个拟合过程的loss也是使用MMD实现的）：</p>\r\n<p>形式化地表示为：<span class=\"math inline\">\\(\\mathcal{L}_{\\mathbf{x}}(p(\\mathbf{x}), q(\\mathbf{x}))\\)</span></p>\r\n<p><span class=\"math inline\">\\(q(\\mathbf{x})=p\\left(\\mathbf{y}=f_{\\mathbf{y}}(\\mathbf{x})\\right) p\\left(\\mathbf{z}=f_{\\mathbf{z}}(\\mathbf{x})\\right) /\\left|J_{\\mathbf{x}}\\right|\\)</span>。其中，<span class=\"math inline\">\\(J_{\\mathbf{x}}=\\operatorname{det}\\left(\\left.\\frac{\\partial g(\\mathbf{y}, \\mathbf{z} ; \\theta)}{\\partial[\\mathbf{y}, \\mathbf{z}]}\\right|_{f_{\\mathbf{y}}(\\mathbf{x}), f_{\\mathbf{z}}(\\mathbf{x})}\\right)=\\left[\\operatorname{det}\\left(\\frac{\\partial f( \\mathbf{x} ; \\theta)}{\\partial\\mathbf x}\\right)\\right]^{-1}\\)</span></p>\r\n<p>作者也证明了，当<span class=\"math inline\">\\(\\mathcal{L_y}\\)</span>、<span class=\"math inline\">\\(\\mathcal{L_z}\\)</span>收敛到0的时候，<span class=\"math inline\">\\(\\mathcal{L_x}\\)</span>也能保证是0。因此<span class=\"math inline\">\\(\\mathcal{L_x}\\)</span>不改变最优解，但是在实践中提高了收敛效率。</p>\r\n<p>最后，如果在网络的任何一端使用零填充，则需要损失项来确保没有信息被编码到附加的维度中。a)使用平方损失来保证这些值接近于零，b)在额外的逆训练过程中，用相同振幅的噪声覆盖那些填充维数，并最小化重构损失，这迫使这些维数被忽略。</p>\r\n<h4 id=\"最大均值差异maximum-mean-discrepancymmd\">最大均值差异(Maximum Mean Discrepancy，MMD)</h4>\r\n<p>这里作者讲的很粗略，我想起以前上深度学习课的时候讲过，这里拿出来复习一下。</p>\r\n<blockquote>\r\n<p>MMD (最大均值差异) 是迁移学习, 尤其是Domain adaptation (域适应) 中使用最广泛 (目前) 的一种损失函数, 主要用来度量两个不同但相关的分布的距离。两个分布的距离定义为： <span class=\"math display\">\\[\r\nM M D(X, Y)=\\left\\|\\frac{1}{n} \\sum_{i=1}^{n} \\phi\\left(x_{i}\\right)-\\frac{1}{m} \\sum_{j=1}^{m} \\phi\\left(y_{j}\\right)\\right\\|_{H}^{2}\r\n\\]</span> 其中 H 表示这个距离是由 <span class=\"math inline\">\\(\\phi()\\)</span> 将数据映射到再生希尔伯特空间（RKHS）中进行度量的。</p>\r\n<p>MMD的关键在于如何找到一个合适的 <span class=\"math inline\">\\(\\phi()\\)</span> 来作为一个映射函数。但是这个映射函数可能在不同的任务中都不是固定的, 并且这个映射可能高维空间中的映射, 所以是很难去选取或者定义的。那如果不能知道 <span class=\"math inline\">\\(\\phi,\\)</span> 那MMD该如何求呢？我们先展 开把MMD展开： <span class=\"math display\">\\[\r\nM M D(X, Y)=\\left\\|\\frac{1}{n^{2}} \\sum_{i}^{n} \\sum_{i^{\\prime}}^{n} \\phi\\left(x_{i}\\right) \\phi\\left(x_{i}^{\\prime}\\right)-\\frac{2}{n m} \\sum_{i}^{n} \\sum_{j}^{m} \\phi\\left(x_{i}\\right) \\phi\\left(y_{j}\\right)+\\frac{1}{m^{2}} \\sum_{j}^{m} \\sum_{j^{\\prime}}^{m} \\phi\\left(y_{j}\\right) \\phi\\left(y_{j}^{\\prime}\\right)\\right\\|_{H}\r\n\\]</span> 展开后就出现了 <span class=\"math inline\">\\(\\phi\\left(x_{i}\\right) \\phi\\left(x_{i}^{\\prime}\\right)\\)</span> 的形式, 这样联系SVM中的核函数 <span class=\"math inline\">\\(k(*),\\)</span> 就可以跳过计算 <span class=\"math inline\">\\(\\phi\\)</span> 的部分, 直接求 <span class=\"math inline\">\\(k\\left(x_{i}\\right) k\\left(x_{i}^{\\prime}\\right)_{\\circ}\\)</span> 所 以MMD又可以表示为： <span class=\"math display\">\\[\r\nM M D(X, Y)=\\left\\|\\frac{1}{n^{2}} \\sum_{i}^{n} \\sum_{i^{\\prime}}^{n} k\\left(x_{i}, x_{i}^{\\prime}\\right)-\\frac{2}{n m} \\sum_{i}^{n} \\sum_{j}^{m} k\\left(x_{i}, y_{j}\\right)+\\frac{1}{m^{2}} \\sum_{j}^{m} \\sum_{j^{\\prime}}^{m} k\\left(y_{j}, y_{j}^{\\prime}\\right)\\right\\|_{H}\r\n\\]</span></p>\r\n</blockquote>\r\n<p>在高维问题中，特别是在基于GAN的图像生成中，可训练的Discriminator loss通常是首选的。但是MMD的效果也很好，并且更容易使用、代价更小，从而使训练更稳定。这种方法需要定义一个核函数，这里使用了一个逆多二次函数(inverse multiquadric)作为核函数：<span class=\"math inline\">\\(k\\left(\\mathbf{x}, \\mathbf{x}^{\\prime}\\right)=1 /\\left(1+\\left\\|\\left(\\mathbf{x}-\\mathbf{x}^{\\prime}\\right) / h\\right\\|_{2}^{2}\\right)\\)</span></p>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<h4 id=\"人为构造的数据\">人为构造的数据</h4>\r\n<p>作者构造了一个由8个单高斯分布组成的高斯混合分布<span class=\"math inline\">\\(p(\\mathbf x)\\)</span>。前向过程是“样本--&gt;标签”的过程，定义的过程也很简单，就是属于8个单高斯分布峰值的的样 本给打上对应的label。共有四种label：红色、蓝色、绿色、紫色</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201030213829.png\" alt=\"image-20201003172559045\" style=\"zoom:67%;\" /></p>\r\n<p>而逆向过程就是给定一种颜色，求该颜色的分布。</p>\r\n<p>作者使用了不同种方法来实现逆向过程，从而进行对比：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201030213833.png\" alt=\"image-20201011222756424\" style=\"zoom:50%;\" /></p>\r\n<ul>\r\n<li>cGAN：和INN模型大小差不多的条件GAN，参数量为10K，输入Generator的噪声向量的维度仅为2</li>\r\n<li>Larger cGAN：更大模型的条件GAN，参数量为2M，输入Generator的噪声向量的维度增加到128</li>\r\n<li>Generator+MMD：把条件GAN中的Generator保留，而把Discriminator换成MMD的判别方式（即把Generator的输出y与喂给Generator的x连接起来，与ground-truth的&lt;x,y&gt;在batch层面进行对比）。在这里作者发现：人工设置的核函数的MMD损失，效果居然好于Discriminator</li>\r\n<li>cVAE(-IAF)：使用条件变分自编码器（加IAF）</li>\r\n<li>Dropout sampling：直接使用普通网络+dropout，拟合“颜色--&gt;分布”这一逆过程</li>\r\n</ul>\r\n<p>另外，作者对三个loss也做了消融实验：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201030213832.png\" alt=\"image-20201011203519544\" style=\"zoom:67%;\" /></p>\r\n<p>可以看到如果只使用正向的loss，则不能很好的拟合逆过程。相反地，只使用逆过程的loss(只是Lx)学习了正确的x分布，但丢失了所有的条件信息（颜色）。</p>\r\n<h3 id=\"我的思考\">我的思考</h3>\r\n<ul>\r\n<li><p>可逆神经网络(INN，Invertible Neural Networks)的核心目标是解决“逆向问题”，而这个逆向问题往往是ill-posed，也就是一个观测值可能有多个对应的系统参数。这样就需要建立一个”测量值--&gt;系统参数的<strong>分布</strong>“的映射，引入隐变量<span class=\"math inline\">\\(\\mathbf z\\)</span>这一随机变量保证了“单值--&gt;概率分布”的映射。</p></li>\r\n<li><p>根据我的查阅，类似的相关工作还有cGAN、cVAE、Normalizing Flow等，我将其思想进行以下的简要对比：</p>\r\n<ul>\r\n<li><p>cGAN是直接利用了GAN可以学分布的特点，加入条件信息进行逆过程的学习，但是对正向过程没有显式的学习。同一般的GAN一样，Discriminator还是扮演了辨别分布真实性的角色。但根据本文的实验的结果，要达到和INN同样的效果，GAN需要更大的网络。</p></li>\r\n<li><p>而在cVAE中，decoder完成了y--&gt;x的逆过程（x=g(z;y)），但对于前向过程(x--&gt;y)，Encoder并没有显式地学习（这和cGAN很像，y都是只作为条件信息）。本文作者发现在逆任务中，cVAE表现比cGAN好，所以作为baseline。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images20201030213831.png\" alt=\"image-20201009202640092\" style=\"zoom:67%;\" /></p></li>\r\n<li><p>Normalizing Flow也使用了可逆的网络结构，但是其的主要关注点在于是否能高效的显式计算雅克比行列式，从而直接最大化似然概率。而本文INN虽然也是用的可逆的网络结构，但并没有使直接计算雅克比行列式，而是进行直接的逆向传播来采样，进而利用MMD，通过分布的样本来衡量分布之间的差异。而对于Normalizing Flow的确点，在网上看到一种说法，其使用简单的最大似然并没有覆盖拟合输入空间分布，而只是要求训练点的似然概率最大。所以我猜想本文没有使用Flow的思想，转而使用MMD去衡量分布差异，或许解决了这个问题。（本文实验没有与Normalizing Flow对比，实践存疑）</p></li>\r\n</ul></li>\r\n<li><p>本文相当于借鉴了Normalizing Flow网络结构，但又不使用其直接最大化后验概率的思想，转而直接让样本数据在网络中来回跑，在两头用MMD加约束，感觉颇有Cycle-GAN的思想。不使用Discriminator而使用MMD，增加了训练的稳定性。</p></li>\r\n<li><p>在超分辨领域，前向问题就是“HR退化为LR”，而逆问题即为超分过程，而正好也是ill-posed。上个月我读的一篇ECCV 2020的Learning the Super-Resolution Space with Normalizing Flow用的是Normalizing Flow的思想，学习“LR--&gt;HR的<strong>分布</strong>“，基本也是这种问题抽象方式。因此，将其改成本文的INN应该也是可行的。这样就和invertible image rescaling的想法基本一致了。但是依据超分辨问题的特点，具体网络结构应该还有很多的改进空间（比如invertible image rescaling中的wavelet模块之类的）</p></li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Learning with Privileged Information for Efficient Image Super-Resolution   Super-Resolution and Beyond","url":"/2020/12/26/2020-12-26-Learning%20with%20Privileged%20Information%20for%20Efficient%20Image%20Super-Resolution/","content":"<p>这是一篇超分领域的知识蒸馏工作，发表于ECCV 2020</p>\r\n<h3 id=\"论文背景\">论文背景</h3>\r\n<p>传统的CNN-based超分方法，一般需要大量的存储资源和计算资源，难以在移动设备以及一些没有神经处理单元和芯片外存储器的设备上运行。</p>\r\n<p>也有很多工作是致力于减少神经网络的消耗的：</p>\r\n<ul>\r\n<li>比如在SISR中，使用递归层或者一些专门为SISR设计的网络结构。但是这些递归层或者专门设计的结构难以在硬件上实现。</li>\r\n<li>网络剪枝、参数量化也被用于网络压缩。其中网络剪枝去除了一些节点冗余连接，而参数量化则降低权重或激活函数的位精度。然而，网络剪枝使得存储访问不连续，而且数据的局部性也较弱，这大大降低了性能。而网络量化的性能本质上取决于全精度模型的性能。</li>\r\n<li>模型压缩的另一种方式是知识蒸馏（Knowledge distillation），即一个大型的模型(teacher网络)软化版本输出分布(即logit)或中间特征表示，由一个小网络(student网络)，这在图像分类任务中已经表现出有效性。而广义蒸馏（teacher）更进一步允许teacher网络)在训练时利用额外的信息（优势特征），并用补充的知识辅助学生网络的训练过程</li>\r\n</ul>\r\n<a id=\"more\"></a>\r\n<p>本论文的主要idea就是，ground-truth HR图像，可以看作为一个优势信息（privileged information）。的确，HR图像包含了LR图像中缺乏的成分（如高频特征），但是，现有的SISR方法，仅仅把它用作用于惩罚重构错误程度。与之相对比，作者提出的方法，使用HR图像作为优势信息，允许提取互补特征，并明确地将它们用于SISR任务。为了实现这个idea，作者设计了一个知识蒸馏的框架，框架中，teacher网络和student网络都致力于重构HR图像，却使用了不同的输入：teacher网络的输入是GT HR图像，而student网络的输入时对应的LR图像——这与传统的知识蒸馏框架是不同的。</p>\r\n<p>具体框架如下图：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201227180921556.png\" alt=\"image-20201227180921556\" style=\"zoom:67%;\" /></p>\r\n<p>传统的知识蒸馏方式如左图，其T网络和S网络的输入是一样的。而本文采用的广义蒸馏方式，对于T网络，其输入是一个优势特征——HR图像，而Encoder-Decoder的沙漏结构，其中的Decoder即为S网络的学习对象，Decoder中的中间特征通过特征蒸馏传递给S网络，这样S网络就可以学习通过优势特征培训的T网络的知识(例如，高频或HR输入的细节)。S网络可以用解码器的网络参数初始化，这允许将教师的重构能力转移给S网络。（？）</p>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<h4 id=\"teather网络\">Teather网络</h4>\r\n<p>由于教师网络输入的是真实的HR图像，可能无法提取出有用的特征，不管其容量如何，只是学会复制其输入——HR图像。此外，网络参数数量的巨大差异或教师和学生之间的表现差距阻碍了蒸馏过程。</p>\r\n<p>为了在促进Teather网络获取有用特征的同时减少差距，作者为Teather网络开发了一个沙漏结构。将HR图像投影到一个低维的特征空间中，生成紧凑的特征，然后从这些特征中重构出原始HR图像，这样Teather网络就可以学习提取更好的特征表示来完成图像重构任务。具体来说，教师网络由一个编码器<span class=\"math inline\">\\(G^{\\mathcal{T}}\\)</span>和一个解码器<span class=\"math inline\">\\(F^{\\mathcal{T}}\\)</span>组成。给定一对LR和HR图像，编码器<span class=\"math inline\">\\(G^{\\mathcal{T}}\\)</span>将输入HR图像<span class=\"math inline\">\\(\\mathbf Y\\)</span>转换为特征表示<span class=\"math inline\">\\(\\hat{\\mathbf{X}}^{\\mathcal{T}}\\)</span>。 <span class=\"math display\">\\[\r\n\\hat{\\mathbf{X}}^{\\mathcal{T}}=G^{\\mathcal{T}}(\\mathbf{Y})\r\n\\]</span> 而<span class=\"math inline\">\\(\\hat{\\mathbf{X}}^{\\mathcal{T}}\\)</span>的size和LR图像是一致的，decoder把<span class=\"math inline\">\\(\\hat{\\mathbf{X}}^{\\mathcal{T}}\\)</span>重新重构为HR图像<span class=\"math inline\">\\(\\hat{\\mathbf{Y}}^{\\mathcal{T}}\\)</span>。 <span class=\"math display\">\\[\r\n\\hat{\\mathbf{Y}}^{\\mathcal{T}}=F^{\\mathcal{T}}\\left(\\hat{\\mathbf{X}}^{\\mathcal{T}}\\right)\r\n\\]</span> 对于decoder，使用与Student网络相同的架构。它允许教师拥有与学生相似的表现能力，这在《Improved knowledge distillation via teacher assistant: Bridging the gap between student and teacher》(AAAI 2020)中被证明是有用的。</p>\r\n<p>而损失函数即为重构损失+模仿损失(imitation loss)： <span class=\"math display\">\\[\r\nL_{\\mathrm{recon}}^{\\mathcal{T}}=\\frac{1}{H W} \\sum_{i=1}^{H} \\sum_{j=1}^{W}\\left|Y_{i j}-\\hat{Y}_{i j}^{\\mathcal{T}}\\right|\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nL_{\\mathrm{im}}^{\\mathcal{T}}=\\frac{1}{H^{\\prime} W^{\\prime}} \\sum_{i=1}^{H^{\\prime}} \\sum_{j=1}^{W^{\\prime}}\\left|X_{i j}-\\hat{X}_{i j}^{\\mathcal{T}}\\right|\r\n\\]</span></p>\r\n<h4 id=\"student网络\">Student网络</h4>\r\n<p>student网络完成以下映射： <span class=\"math display\">\\[\r\n\\hat{\\mathbf{Y}}^{\\mathcal{S}}=F^{\\mathcal{S}}(\\mathbf{X})\r\n\\]</span> 损失函数使用的是重构损失+蒸馏损失。重构损失如下： <span class=\"math display\">\\[\r\nL_{\\text {recon }}^{\\mathcal{S}}=\\frac{1}{H W} \\sum_{i=1}^{H} \\sum_{j=1}^{W}\\left|Y_{i j}-\\hat{Y}_{i j}^{S}\\right|\r\n\\]</span></p>\r\n<h5 id=\"蒸馏损失\">蒸馏损失</h5>\r\n<p>用<span class=\"math inline\">\\(\\mathbf{f}^{\\mathcal{T}}\\)</span>和<span class=\"math inline\">\\(\\mathbf{f}^{\\mathcal{S}}\\)</span>分别表示教师网络和学生网络的中间特征，它们的大小相同，分别为<span class=\"math inline\">\\(C×H&#39;×W&#39;\\)</span>，定义互信息（mutual information）如下： <span class=\"math display\">\\[\r\nI\\left(\\mathbf{f}^{\\mathcal{T}} ; \\mathbf{f}^{\\mathcal{S}}\\right)=H\\left(\\mathbf{f}^{\\mathcal{T}}\\right)-H\\left(\\mathbf{f}^{\\mathcal{T}} \\mid \\mathbf{f}^{\\mathcal{S}}\\right)\r\n\\]</span> <span class=\"math inline\">\\(H\\left(\\mathbf{f}^{\\mathcal{T}}\\right)\\)</span>和<span class=\"math inline\">\\(H\\left(\\mathbf{f}^{\\mathcal{T}} \\mid \\mathbf{f}^{\\mathcal{S}}\\right)\\)</span>分别是边际熵和条件熵(marginal and conditional entropies)。为了使互信息最大化，应该使条件熵<span class=\"math inline\">\\(H\\left(\\mathbf{f}^{\\mathcal{T}} \\mid \\mathbf{f}^{\\mathcal{S}}\\right)\\)</span>最小。然而，对学生的权重进行精确的优化是很难的，因为它涉及到对条件概率<span class=\"math inline\">\\(p\\left(\\mathbf{f}^{\\mathcal{T}} \\mid \\mathbf{f}^{\\mathcal{S}}\\right)\\)</span>的积分。变分信息最大化(The variational information maximization)技术使用参数模型<span class=\"math inline\">\\(q\\left(\\mathbf{f}^{\\mathcal{T}} \\mid \\mathbf{f}^{\\mathcal{S}}\\right)\\)</span>来近似条件分布<span class=\"math inline\">\\(p\\left(\\mathbf{f}^{\\mathcal{T}} \\mid \\mathbf{f}^{\\mathcal{S}}\\right)\\)</span>，例如高斯分布或拉普拉斯分布，使得找到互信息<span class=\"math inline\">\\(I\\left(\\mathbf{f}^{\\mathcal{T}} ; \\mathbf{f}^{\\mathcal{S}}\\right)\\)</span>的下界。对于参数模型<span class=\"math inline\">\\(q\\left(\\mathbf{f}^{\\mathcal{T}} \\mid \\mathbf{f}^{\\mathcal{S}}\\right)\\)</span>，我们使用一个多元拉普拉斯分布，这个分布包含两个参数，其中<span class=\"math inline\">\\(\\boldsymbol{\\mu}\\)</span>为位置参数，而<span class=\"math inline\">\\(\\boldsymbol b\\)</span>为尺度参数（控制蒸馏的程度），<span class=\"math inline\">\\(\\boldsymbol{\\mu},\\boldsymbol{b} \\in \\mathbb{R}^{C \\times H^{\\prime} \\times W^{\\prime}}\\)</span>。于是定义蒸馏损失<span class=\"math inline\">\\(L_{\\text {distill }}^{S}\\)</span>为: <span class=\"math display\">\\[\r\nL_{\\mathrm{distill}}^{\\mathcal{S}}=\\frac{1}{C H^{\\prime} W^{\\prime}} \\sum_{i=1}^{C} \\sum_{j=1}^{H^{\\prime}} \\sum_{k=1}^{W^{\\prime}} \\log b_{i j k}+\\frac{\\left|f_{i j k}^{\\mathcal{T}}-\\mu_{i j k}\\right|}{b_{i j k}}\r\n\\]</span> 当S网络不能从蒸馏中获益时，尺度参数<span class=\"math inline\">\\(b_{ijk}\\)</span>增大以减小蒸馏程度。因为教师和学生网络采取不同的输入，这样就能自适应地决定，学生从教师那里学到学生“可以接受的”特征。<span class=\"math inline\">\\(\\log b_{i j k}\\)</span>相当于一个正则项，防止<span class=\"math inline\">\\(b_{i j k}\\)</span>造成loss的一个平凡解。</p>\r\n<p>而<span class=\"math inline\">\\(\\boldsymbol{\\mu}\\)</span>和<span class=\"math inline\">\\(\\boldsymbol{b}\\)</span>是从student网络的特征<span class=\"math inline\">\\(\\mathbf f^{\\mathcal S}\\)</span>中估计的。估计方法是使用一个小网络，这个小网络有两个分支，分别用于估计<span class=\"math inline\">\\(\\boldsymbol{\\mu}\\)</span>和<span class=\"math inline\">\\(\\boldsymbol{b}\\)</span>。两个分支使用相同的网络架构，两个1×1卷积层，之间有一个PReLU。对于估计<span class=\"math inline\">\\(\\boldsymbol{b}\\)</span>的尺度分支，我们在最后一层添加softplus函数(ζ(x) = log(1 + e^x))，使尺度参数为正。<strong>注意，估算模块是为蒸馏过程服务的，因此仅在训练时使用。</strong></p>\r\n<h3 id=\"实验设计与结果\">实验设计与结果</h3>\r\n<p>与大多数SR工作一样，使用DIV2K来训练，并在Set5、Set14、B100、Urban100上做测试。</p>\r\n<h4 id=\"消融实验\">消融实验</h4>\r\n<p>如下表所示。</p>\r\n<ol type=\"1\">\r\n<li>baseline使用的是FSRCNN（第一行）。</li>\r\n<li>从第二行开始，就能看出distillation对SR结果的促进效果了。第二行是把FSRCNN的结构去掉最后的deconvolution，作为teacher的结构，但没有沙漏结构。</li>\r\n<li>而第三行的沙漏结构限制了教师的性能并降低了性能(例如:第二排的老师比第二排的老师下降了19.9dB)，但是缩小了老师和学生之间的成绩差距。这使得特征提取更加有效，因此第三行student的性能(37.22dB)优于第二行student的性能(37.19dB)。</li>\r\n<li>从第四行可以看出，学生网络从教师中解码器的网络权值初始化中获益，这为学习提供了一个良好的起点，并转移了教师的重构能力。</li>\r\n<li>第五行，模仿损失进一步提高了PSNR的性能，使得学生更容易从老师那里学习特征。</li>\r\n<li>最后两行表明，在拉普拉斯分布的情况下，VID loss的处理效果比MAE的要好（基于MAE的蒸馏损失，会使得学生网络和教师网络的特征图相同。然而，这种对特征映射的强烈约束在本文的例子中是有问题的，因为本文的框架中对学生和教师网络使用了不同的输入。）</li>\r\n</ol>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201227223828860.png\" alt=\"image-20201227223828860\" style=\"zoom: 50%;\" /></p>\r\n<h4 id=\"lr\">LR</h4>\r\n<p>对于encoder编码得到的compact features ，作者也在w和w/o imitation loss的条件下做了分析，这个结果也是可预见的。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201227225432138.png\" alt=\"image-20201227225432138\" style=\"zoom:50%;\" /></p>\r\n<h4 id=\"最终结果\">最终结果</h4>\r\n<p>最终也是取得了不错的结果。相对于baselineFSRCNN，没有任何参数或是计算量的增加，但提上来了指标。相对于其他的大模型，本框架在时空效率上也更优。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201227225633856.png\" alt=\"image-20201227225633856\" style=\"zoom:67%;\" /></p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201227225845509.png\" alt=\"image-20201227225845509\" style=\"zoom:50%;\" /></p>\r\n<p>不仅在FSRCNN上，把本方法应用到其他SR模型中，也能提升性能：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201227225948371.png\" alt=\"image-20201227225948371\" style=\"zoom:50%;\" /></p>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Glow：generative flow with invertible 1x1 convolutions","url":"/2020/11/07/2020-11-07-Glow%EF%BC%9Agenerative%20flow%20with%20invertible%201x1%20convolutions/","content":"<h3 id=\"论文背景\">论文背景</h3>\r\n<p>这里，作者照例总结了几个生成模型：</p>\r\n<ul>\r\n<li>自回归模型(Autoregressive models)：简易，但并行化不够</li>\r\n<li>变分编码器(VAEs)：对数据的对数似然的<strong>下界</strong>进行优化，相较于变分编码器，有并行化的优势，但优化起来比较困难</li>\r\n<li>基于流的生成模型(Flow-based generative models)：在NICE中首次描述，在Real NVP中进行了扩展</li>\r\n</ul>\r\n<p>基于流的生成模型有如下的优点：</p>\r\n<ul>\r\n<li>精确隐变量推理和对数似然评价\r\n<ul>\r\n<li>在VAEs中，只能推断出数据点对应的隐变量的<strong>估计值</strong>。在可逆生成模型中，这可以在没有近似的情况下精确地实现。这不仅可以导致准确的推断，还可以优化数据的精确对数似然值，而不是数据的下界</li>\r\n</ul></li>\r\n<li>高效的推理与训练\r\n<ul>\r\n<li>在自回归模型，如Pixel-CNN中，难以并行化。而基于流的生成模型解决了这个问题</li>\r\n</ul></li>\r\n<li>隐空间对下游任务有用\r\n<ul>\r\n<li>在自回归模型中，隐层的边缘分布是未知的，这使得执行有效的数据操作更加困难。在GANs中，数据点通常不能直接表示在潜在空间中，因为GAN没有Encoder。</li>\r\n</ul></li>\r\n<li>内存节省\r\n<ul>\r\n<li>正如RevNet论文(Gomez et al.，2017)中所解释的，可逆神经网络中计算梯度需要的记忆量是恒定的，而不是线性的。</li>\r\n</ul></li>\r\n</ul>\r\n<a id=\"more\"></a>\r\n<h3 id=\"问题定义\">问题定义</h3>\r\n<p><span class=\"math inline\">\\(\\mathbf x\\)</span>是一个高维向量，分布<span class=\"math inline\">\\(\\mathbf{x} \\sim p^{*}(\\mathbf{x})\\)</span>是未知的。我们收集了一个独立同分布的数据集<span class=\"math inline\">\\(\\mathcal{D}\\)</span>，要选择一个模型<span class=\"math inline\">\\(p_{\\boldsymbol \\theta}(\\mathbf x)\\)</span>的参数<span class=\"math inline\">\\(\\theta\\)</span>。对于离散的数据<span class=\"math inline\">\\(\\mathbf x\\)</span>，以对数似然形式构建的目标函数为: <span class=\"math display\">\\[\r\n\\mathcal{L}(\\mathcal{D})=\\frac{1}{N} \\sum_{i=1}^{N}-\\log p_{\\boldsymbol{\\theta}}\\left(\\mathbf{x}^{(i)}\\right)\r\n\\]</span> 上述目标函数使用小批量数据的随机梯度下降进行优化。</p>\r\n<p>而生成过程被描述为： <span class=\"math display\">\\[\r\n\\begin{array}{l}\r\n\\mathbf{z} \\sim p_{\\boldsymbol{\\theta}}(\\mathbf{z}) \\\\\r\n\\mathbf{x}=\\mathbf{g}_{\\boldsymbol{\\theta}}(\\mathbf{z})\r\n\\end{array}\r\n\\]</span> <span class=\"math inline\">\\(\\mathbf z\\)</span>是一个隐变量，有着一个易于处理的简单分布<span class=\"math inline\">\\(p_{\\boldsymbol{\\theta}}(\\mathbf{z})\\)</span>，比如多变量高斯分布<span class=\"math inline\">\\(p_{\\boldsymbol{\\theta}}(\\mathbf{z})=\\mathcal{N}(\\mathbf{z} ; 0, \\mathbf{I})\\)</span>。而<span class=\"math inline\">\\(\\mathbf g(\\cdot)\\)</span>是可逆的：<span class=\"math inline\">\\(\\mathbf{z}=\\mathbf{f}_{\\boldsymbol{\\theta}}(\\mathbf{x})=\\mathbf{g}_{\\boldsymbol \\theta}^{-1}(\\mathbf{x})\\)</span>。</p>\r\n<p>而作者这次关注的主要问题是，当<span class=\"math inline\">\\(\\mathbf f\\)</span>由一个变换序列组合而成：<span class=\"math inline\">\\(\\mathbf{f}=\\mathbf{f}_{1} \\circ \\mathbf{f}_{2} \\circ \\cdots \\circ \\mathbf{f}_{K}\\)</span>，那么<span class=\"math inline\">\\(\\mathbf x\\)</span>与<span class=\"math inline\">\\(\\mathbf z\\)</span>之间的关系表示为： <span class=\"math display\">\\[\r\n\\mathbf{x} \\stackrel{\\mathbf{f}_{1}}{\\longleftrightarrow} \\mathbf{h}_{1} \\stackrel{\\mathbf{f}_{2}}{\\longleftrightarrow} \\mathbf{h}_{2} \\cdots \\stackrel{\\mathbf{f}_{K}}{\\longleftrightarrow} \\mathbf{z}\r\n\\]</span> 根据变量代换公式，原本的密度可以表示为： <span class=\"math display\">\\[\r\n\\begin{aligned}\r\n\\log p_{\\boldsymbol{\\theta}}(\\mathbf{x}) &amp;=\\log p_{\\boldsymbol{\\theta}}(\\mathbf{z})+\\log |\\operatorname{det}(d \\mathbf{z} / d \\mathbf{x})| \\\\\r\n&amp;=\\log p_{\\boldsymbol{\\theta}}(\\mathbf{z})+\\sum_{i=1}^{K} \\log \\left|\\operatorname{det}\\left(d \\mathbf{h}_{i} / d \\mathbf{h}_{i-1}\\right)\\right|\r\n\\end{aligned}\r\n\\]</span></p>\r\n<p>为了方便，我们设置<span class=\"math inline\">\\(\\mathbf{h}_{0} \\triangleq \\mathbf{x} , \\mathbf{h}_{K} \\triangleq \\mathbf{z}\\)</span>。虽然这个雅克比行列式看起来很吓人，但是它的值对于某些变换的选择计算起来却出奇的简单。其基本思想是选择其雅可比矩阵为三角矩阵的变换，这样一来其对数雅克比就很简单： <span class=\"math display\">\\[\r\n\\log \\left|\\operatorname{det}\\left(d \\mathbf{h}_{i} / d \\mathbf{h}_{i-1}\\right)\\right|=\\operatorname{sum}\\left(\\log \\left|\\operatorname{diag}\\left(d \\mathbf{h}_{i} / d \\mathbf{h}_{i-1}\\right)\\right|\\right)\r\n\\]</span></p>\r\n<h3 id=\"主要方法\">主要方法</h3>\r\n<h4 id=\"可逆1x1卷积\">可逆1x1卷积</h4>\r\n<p>如题目所述，这篇文章的主要重点为1x1可逆卷积。</p>\r\n<p><strong>置换矩阵</strong></p>\r\n<p>对向量的置换操作，可以用矩阵乘法来描述，比如原来向量是 [1,2,3,4]，分别交换第一、二和第三、四两个数，得到 [2,1,4,3]，这个操作可以用矩阵乘法来描述：</p>\r\n<p><img src=\"https://image.jiqizhixin.com/uploads/editor/2c6ffd2f-0341-4f33-91ea-0566b85dcefb/1535347013381.png\" alt=\"img\" style=\"zoom:50%;\" /></p>\r\n<p>其中右端第一项是“由单位矩阵不断交换两行或两列最终得到的矩阵”称为置换矩阵。</p>\r\n<p><strong>一般化置换</strong></p>\r\n<p>既然这样，那很自然的想法就是：为什么不将置换矩阵换成一般的可训练的参数矩阵呢？所谓 1x1 可逆卷积，就是这个想法的结果。</p>\r\n<p>一开始提出 flow 模型的思路时就已经明确指出，flow 模型中的变换要满足两个条件：一是可逆，二是雅可比行列式容易计算。如果直接写出变换： <span class=\"math display\">\\[\r\nh=xW\r\n\\]</span> 那么它就只是一个普通的没有 bias 的全连接层，并不能保证满足这两个条件。为此，要做一些准备工作。首先，让 h 和 x 的维度一样，也就是说 W 是一个方阵，这是最基本的设置；其次，由于这只是一个线性变换，因此它的雅可比矩阵就是<span class=\"math inline\">\\(\\left[\\frac{\\partial h}{\\partial x}\\right]=W\\)</span>，所以它的行列式就是 det <em>W</em>，因此需要把 −log |det <em>W</em>| 这一项加入到 loss 中；最后，初始化时为了保证 W 的可逆性，一般使用“随机正交矩阵”初始化。</p>\r\n<p><strong>利用LU分解</strong></p>\r\n<p>由于算矩阵的行列式运算量特别大，还容易溢出。而 Glow 给出了一个非常巧妙的解决方案：LU 分解的逆运用。具体来说，是因为任意矩阵都可以分解为： <span class=\"math display\">\\[\r\nW = PLU\r\n\\]</span> 其中 P 是一个置换矩阵，也就是前面说的 shuffle 的等价矩阵；L 是一个下三角阵，对角线元素全为 1；U 是一个上三角阵。这种形式的分解称为 LU 分解。如果知道这种矩阵的表达形式，显然求雅可比行列式是很容易的，它等于： <span class=\"math display\">\\[\r\n\\log |\\operatorname{det} \\boldsymbol{W}|=\\sum \\log |\\operatorname{diag}(\\boldsymbol{U})|\r\n\\]</span></p>\r\n<p>本文中给出的技巧：先随机生成一个正交矩阵，然后做 LU 分解，得到 P,L,U，固定 P，也固定 U 的对角线的正负号，然后约束 L 为对角线全 1 的下三角阵，U 为上三角阵，优化训练 L,U 的其余参数。</p>\r\n<h4 id=\"actnorm\">Actnorm</h4>\r\n<p>RealNVP 中用到了 BN 层，而 Glow 中提出了名为 Actnorm 的层来取代 BN。不过，所谓 Actnorm 层事实上只不过是 NICE 中的尺度变换层的一般化，也就是 (5) 式提到的缩放平移变换： <span class=\"math display\">\\[\r\n\\hat{z}=\\frac{z-\\boldsymbol{\\mu}}{\\boldsymbol{\\sigma}}\r\n\\]</span> 其中 μ,σ 都是训练参数。Glow 在论文中提出的创新点是用初始的 batch 的均值和方差去初始化 μ,σ 这两个参数。</p>\r\n<p>相比于加性耦合层，仿射耦合层多了一个尺度变换层，从而计算量翻了一倍。但事实上相比加性耦合，仿射耦合效果的提升并不高（尤其是加入了 Actnorm 后），<strong>所以要训练大型的模型，为了节省资源，一般都只用加性耦合</strong>，比如 Glow 训练 256x256 的高清人脸生成模型，就只用到了加性耦合。</p>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<p>使用Glow训练人脸：</p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/images2020/12/12/12:22:32.png\" alt=\"image-20201107161822636\" /><figcaption aria-hidden=\"true\">image-20201107161822636</figcaption>\r\n</figure>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<p>整体来看，Glow 模型在 RealNVP 的基础上引入了 1x1 可逆卷积来代替前面说的打乱通道轴的操作，并且对 RealNVP 的原始模型做了简化和规范，使得它更易于理解和使用。</p>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：VarSR：Variational Super-Resolution Network for Very Low Resolution Images","url":"/2020/11/24/2020-11-24-VarSR%20Variational%20Super-Resolution%20Network%20for%20Very%20Low%20Resolution%20Images/","content":"<h3 id=\"简述\">简述</h3>\r\n<p>本文提出的方法要完成的任务是在超低分辨率下的超分辨，正视超分辨的ill-posed属性，从一张LR图像中恢复出多张可能的HR图像。这个方法被作者称为VarSR。</p>\r\n<p>主要思路是：通过最小化在HR与LR的KL散度来连接LR图像与HR图像间的表示能力，从而把LR图像和HR图像同时encode到同一个隐变量特征空间。然后SR模块的输入是这个隐变量，生成一个与Ground-truth HR之间的像素/感知上的相似的SR结果。<strong>由于HR图像的多样性程度高于LR图像，因此HR图像的潜在变量要比LR图像密集得多。</strong>所以在推理过程中，从隐变量空间中多次取样，从而产生多种SR图像。整个过程如下图所示。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201209171949200.png\" alt=\"image-20201209171949200\" style=\"zoom: 50%;\" /></p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<h4 id=\"整体框架描述\">整体框架描述</h4>\r\n<p>传统的SR框架都是这样的： <span class=\"math display\">\\[\r\n\\hat{I}_{H}=g_{S R}\\left(I_{L}\\right)\r\n\\]</span> 使用SR图片<span class=\"math inline\">\\(\\hat{I}_{H}\\)</span>与真实HR图像<span class=\"math inline\">\\(I_{H}\\)</span>之间的重构损失、感知损失、对抗损失训练。但是，由于<span class=\"math inline\">\\(I_{H}\\)</span>的详细信息难以在<span class=\"math inline\">\\(I_{L}\\)</span>中编码，使得超分辨率模型无法推断出可靠的输出，特别是对于极低分辨率的输入。</p>\r\n<p>为了解决这个问题，本文引入了一个隐变量，作为SR子模块的输入，描述<span class=\"math inline\">\\(I_{H}\\)</span>的信息，处理<span class=\"math inline\">\\(I_{L}\\)</span>的模糊性: <span class=\"math display\">\\[\r\n\\hat{I}_{H}=g_{S R}\\left(I_{L}, E_{H}\\left(I_{H}\\right)\\right)\r\n\\]</span> 其中，<span class=\"math inline\">\\(E_{H}(\\cdot)\\)</span>为一个encoder，用于从<span class=\"math inline\">\\(I_H\\)</span>中提取特征。而SR模型<span class=\"math inline\">\\(g_{SR}\\)</span>不仅输入低分辨图像<span class=\"math inline\">\\(I_L\\)</span>中获取信息，也从encoder编码的<span class=\"math inline\">\\(I_H\\)</span>的特征中获取信息，从而做出更准确的超分。</p>\r\n<p>然而，(2)式中，需要获得<span class=\"math inline\">\\(I_H\\)</span>的信息，这在超分中显然是不妥当的。所以我们需要只从<span class=\"math inline\">\\(I_L\\)</span>中去估计<span class=\"math inline\">\\(E_{H}(\\cdot)\\)</span>。</p>\r\n<p>因此，作者为<span class=\"math inline\">\\(I_L\\)</span>引入另一个encoder <span class=\"math inline\">\\(E_L(\\cdot)\\)</span>。由于SR问题的ill-posed属性，一张LR图像对应多张HR图像，因此，确定性的encoder是不够的。这里作者把隐变量的空间建模成一个多变量的高斯分布，这样就能从分布中多次采样，从而提供一个如下的“一对多”的映射： <span class=\"math display\">\\[\r\nE_{L}(x)=\\left[\\mu_{x}, \\sigma_{x}\\right] \\text { and } E_{H}(x)=\\left[\\mu_{x}, \\sigma_{x}\\right]\r\n\\]</span> 其中<span class=\"math inline\">\\(x\\)</span>代表HR或者LR图像，而<span class=\"math inline\">\\(\\mu_x\\)</span>与<span class=\"math inline\">\\(\\sigma_x\\)</span>分别是分布的期望和方差。</p>\r\n<p>于是，作者的关键idea就是，让两个隐变量 <span class=\"math inline\">\\(E_L(\\cdot)\\)</span>和 <span class=\"math inline\">\\(E_H(\\cdot)\\)</span>的分布对应起来。换句话说，就是要使得从 <span class=\"math inline\">\\(E_L(\\cdot)\\)</span>中取样和从 <span class=\"math inline\">\\(E_H(\\cdot)\\)</span>是高度相似的。因此，作者使用$E_{H}(I_{H}) <span class=\"math inline\">\\(和\\)</span> E_{L}(I_{L})$两个分布之间的KL散度来训练这两个encoder。</p>\r\n<p>测试与训练过程描述如下</p>\r\n<ul>\r\n<li><p>在训练过程中，超分网络<span class=\"math inline\">\\(G(\\cdot, \\cdot)\\)</span>的输入<span class=\"math inline\">\\((I_L, z)\\)</span>，其中<span class=\"math inline\">\\(z\\)</span>是从HR图片的encoder对应的高斯分布<span class=\"math inline\">\\(\\mathcal{N}\\left(E_{H}^{\\mu}\\left(I_{H}\\right), E_{H}^{\\sigma}\\left(I_{H}\\right)\\right)\\)</span>中取样（因为HR图像在训练过程中是可以得到的）。</p></li>\r\n<li><p>而在测试过程中，超分网络<span class=\"math inline\">\\(G(\\cdot, \\cdot)\\)</span>的输入<span class=\"math inline\">\\((I_L, z)\\)</span>，其中<span class=\"math inline\">\\(z\\)</span>是从LR图片的encoder对应的高斯分布<span class=\"math inline\">\\(\\mathcal{N}\\left(E_{L}^{\\mu}\\left(I_{L}\\right), E_{L}^{\\sigma}\\left(I_{L}\\right)\\right)\\)</span>中取样。即，从一幅LR图片<span class=\"math inline\">\\(I_L\\)</span>获得多种HR图片<span class=\"math inline\">\\(\\left\\{\\hat{I}_{H}^{1}, \\ldots, \\hat{I}_{H}^{n}\\right\\}\\)</span>的方法如下： <span class=\"math display\">\\[\r\n\\hat{I}_{H}^{i}=G\\left(I_{L}, z_{i}\\right), \\quad z_{i} \\sim \\mathcal{N}\\left(E_{L}^{\\mu}\\left(I_{L}\\right), E_{L}^{\\sigma}\\left(I_{L}\\right)\\right)\r\n\\]</span></p></li>\r\n</ul>\r\n<h5 id=\"与条件变分自编码器cvaes的关系\">与条件变分自编码器(cVAEs)的关系</h5>\r\n<p>cVAE是用来估计一个条件分布<span class=\"math inline\">\\(p_{\\theta}(x \\mid y)\\)</span>的，其中<span class=\"math inline\">\\(x\\)</span>为数据，<span class=\"math inline\">\\(y\\)</span>为条件。给定条件<span class=\"math inline\">\\(y\\)</span>，则<span class=\"math inline\">\\(z\\)</span>从一个先验分布<span class=\"math inline\">\\(p_\\theta(z|y)\\)</span>中取。而<span class=\"math inline\">\\(x\\)</span>是从分布<span class=\"math inline\">\\(p_\\theta(x|y,z)\\)</span>中取的（感觉这里都用<span class=\"math inline\">\\(\\theta\\)</span>是不是不太妥？）。而<span class=\"math inline\">\\(x\\)</span>的多样性<span class=\"math inline\">\\(\\left\\{x_{i}\\right\\}\\)</span>由多个隐变量<span class=\"math inline\">\\(\\left\\{z_{i}\\right\\}\\)</span>来产生。cVAE的evidence lower bound(ELBO)如下： <span class=\"math display\">\\[\r\n\\begin{aligned}\r\nL_{C V A E}(x, y ; \\theta, \\phi) &amp;=\\mathbb{E}_{q_{\\phi}(z \\mid x, y)} \\log p_{\\theta}(x \\mid y, z) \\\\\r\n&amp;-D_{K L}\\left(q_{\\phi}(z \\mid x, y) \\| p_{\\theta}(z \\mid y)\\right) \\leq \\log p_{\\theta}(x \\mid y)\r\n\\end{aligned}\r\n\\]</span> 上面的式子利用Jensen不等式很容易推出来，其中<span class=\"math inline\">\\(q_{\\phi}(z|x, y)\\)</span>是对真实后验概率<span class=\"math inline\">\\(p_\\theta(z|y)\\)</span>的估计（为啥前面又说是先验？）。根据变分推断的思想，最大化这个下界，即可最大化似然函数<span class=\"math inline\">\\(\\log {p_\\theta(x|y)}\\)</span>。</p>\r\n<p>如果我们假设：<strong>高分辨图像包含了其对应的低分辨图像的所有信息</strong>。那么，我们能将VarSR模型翻译为一个cVAE的结构，<span class=\"math inline\">\\(x\\)</span>就是高分辨图像<span class=\"math inline\">\\(I_H\\)</span>，<span class=\"math inline\">\\(y\\)</span>为低分辨图像<span class=\"math inline\">\\(I_L\\)</span>，<span class=\"math inline\">\\(p_\\theta(z|y)\\)</span>就是LR encoder<span class=\"math inline\">\\(E_{L}\\left(I_{L}\\right)\\)</span>，<span class=\"math inline\">\\(q_{\\phi}(z \\mid x, y)\\)</span>是HR encoder<span class=\"math inline\">\\(E_{H}\\left(I_{H}\\right)\\)</span>，<span class=\"math inline\">\\(p_{\\theta}(x|y, z)\\)</span>为超分网络<span class=\"math inline\">\\(G\\left(I_{L}, z\\right)\\)</span>。而<span class=\"math inline\">\\(\\log p_{\\theta}(x \\mid y, z)\\)</span>这项，其实就是使用像素级别的重构/感知等损失。作者表示，这种解释为VarSR模型提供了理论支持，也就是使观察数据的<strong>条件对数似然最大化</strong>。</p>\r\n<h4 id=\"目标函数\">目标函数</h4>\r\n<p>损失函数主要为三个：</p>\r\n<ul>\r\n<li><p>像素级别的重构损失：用于鼓励HR编码器<span class=\"math inline\">\\(E_H(\\cdot)\\)</span>提取高分辨率图像的信息特征 <span class=\"math display\">\\[\r\n\\mathcal{L}_{\\mathrm{pixel}}=\\frac{1}{r^{2} H W} \\sum_{x=1}^{r H} \\sum_{y=1}^{r W}\\left(I_{H}^{x, y}-G\\left(I_{L}, z\\right)^{x, y}\\right)^{2}, z \\sim \\mathcal{N}\\left(E_{H}^{\\mu}\\left(I_{H}\\right), E_{H}^{\\sigma}\\left(I_{H}\\right)\\right)\r\n\\]</span></p></li>\r\n<li><p>KL散度：最小化LR图像与HR图像在隐变量空间的分布差距 <span class=\"math display\">\\[\r\n\\mathcal{L}_{\\mathrm{KL}}=D_{K L}\\left(q\\left(z \\mid I_{H}\\right) \\| p\\left(z \\mid I_{L}\\right)\\right)\r\n\\]</span></p></li>\r\n<li><p>对抗损失：用于恢复更真实的纹理 <span class=\"math display\">\\[\r\n\\mathcal{L}_{\\mathrm{adv}}=\\underset{\\hat{I} \\sim \\mathbb{P}_{g}}{\\mathbb{E}}[D(\\hat{I})]-\\underset{I \\sim \\mathbb{P}_{r}}{\\mathbb{E}}[D(I)]+\\delta \\underset{\\hat{I} \\sim \\mathbb{P}_{\\hat{\\jmath}}}{\\mathbb{E}}\\left[\\left(\\left\\|\\nabla_{\\hat{I}} D(\\hat{I})\\right\\|_{2}-1\\right)^{2}\\right]\r\n\\]</span></p></li>\r\n</ul>\r\n<p>总损失是三者的加权和： <span class=\"math display\">\\[\r\n\\mathcal{L}=\\lambda_{\\text {pixel }} \\mathcal{L}_{\\text {pixel }}+\\lambda_{\\mathrm{KL}} \\mathcal{L}_{\\mathrm{KL}}+\\lambda_{\\mathrm{adv}} \\mathcal{L}_{\\mathrm{adv}}\r\n\\]</span></p>\r\n<h3 id=\"实验\">实验</h3>\r\n<p>作者在两个数据集上做了实验，一个是人脸数据集，一个是数字数据集。选择的比较对象有：</p>\r\n<ul>\r\n<li>PRSR：像素递归的超分辨方法（但是由于人脸数据集的像素为64x64，对于PRSR来说代价太大，因此PRSR没有在人脸数据集上面测。）</li>\r\n<li>MR-GAN：使用了基于动量的损失来代替均方误差，从而降低在cGAN中的模式坍塌</li>\r\n</ul>\r\n<p>此外，SRGAN作为deterministic SR technique（就是一张LR，只产生一张SR的技术）的baseline。对于数字数据集，由于数字数据集输入的低分辨率图像具有极低的维数，例如2×4像素，因此我们对整个方法使用带有跳跃连接的自动编码器。因此，后文中将deterministic SR technique表示为“Det”，而不是“SRGAN”。</p>\r\n<h4 id=\"数据集\">数据集</h4>\r\n<ul>\r\n<li>人脸数据集采用CelebA。一共200k张，100k作为训练集，1k作为测试集。HR分辨率为64x64，LR分辨率为8x8。对于网络结构来说，为了公平期间，和MR-GAN中设置的一样，都是8个Res Block。</li>\r\n<li>数字数据集用了两个：\r\n<ul>\r\n<li>MNIST。60k张训练集，10k张测试集。HR分辨率为64x64，LR分辨率为8x8。</li>\r\n<li>LP。110k训练，7k测试。</li>\r\n</ul></li>\r\n</ul>\r\n<h4 id=\"评价指标\">评价指标</h4>\r\n<p>由于VarSR-Net不是用来生成确定性结果的。因此作者根据不同超分辨图像的平均值/最佳分数来进行评估。</p>\r\n<ul>\r\n<li>传统的PSNR、SSIM、MSE</li>\r\n<li>对于数字数据集，使用图像分类方法，来衡量语义上的可信性</li>\r\n<li>对于人脸数据集，使用感知图像质量指标（具体使用了LPIPS分数、人脸验证网络FaceNet提取的特征间的距离）</li>\r\n</ul>\r\n<p>此外，为了衡量生成的图像的多样性，我们使用了结果SR图像之间的平均LPIPS距离来衡量。</p>\r\n<h4 id=\"定性结果\">定性结果</h4>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201211124854567.png\" alt=\"image-20201211124854567\" style=\"zoom: 50%;\" /></p>\r\n<p>另外，作者还尝试了其他High level的任务，如人脸属性编辑、属性迁移等，也取得了不错的效果：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201211125032030.png\" alt=\"image-20201211125032030\" style=\"zoom:50%;\" /></p>\r\n<h4 id=\"定量结果\">定量结果</h4>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201211125210693.png\" alt=\"image-20201211125210693\" style=\"zoom: 50%;\" /></p>\r\n<figure>\r\n<img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201211125145944.png\" alt=\"image-20201211125145944\" /><figcaption aria-hidden=\"true\">image-20201211125145944</figcaption>\r\n</figure>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li>这篇文章主要是用了cVAE的思想来解决SR的ill-posed问题，但是讲故事很有水平，一开始先重点讲HR encoder和LR encoder，把读者代入这种latent space的思路后，话锋一转，引入与cVAE关系，一下子就引入了可解释性。</li>\r\n<li>但是仔细看这篇文章的实验设计，还是能学到很多。相关的评价标准，以及baseline的选择都很巧妙。由于我的可逆网络毕设，也是解决SR的ill-posed问题，所以本文的实验设计很有参考价值。</li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：LAPAR：Linearly-Assembled Pixel-Adaptive Regression Network for Single Image Super-Resolution and Beyond","url":"/2020/12/17/2020-12-17-Journey%20Towards%20Tiny%20Perceptual%20Super-Resolution/","content":"<h3 id=\"论文背景\">论文背景</h3>\r\n<p>对于图像超分辨问题，最简单的方法是基于邻像素的空间不变性的双线性插值、双三次插值等方法，但是这些方法忽视了图像内容的多样性，会造成过于模糊的纹理结构与细节。</p>\r\n<p>为了处理图像中的不同的内容，稀疏字典学习(sparse dictionary learning)独立地处理每个像素(或者patch)。比如经典的这篇《Image super-resolution via sparse representation》，给LR和HR中的patch学习一对字典，而假设LR和HR图像共享同一个稀疏编码。在推理过程中，给定训练字典，在一个优化过程中求出稀疏编码，从而完成对HR的估计。然而，在训练过程中，（字典与编码的）联合优化的难度还是会影响恢复效果。比如《Raisr: Rapid and accurate image super resolution》这篇中，基于图像的局部梯度统计特征，对图像的patch进行聚类处理，对每一类使用一个滤波器。虽然简单，但这种硬选择(hard-selection)操作是不连续的且不可微的。它们只为变化的输入模式提供折衷的解决方案，而不是最优的解决方案。</p>\r\n<p>而之后，各类深度学习的方法被提出来，但是挑战在于图像内容的无约束性质，当随机梯度存在很大变化时，训练可能是不稳定的。它会导致artifact。残差学习、注意力机制等策略可以缓解这些问题，但这些方法对计算资源要求很高。</p>\r\n<p>与对原图像的直接估计不同，自适应滤波器(核)方法按照空间变化，对相邻像素进行分组。由此带来的好处有两点：</p>\r\n<ol type=\"1\">\r\n<li>估计的像素始终处于环境的凸包内，为了避免视觉伪影的产生（？）</li>\r\n<li>网络只需要评估相邻像素的相对重要性，而不需要预测绝对值，这加快了学习过程</li>\r\n</ol>\r\n<p>本文作者提出了一种，对SISR问题进行线性约束的方法——LAPAR（linearly-assembled pixel-adaptive regression network，线性组合像素自适应回归网络）。核心思想是，对一个进行把LR进行Bicubic插值后的模糊图像，应用一个“像素自适应”的滤波器进行滤波。而滤波器来自于，轻量级的卷积神经网络，这个网络根据每个输入像素，确定预定义的滤波器基的线性组合系数。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<p>方法没有很复杂，用以下图片就可以看出来</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201221215658124.png\" alt=\"image-20201221215658124\"  /></p>\r\n<p>预定义了一堆滤波器字典（也就是线性组合的基）<span class=\"math inline\">\\(\\mathbf{D} \\in \\mathbb{R}^{L \\times k^{2}}\\)</span>，然后设计一个网络LaparNet，输入LR图像，学习每个像素对应的滤波器的系数Coefficients，每个像素所在的Bicubic patch都对应了一个由线性基合成的滤波器（卷积核）。而在实际SR过程中，把Bicubic 插值后的图像，应用每个patch所对应的卷积核，即可恢复出SR图像。</p>\r\n<p>而滤波器字典的采用的都是高斯滤波器（G）和差分高斯滤波器（DoG）： <span class=\"math display\">\\[\r\n\\begin{aligned}\r\nG\\left(\\mathbf{x}-\\mathbf{x}^{\\prime} ; \\mathbf{\\Sigma}\\right)&amp;=\\frac{1}{2 \\pi|\\mathbf{\\Sigma}|^{\\frac{1}{2}}} \\exp \\left\\{-\\frac{1}{2}\\left(\\mathbf{x}-\\mathbf{x}^{\\prime}\\right)^{T} \\mathbf{\\Sigma}^{-1}\\left(\\mathbf{x}-\\mathbf{x}^{\\prime}\\right)\\right\\} \\\\\r\n\\boldsymbol{\\Sigma} &amp;=\\gamma^{2} \\mathbf{U}_{\\theta} \\boldsymbol{\\Lambda} \\mathbf{U}_{\\theta}^{T} \\\\\r\n\\mathbf{U}_{\\theta} &amp;=\\left[\\begin{array}{cc}\r\n\\cos \\theta &amp; -\\sin \\theta \\\\\r\n\\sin \\theta &amp; \\cos \\theta\r\n\\end{array}\\right] \\\\\r\n\\boldsymbol{\\Lambda} &amp;=\\left[\\begin{array}{cc}\r\n\\sigma_{1}^{2} &amp; 0 \\\\\r\n0 &amp; \\sigma_{2}^{2}\r\n\\end{array}\\right] \\\\\r\nD o G\\left(\\mathbf{x}-\\mathbf{x}^{\\prime} ; \\mathbf{\\Sigma}_{1}, \\mathbf{\\Sigma}_{2}\\right)&amp;=G\\left(\\mathbf{x}-\\mathbf{x}^{\\prime} ; \\mathbf{\\Sigma}_{1}\\right)-G\\left(\\mathbf{x}-\\mathbf{x}^{\\prime} ; \\mathbf{\\Sigma}_{2}\\right)\r\n\\end{aligned}\r\n\\]</span></p>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<p>首先对于滤波器字典，作者做了一系列实验：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201221223513296.png\" alt=\"image-20201221223513296\" style=\"zoom: 50%;\" /></p>\r\n<p>然后是与SOTA方法进行对比：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201221223736994.png\" alt=\"image-20201221223736994\" style=\"zoom: 50%;\" /></p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201221223827352.png\" alt=\"image-20201221223827352\" style=\"zoom: 50%;\" /></p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201221224302876.png\" alt=\"image-20201221224302876\" style=\"zoom: 50%;\" /></p>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li>这篇工作的角度比较新颖，利用对滤波器空间的线性约束，充当正则项，进而大大减少网络参数和性能消耗</li>\r\n<li>只给局部patch使用单独滤波器的使用就意味着，在复原时，放弃了对图像更大范围的特征的<strong>直接</strong>捕获，转而使用一个卷积网络学滤波器的系数，<strong>间接</strong>地利用了图像更大范围的特征。感觉颇有Meta-Learning的意味</li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Learning Continuous Image Representation with Local Implicit Image Function","url":"/2021/01/23/2021-01-23-Learning%20Continuous%20Image%20Representation%20with%20Local%20Implicit%20Image%20Function/","content":"<p>经过上次旁听小组会，大致对神经表示的方法有所了解，这是那次组会上张江辉分享的神经表示+超分辨的论文，当时没有太听明白，这回拿出来仔细研读一下。</p>\r\n<p>这篇论文主要利用了神经表示在3D重构中的作用，提出了一个局部隐式图像函数（Local Implicit Image function, LIIF），利用表示的连续性完成任意尺度的超分辨。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"论文背景\">论文背景</h3>\r\n<p>真实的视觉世界应该是连续的，但是机器在捕获一个场景的图片时，会将其离散化采样为2D得像素数组，也就是<strong>基于像素表示的</strong>数字图像。而这种表示方法也带来了“分辨率”这一衡量图像采样质量的描述。而本文的工作是想以一种连续性的表示方法去表示图像，这样，我们可以以任意的分辨率来储存、生成图像。</p>\r\n<p>对于连续地表示图像，经典的编码器-解码器就是一个例子——把图像编码到一个隐空间，这个隐空间就是连续的，再通过一个独立的解码器解码出图像。但作者表示，这种encoder是在实例(instance)之间分享知识(knowledge)的，这里我的理解是encoder是学习了不同的图像(实例)的编码过程，得到了最终的encoder参数(知识)，也就是多个实例共享一个decoder模型的。而decoder也是一样的道理。但是这种表示方法，只能成功地表示简单的图像，无法表示信息丰富的自然图像。据作者推断，这是因为，将自然图像的所有细节编码在一个简单的隐编码中是很困难的。</p>\r\n<p>然后作者基于神经表示的思想，在本文提出一个局部隐式图像函数（Local Implicit Image function, LIIF），用一组<strong>分布在空间维度上</strong>的隐码来表示图像，每个隐码存储关于其<strong>局部区域</strong>的信息。</p>\r\n<p>对于这样一种表示方法，其输入也是一张基于像素表示的离散图像吗，但是LIIF却要生成准确度更高的信息，于是</p>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<h4 id=\"局部隐式图像函数local-implicit-image-function-liif\">局部隐式图像函数（Local Implicit Image function, LIIF）</h4>\r\n<p>在LIIF的表示中，<span class=\"math inline\">\\(I^{(i)}\\)</span>表示<strong>连续图像</strong>，而这个<span class=\"math inline\">\\(I^{(i)}\\)</span>是由一个二维的特征图<span class=\"math inline\">\\(M^{(i)} \\in \\mathbb{R}^{H \\times W \\times D}\\)</span>变换而来的，而一个建模成MLP的神经隐式函数定义为如下： <span class=\"math display\">\\[\r\ns=f(z, x)\r\n\\]</span> 其中<span class=\"math inline\">\\(z\\)</span>是一个特征向量，<span class=\"math inline\">\\(x \\in \\mathcal{X}\\)</span> 是一个二维连续坐标，<span class=\"math inline\">\\(s \\in \\mathcal{S}\\)</span> 是预测的RGB值。这样，每个<span class=\"math inline\">\\(z\\)</span>都可以被看做一个二维坐标到像素值的一个映射：<span class=\"math inline\">\\(f(z, \\cdot): \\mathcal{X} \\mapsto \\mathcal{S}\\)</span>，而这个映射本身<span class=\"math inline\">\\(f(z, \\cdot)\\)</span>正是一种图像的连续的表示。假设<span class=\"math inline\">\\(H\\times W\\)</span>个<span class=\"math inline\">\\(D\\)</span>维特征向量（后文中称为latent code隐码）均匀地分布在连续图像<span class=\"math inline\">\\(I^{(i)}\\)</span>所在的二维空间中，组成了特征图<span class=\"math inline\">\\(M^{(i)}\\)</span>。</p>\r\n<p>更具体地，对于连续图像<span class=\"math inline\">\\(I^{(i)}\\)</span>，在坐标<span class=\"math inline\">\\(x_q\\)</span>处的RGB值可表示为： <span class=\"math display\">\\[\r\nI^{(i)}\\left(x_{q}\\right)=f\\left(z^{*}, x_{q}-v^{*}\\right)\r\n\\]</span> 其中，<span class=\"math inline\">\\(z^*\\)</span>是离坐标<span class=\"math inline\">\\(x_q\\)</span>处欧氏距离最近的latent code，<span class=\"math inline\">\\(v^*\\)</span>是<span class=\"math inline\">\\(z^*\\)</span>的坐标，那么<span class=\"math inline\">\\(x_q-v^*\\)</span>也就是一个坐标偏移（欧式空间中的向量）。</p>\r\n<p>另外，作者为LIIF设置了如下几个trick：</p>\r\n<h5 id=\"特征折叠feature-unfolding\">特征折叠(Feature unfolding)</h5>\r\n<p>为了使得隐码包含更多的空间局部信息，其实就是把原始的<span class=\"math inline\">\\(M^{(i)}\\)</span>的每个3x3相邻的隐码concatenate到一起。</p>\r\n<h5 id=\"feature-unfolding\">Feature unfolding</h5>\r\n<p>式(2)存在一个问题，当目标点的位置从一个<span class=\"math inline\">\\(z\\)</span>的附近渐变到另一个<span class=\"math inline\">\\(z\\)</span>的附近时，<span class=\"math inline\">\\(z^*\\)</span>的选取会发生改变，从而造成像素值的突变，这会大大影响到图像的局部像素值连续性。</p>\r\n<p>对此，作者提出了Feature unfolding的方法，其实就是通过多个<span class=\"math inline\">\\(f(\\cdot)\\)</span>的加权和，扩大<span class=\"math inline\">\\(z\\)</span>的选取范围为离离坐标<span class=\"math inline\">\\(x_q\\)</span>处欧氏距离最近的4个latent code。而根据到坐标<span class=\"math inline\">\\(x_q\\)</span>处的相对距离不同，有不同的权值。 <span class=\"math display\">\\[\r\nI^{(i)}\\left(x_{q}\\right)=\\sum_{t \\in\\{00,01,10,11\\}} \\frac{S_{t}}{S} \\cdot f\\left(z_{t}^{*}, x_{q}-v_{t}^{*}\\right)\r\n\\]</span></p>\r\n<h5 id=\"cell-decoding\">Cell decoding</h5>\r\n<p>设想使用LIIF的表示方法解码出任意分辨率的离散图像的场景，直接的做法是根据所需分辨率，均匀离散地取各个坐标，代入LIIF中查询得到各点的像素值。但是这种做法有一个问题，某个点的查询所得像素值是<strong>独立于目标图像分辨率的</strong>，换句话说，无论是什么分辨率，该点的像素值都是一成不变的，也就是说，其他更精细尺度下的信息在某个粗糙尺度下被完全丢弃了，这其实是不符合常规的图像退化假设的。比如高分辨到低分辨的退化中，并不是单纯的下采样，而是首先伴随一个模糊的过程（双三次、任意模糊核等待），也就是一个整合周围像素信息的过程，而已定义的LIIF把这个过程忽略掉了。</p>\r\n<p>于是作者把图像分辨率信息也加入到LIIF中，具体做法是，把图像长宽的倒数与坐标<span class=\"math inline\">\\(x_q\\)</span>连接在一起： <span class=\"math display\">\\[\r\ns=f_{\\text {cell }}(z,[x, c])\r\n\\]</span></p>\r\n<h4 id=\"学习过程\">学习过程</h4>\r\n<p>学习过程可以用下图概括：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20210124195149674.png\" alt=\"image-20210124195149674\" style=\"zoom: 50%;\" /></p>\r\n<p>由原始的图像作为GT，采样点坐标为<span class=\"math inline\">\\(x_{hr}\\)</span>，对应的像素值为<span class=\"math inline\">\\(s_{hr}\\)</span>，然后进行监督训练。此处loss为L1 loss。</p>\r\n<h3 id=\"实验设计与结果\">实验设计与结果</h3>\r\n<p>训练数据集为DIV2K，把EDSR、RDN去除最后的Upsample模块，作为<span class=\"math inline\">\\(E_{\\varphi}\\)</span>的结构。</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20210124202714069.png\" alt=\"image-20210124202714069\" style=\"zoom: 50%;\" /></p>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li>这是一篇把神经表示应用到超分辨领域的工作，应用的角度也很直接，就是把3D的神经表示应用到2D图像中</li>\r\n<li>不过其没有直接使用一个MLP去强行表示一幅LR图像，而是充分利用了SOTA的SR网络起到的特征提取能力，将提取的特征图作为LIIF的输入，利用超分辨退化的局部性，设置了LIIF的变换过程。\r\n<ul>\r\n<li>换个角度说，其实LIIF就是一个可变的上采样模块，用于替换EDSR等SOTA SR网络的上采样层。只不过在推理过程中，后续的LIIF网络参数是“LR输入相关的”，对于每个LR输入，都需要把上采样层的参数进行重新训练。</li>\r\n<li>我觉得这种模型最大的优点是，对于同一张测试图像下，变换尺度的效率很高，因为只需要更改连续坐标的采样间隔即可。但是对于不同的测试图像，需要额外的时间训练其神经表示，时间效率不高，不过这也是神经表示本身的缺点之一</li>\r\n</ul></li>\r\n<li>其余的特征折叠(Feature unfolding)、Feature unfolding、Cell decoding基本算是根据SR任务的特征加入的小trick</li>\r\n</ul>\r\n<p>$$</p>\r\n<p>$$</p>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读","神经表示"]},{"title":"读论文：Pre-Trained Image Processing Transformer","url":"/2020/12/11/2020-12-11-Pre-Trained%20Image%20Processing%20Transformer/","content":"<p>这篇文章把Transformer应用到low level视觉中，并且把多种low level视觉问题（去噪、超分辨、去雨）放在一起，设计一个预训练模型来统一解决这些问题。</p>\r\n<a id=\"more\"></a>\r\n<h3 id=\"论文背景\">论文背景</h3>\r\n<p>图像处理（Image Processing）是计算机视觉系统的底层部分（low level）的一个组成部分。多种图像处理问题都是相关的，自然想到一个基于某个大的数据集预训练(pre-trained)的模型，很可能对其他的图像处理问题有帮助。但是目前几乎没有研究是把预训练模型应用到Image Processing领域的。</p>\r\n<p>预训练模型，一般用于具有以下两个特征的视觉问题：</p>\r\n<ol type=\"1\">\r\n<li>与任务相关的数据量很有限</li>\r\n<li>在测试数据输入之前，模型是不知道要完成哪个任务的</li>\r\n</ol>\r\n<p>而对于图像处理问题来说：</p>\r\n<ul>\r\n<li>问题(1)往往表现在很多数据是私有的/收费的。此外，各种不一致的因素（如相机参数、光照、天气等）也会进一步干扰捕捉到的训练数据的分布。</li>\r\n<li>问题(2)表现在，对于不同的图像处理任务，其输入输出形式是有差别的（如超分和去噪的输出尺度就不一样等）</li>\r\n</ul>\r\n<p>因此，预训练模型应用到图像处理领域是很有价值的。</p>\r\n<p>在CV的high level任务中，AlexNet、VGGNet、ResNet等在ImageNet数据集上训练的模型已经很常用了。而在NLP中，各种基于Transformer的预训练模型也很常见，比如BERT、GPT-3等。</p>\r\n<p>把Transformer引入CV的研究也有很多，但基本都致力于解决图像分类，目标检测等high level任务中。而与这些High level任务不同的是，Image Processing问题的输入和输出都是一幅图像，所以显然不能直接使用他们的预训练模型。</p>\r\n<p>在本工作中，作者提出了一个用于解决Image Process问题的预训练模型，这个模型使用了Transformer的结构，取名为Image Processing Transformer（IPT）。主要框架如下图：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201213191954911.png\" style=\"zoom:67%;\" /></p>\r\n<h3 id=\"方法详述\">方法详述</h3>\r\n<h4 id=\"ipt的结构\">IPT的结构</h4>\r\n<p>整个结构分为四个部分：Head、Encoder、Decoder、Tail。如上图所示，Encoder、Decoder是公用的，而Head、Tail是任务特异性的。</p>\r\n<h5 id=\"head\">Head</h5>\r\n<p>头部由三个卷积层组成，总的实现<span class=\"math inline\">\\(\\mathbb{R}^{3 \\times H \\times W}\\rightarrow \\mathbb{R}^{C \\times H \\times W}\\)</span>。</p>\r\n<h5 id=\"encoder\">Encoder</h5>\r\n<p>把头部提取的特征拆解成一个个patch，每个patch就是一个“word”（类似NLP中的Transformer）。即对于一个特征图<span class=\"math inline\">\\(f_{H} \\in \\mathbb{R}^{C \\times H \\times W}\\)</span>，拆成patch序列<span class=\"math inline\">\\(f_{p_{i}} \\in \\mathbb{R}^{P^{2} \\times C}, i=\\{1, \\ldots, N\\}\\)</span>，其中<span class=\"math inline\">\\(N=\\frac{H W}{P^{2}}\\)</span>就是Patch的个数。</p>\r\n<p>另外，如同Transformer中的位置编码，为了维持信息，也设置了位置编码<span class=\"math inline\">\\(E_{p_{i}} \\in \\mathbb{R}^{P^{2} \\times C}\\)</span>，最后丢进编码器的是<span class=\"math inline\">\\(E_{p_{i}}+f_{p}\\)</span>。</p>\r\n<p>编码器的结构就使用了Transformer论文中的结构。编码器的输入尺寸也是<span class=\"math inline\">\\(\\mathbb{R}^{P^{2} \\times C}\\)</span>。总的结构形式化如下： <span class=\"math display\">\\[\r\n\\begin{array}{l}\r\ny_{0}=\\left[E_{p_{1}}+f_{p_{1}}, E_{p_{2}}+f_{p_{2}}, \\ldots, E_{p_{N}}+f_{p_{N}}\\right] \\\\\r\nq_{i}=k_{i}=v_{i}=\\mathrm{LN}\\left(y_{i-1}\\right) \\\\\r\ny_{i}^{\\prime}=\\operatorname{MSA}\\left(q_{i}, k_{i}, v_{i}\\right)+y_{i-1} \\\\\r\ny_{i}=\\operatorname{FFN}\\left(\\mathrm{LN}\\left(y_{i}^{\\prime}\\right)\\right)+y_{i}^{\\prime}, \\quad i=1, \\ldots, l \\\\\r\n{\\left[f_{E_{1}}, f_{E_{2}}, \\ldots, f_{E_{N}}\\right]=y_{l}}\r\n\\end{array}\r\n\\]</span> MSA为传统Transformer模型中的multi-head self-attention模块，FFN包含两个全连接层。</p>\r\n<h5 id=\"decoder\">Decoder</h5>\r\n<p>Decoder的结构也类似： <span class=\"math display\">\\[\r\n\\begin{array}{l}\r\nz_{0}=\\left[f_{E_{1}}, f_{E_{2}}, \\ldots, f_{E_{N}}\\right] \\\\\r\nq_{i}=k_{i}=\\mathrm{LN}\\left(z_{i-1}\\right)+E_{t}, v_{i}=\\mathrm{LN}\\left(z_{i-1}\\right) \\\\\r\nz_{i}^{\\prime}=\\operatorname{MSA}\\left(q_{i}, k_{i}, v_{i}\\right)+z_{i-1} \\\\\r\nq_{i}^{\\prime}=\\mathrm{LN}\\left(z_{i}^{\\prime}\\right)+E_{t}, k_{i}^{\\prime}=v_{i}^{\\prime}=\\mathrm{LN}\\left(z_{0}\\right) \\\\\r\nz_{i}^{\\prime \\prime}=\\operatorname{MSA}\\left(q_{i}^{\\prime}, k_{i}^{\\prime}, v_{i}^{\\prime}\\right)+z_{i}^{\\prime} \\\\\r\nz_{i}=\\mathrm{FFN}\\left(\\mathrm{LN}\\left(z_{i}^{\\prime \\prime}\\right)\\right)+z_{i}^{\\prime \\prime}, \\\\\r\n{\\left[f_{D_{1}}, f_{D_{2}}, \\ldots, f_{D_{N}}\\right]=y_{l}}\r\n\\end{array}\r\n\\]</span></p>\r\n<h5 id=\"tail\">Tail</h5>\r\n<p>尾部的结构按照任务的不同有差异。超分辨模型则有一个上采样的操作。</p>\r\n<h4 id=\"在imagenet数据集上的预训练\">在ImageNet数据集上的预训练</h4>\r\n<p>在训练中，作者引入了两种学习的方式，一种是经典的图像恢复中的监督学习；另一个称为对比学习（contrastive learning）。</p>\r\n<h5 id=\"监督学习\">监督学习</h5>\r\n<p>基本操作就是把ImageNet数据集中的各种语义信息全部去除，针对不同的Image Processing问题，使用不同的退化模型构造成对数据集：SR使用双三次退化；denoising加高斯噪声等。</p>\r\n<p>整个过程形式化如下： <span class=\"math display\">\\[\r\n\\begin{array}{l}\r\nI_{\\text {corrupted}}=\\boldsymbol{f}\\left(I_{\\text {clean}}\\right)\\\\\r\n\\mathcal{L}_{\\text {supervised}}=\\sum_{i=1}^{N_{t}} L_{1}\\left(\\operatorname{IPT}\\left(I_{\\text {corrupted}}^{i}\\right), I_{\\text {clean}}\\right)\r\n\\end{array}\r\n\\]</span> 具体实现过程中，对于每一个Batch，随机选择一个图像处理task（如SR、denoising、deraining）对应的成对数据集进行训练。</p>\r\n<h5 id=\"对比学习\">对比学习</h5>\r\n<p>由于IPT模型要用于多个任务，所以为了强化它的泛化能力，引入对比学习，从而引入不同图像的不同patch之间的关系信息。例如，从相同的特征图中裁剪出来的patch更有可能聚在一起，它们更应该被嵌入到相似的位置中。</p>\r\n<p>形式化地，对于每张图<span class=\"math inline\">\\(x_j\\)</span>，它所在的Batch为<span class=\"math inline\">\\(X=\\left\\{x_{1}, x_{2}, \\ldots, x_{B}\\right\\}\\)</span>，其Decode的结果为<span class=\"math inline\">\\(f_{D_{i}}^{j} \\in \\mathbb{R}^{P^{2} \\times C}, i=\\{1, \\ldots, N\\}\\)</span>。目标是最小化来自<strong>同一幅图像</strong>的patch之间的距离，最大化来自<strong>不同图像</strong>的patch之间的距离。所以引入如下损失： <span class=\"math display\">\\[\r\n\\begin{array}{r}\r\nl\\left(f_{D_{i_{1}}}^{j}, f_{D_{i_{2}}}^{j}\\right)=-\\log \\frac{\\exp \\left(d\\left(f_{D_{i_{1}}}^{j}, f_{D_{i_{2}}}^{j}\\right)\\right)}{\\sum_{k=1}^{B} \\mathbb{I}_{k \\neq j} \\exp \\left(d\\left(f_{D_{i_{1}}}^{j}, f_{D_{i_{2}}}^{k}\\right)\\right)} \\\\\r\n\\mathcal{L}_{\\text {constrastive}}=\\frac{1}{B N^{2}} \\sum_{i_{1}=1}^{N} \\sum_{i_{2}=1}^{N} \\sum_{j=1}^{B} l\\left(f_{D_{i_{1}}}^{j}, f_{D_{i_{2}}}^{j}\\right)\r\n\\end{array}\r\n\\]</span> 其中<span class=\"math inline\">\\(d(\\cdot,\\cdot)\\)</span>为余弦相似度<span class=\"math inline\">\\(d(a, b)=\\frac{a^{T} b}{\\|a\\|\\|b\\|}\\)</span>。</p>\r\n<p>最终的loss为： <span class=\"math display\">\\[\r\n\\mathcal{L}_{I P T}=\\lambda \\cdot \\mathcal{L}_{\\text {contrastive}}+\\mathcal{L}_{\\text {supervised}}\r\n\\]</span></p>\r\n<h3 id=\"实验结果\">实验结果</h3>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201213202531504.png\" alt=\"image-20201213202531504\" style=\"zoom:50%;\" /></p>\r\n<p>在各个任务上都达到了SOTA：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201213202617373.png\" alt=\"image-20201213202617373\" style=\"zoom:67%;\" /></p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201213202631010.png\" alt=\"image-20201213202631010\" style=\"zoom:50%;\" /></p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20201213202733752.png\" alt=\"image-20201213202733752\" style=\"zoom:67%;\" /></p>\r\n<h3 id=\"总结与思考\">总结与思考</h3>\r\n<ul>\r\n<li><p>利用Transformer的强大表示能力+ImageNet的海量数据，作者成功达到的多个low level问题的SOTA，真的很吃惊，虽然源码没有放出来，但是放出来也很难复现整个训练过程（32张V100.。。）</p></li>\r\n<li><p>作者给Transformer+low level挖了个新坑，读这篇文章让我系统性的学了一下Transformer相关的内容，这是我之前忽视的知识，感觉还是挺有收获的</p></li>\r\n</ul>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读"]},{"title":"读论文：Exploiting Deep Generative Prior for Versatile Image Restoration and Manipulation","url":"/2021/01/23/2021-01-29-Exploiting%20Deep%20Generative%20Prior%20for%20Versatile%20Image%20Restoration%20and%20Manipulation/","content":"<h3 id=\"论文背景\">论文背景</h3>\r\n<h3 id=\"主要方法\">主要方法</h3>\r\n<p>​</p>\r\n","categories":["科研"],"tags":["图像超分辨","论文阅读","神经表示"]},{"title":"如何读论文","url":"/2021/12/19/2021-12-19-how_to_read_paper/","content":"<p>来源：Bilibili</p>\r\n<p>英文版：<a href=\"https://www.bilibili.com/video/BV1Y54y1t78m?from=search&amp;seid=6809677342001715473&amp;spm_id_from=333.337.0.0\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://www.bilibili.com/video/BV1Y54y1t78m?from=search&amp;seid=6809677342001715473&amp;spm_id_from=333.337.0.0</a></p>\r\n<p>带翻译：https://www.bilibili.com/video/BV1A64y1v77W/?spm_id_from=333.788.b_7265636f5f6c697374.2</p>\r\n<a id=\"more\"></a>\r\n<h2 id=\"阅读的步骤\">阅读的步骤</h2>\r\n<ol type=\"1\">\r\n<li>标题、摘要、图表</li>\r\n<li>Intro、结论、（仔细地看）图表、略读剩下的\r\n<ol type=\"1\">\r\n<li>除非要了解领域中最重要的几篇论文，否则，<strong>跳过related work！</strong>：没啥用，该不懂的还是不懂，<del>related work只是论文作者为了增加审稿人被引的概率</del></li>\r\n</ol></li>\r\n<li>看剩下的论文，但是跳过数学部分</li>\r\n<li>阅读整篇，但是跳过没意义的部分</li>\r\n</ol>\r\n<h2 id=\"读完论文后\">读完论文后</h2>\r\n<p>问几个问题</p>\r\n<ol type=\"1\">\r\n<li>作者要完成什么？</li>\r\n<li>key elements 关键要素是啥？</li>\r\n<li>我能从中用什么？what can you use yourself?</li>\r\n<li>还想关注哪些参考文献?</li>\r\n</ol>\r\n","categories":["知识总结"],"tags":["科研"]},{"title":"矩阵微积分","url":"/2021/02/28/2021-02-28-Matrix%20calculus/","content":"<p>指的是列向量</p>\r\n<h2 id=\"矩阵求导\">矩阵求导</h2>\r\n<p>矩阵求导在最大似然问题中经常出现。总的来说，矩阵求导有四种类型，可以用下列表格表示：</p>\r\n<p><img src=\"https://img-1302874500.cos.ap-shanghai-fsi.myqcloud.com/imagesimage-20210228112100880.png\" alt=\"image-20210228112100880\" style=\"zoom:67%;\" /></p>\r\n<p>一句话概括：<strong>分子的偏导符号根据<span class=\"math inline\">\\(\\mathbf{Y}\\)</span>的形状展开，而分母的偏导符号根据<span class=\"math inline\">\\(\\mathbf{X}\\)</span>的形状的转置展开。</strong>举例来说，<span class=\"math inline\">\\(\\mathrm d \\mathbf y / \\mathrm{d} x\\)</span>是一个列向量，<span class=\"math inline\">\\(\\mathrm{d} y / \\mathrm{d} \\mathbf{x}\\)</span>是一个行向量（假设<span class=\"math inline\">\\(\\mathbf y\\)</span>和<span class=\"math inline\">\\(\\mathbf x\\)</span>都指的是列向量）。每个积分都可以这样“冗长地”通过标量的偏导来计算，但是本节展示如何来通过矩阵操作来计算矩阵求导。</p>\r\n<a id=\"more\"></a>\r\n<p>就像工数中学习的那样，定义微分<span class=\"math inline\">\\(dy(x)\\)</span>为增量<span class=\"math inline\">\\(y(x+\\mathrm{d} x)-y(x)\\)</span>对<span class=\"math inline\">\\(dx\\)</span>的线性主部。<strong>不像是经典的极限定义，这里的定义即使在<span class=\"math inline\">\\(x\\)</span>或<span class=\"math inline\">\\(y\\)</span>不是标量的情况下也成立。</strong></p>\r\n<p>举例来说，下面的等式： <span class=\"math display\">\\[\r\n\\mathbf{y}(\\mathbf{x}+\\mathrm{d} \\mathbf{x})=\\mathbf{y}(\\mathbf{x})+\\mathbf{A} \\mathrm{d} \\mathbf{x}+(\\text {更高阶的无穷小项} )\r\n\\]</span> 对于任意满足一定连续性的<span class=\"math inline\">\\(\\mathbf y\\)</span>都有定义。式中的矩阵<span class=\"math inline\">\\(\\mathbf A\\)</span>就是导数，又叫做雅可比矩阵<span class=\"math inline\">\\(\\mathbf{J}_{x \\rightarrow y}\\)</span>。它的转置即为<span class=\"math inline\">\\(y\\)</span>的梯度<span class=\"math inline\">\\(\\nabla \\mathbf{y}\\)</span>。雅可比矩阵在微积分中很有用，而梯度在优化问题中很有用。</p>\r\n<p>因此，对于任意表达式的导数都可以用两个步骤来计算：</p>\r\n<ol type=\"1\">\r\n<li>计算其微分</li>\r\n<li>把结果写成规范的形式</li>\r\n</ol>\r\n<p>然后矩阵导数就能够从<span class=\"math inline\">\\(\\mathrm{d} x, \\mathrm{~d} \\mathbf{x},\\)</span> 或者<span class=\"math inline\">\\(\\mathrm{d} \\mathbf{X}\\)</span>的系数中直接读出。</p>\r\n<p>第二步规范化的过程可以通过以下定理来完成： <span class=\"math display\">\\[\r\n\\mathrm{dA}=0 \\text { (for constant } \\mathbf{A})\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\mathrm{d}(\\alpha \\mathbf{X})=\\alpha \\mathrm{d} \\mathbf{X}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\mathrm{d}(\\mathbf{X}+\\mathbf{Y})=\\mathrm{d} \\mathbf{X}+\\mathrm{d} \\mathbf{Y}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\mathrm{d}(\\operatorname{tr}(\\mathbf{X}))=\\operatorname{tr}(\\mathrm{d} \\mathbf{X})\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\mathrm{d}(\\mathrm{XY})=(\\mathrm{d} \\mathrm{X}) \\mathrm{Y}+\\mathrm{XdY}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\mathrm{d}(\\mathrm{X} \\otimes \\mathrm{Y})=(\\mathrm{d} \\mathrm{X}) \\otimes \\mathrm{Y}+\\mathrm{X} \\otimes \\mathrm{d} \\mathrm{Y} \\quad \\text { (see section 2) }\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\mathrm{d}(\\mathrm{X} \\circ \\mathrm{Y})=(\\mathrm{d} \\mathrm{X}) \\circ \\mathrm{Y}+\\mathrm{X} \\circ \\mathrm{d} \\mathrm{Y} \\quad(\\text {see section } 5)\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\mathrm{d} \\mathbf{X}^{-1}=-\\mathbf{X}^{-1}(\\mathrm{~d} \\mathbf{X}) \\mathbf{X}^{-1}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\mathrm{d}|\\mathbf{X}|=|\\mathbf{X}| \\operatorname{tr}\\left(\\mathbf{X}^{-1} \\mathrm{~d} \\mathbf{X}\\right)\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\mathrm{d} \\log |\\mathbf{X}|=\\operatorname{tr}\\left(\\mathbf{X}^{-1} \\mathrm{~d} \\mathbf{X}\\right)\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\mathrm{d} \\mathbf{X}^{\\star}=(\\mathrm{d} \\mathbf{X})^{\\star}\r\n\\]</span></p>\r\n<p>（12）式中的*指的是任意对元素的重排操作，比如转置、向量化、向量化-转置等。</p>\r\n<p>以上大多数规则可以通过计算<span class=\"math inline\">\\(\\mathbf{F}(\\mathbf{X}+\\mathrm{d} \\mathbf{X})-\\mathbf{F}(\\mathbf{X})\\)</span>，然后取线性主部来导出，比如(6)式： <span class=\"math display\">\\[\r\n\\because (\\mathbf{X}+\\mathrm{d} \\mathbf{X})(\\mathbf{Y}+\\mathrm{d} \\mathbf{Y})=\\mathbf{X} \\mathbf{Y}+(\\mathrm{d} \\mathbf{X}) \\mathbf{Y}+\\mathbf{X} \\mathrm{d} \\mathbf{Y}+(\\mathrm{d} \\mathbf{X})(\\mathrm{d} \\mathbf{Y})  \\nonumber \\\\\r\n\\therefore (\\mathbf{X}+\\mathrm{d} \\mathbf{X})(\\mathbf{Y}+\\mathrm{d} \\mathbf{Y})-\\mathbf{X} \\mathbf{Y}=(\\mathrm{d} \\mathbf{X}) \\mathbf{Y}+\\mathbf{X} \\mathrm{d} \\mathbf{Y}+(\\mathrm{d} \\mathbf{X})(\\mathrm{d} \\mathbf{Y}) \\\\\r\n\\therefore \\mathrm{d}(\\mathbf{XY})=(\\mathrm{d} \\mathbf{X}) \\mathbf{Y}+\\mathbf X \\mathrm d\\mathbf Y\r\n\\]</span> 而要导出<span class=\"math inline\">\\(\\mathrm d\\mathbf{X}^{-1}\\)</span>，可以通过下式导出： <span class=\"math display\">\\[\r\n0=\\mathrm{d} \\mathbf{I}=\\mathrm{d} \\mathbf{X}^{-1} \\mathbf{X}=\\left(\\mathrm{d} \\mathbf{X}^{-1}\\right) \\mathbf{X}+\\mathbf{X}^{-1} \\mathrm{~d} \\mathbf{X}\r\n\\]</span></p>\r\n<p>下一步，把微分推导为以下六种规范形式（假设<span class=\"math inline\">\\(\\mathbf x\\)</span>和<span class=\"math inline\">\\(\\mathbf y\\)</span>都是列向量）：</p>\r\n<p><img src=\"C:\\Users\\Jame Kuma\\AppData\\Roaming\\Typora\\typora-user-images\\image-20210228123320421.png\" alt=\"image-20210228123320421\" style=\"zoom: 67%;\" /></p>\r\n","categories":["知识总结"],"tags":["数学"]},{"title":"相机的内参和外参&相机畸变矫正","url":"/2022/07/07/2022-07-07-Camera_para/","content":"<p>参考了文章：</p>\r\n<ol type=\"1\">\r\n<li><a href=\"https://zhuanlan.zhihu.com/p/389653208\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://zhuanlan.zhihu.com/p/389653208</a></li>\r\n<li><a href=\"https://zhuanlan.zhihu.com/p/356925508\" target=\"_blank\" rel=\"noopener\" class=\"uri\">https://zhuanlan.zhihu.com/p/356925508</a></li>\r\n</ol>\r\n<h2 id=\"相机的内参和外参\">相机的内参和外参</h2>\r\n<h3 id=\"相机内参\">相机内参</h3>\r\n<p><img src=\"https://pic2.zhimg.com/80/v2-b7e496c4e2f9250b3705880fe2858c3d_720w.jpg\" alt=\"img\" style=\"zoom: 80%;\" /></p>\r\n<a id=\"more\"></a>\r\n<p>左图中，把相机看作是针孔，<strong>现实世界</strong>中的点P经过相机的光心O，投影到<strong>物理成像平面</strong>上，变为点P'。</p>\r\n<p>右图中，对这个模型进行了一个简化，将其看作是一个相似三角形。</p>\r\n<p>设<span class=\"math inline\">\\(O-x-y-z\\)</span>为相机坐标系，习惯上我们把z轴指向相机前方，x向右，y向下。O为摄像机的<strong>光心</strong>，也是针孔模型中的针孔。</p>\r\n<p>设现实世界中的点的的坐标为<span class=\"math inline\">\\([X,Y,Z]^T\\)</span>，而成像点的坐标为<span class=\"math inline\">\\([X&#39;, Y&#39;,Z&#39;]\\)</span>，物理成像平面到光心的距离为<span class=\"math inline\">\\(f\\)</span>，也就是焦距。所以根据右图的相似三角形关系，有以下式子： <span class=\"math display\">\\[\r\n\\frac{Z}{f}=-\\frac{X}{X^{\\prime}}=-\\frac{Y}{Y^{\\prime}}\r\n\\]</span> 其中，有负号是因为坐标轴方向，也就表示了成的像是倒立的。</p>\r\n<p>为了表示起来更方便，我们把成像平面从相机的后面对称到前面去，如下图所示。这样，负号就没有了。</p>\r\n<p><img src=\"https://pic3.zhimg.com/80/v2-e205e941aa8e549d802907a1eaa059ba_720w.jpg\" alt=\"img\" style=\"zoom:50%;\" /> <span class=\"math display\">\\[\r\n\\frac{Z}{f}=\\frac{X}{X^{\\prime}}=\\frac{Y}{Y^{\\prime}}\r\n\\]</span> 整理出P'的坐标： <span class=\"math display\">\\[\r\n\\begin{aligned}\r\n&amp;X^{\\prime}=f \\frac{X}{Z} \\\\\r\n&amp;Y^{\\prime}=f \\frac{Y}{Z}\r\n\\end{aligned}\r\n\\]</span> 然而物理成像平面是不够的，还需要放在像素坐标系里面。设P'在像素坐标系下对应的坐标为<span class=\"math inline\">\\([u,v]^T\\)</span>。</p>\r\n<p>那么物理成像平面到像素坐标系的变换只涉及到缩放和平移。设像素坐标在u轴上缩放了<span class=\"math inline\">\\(\\alpha\\)</span>倍，在v轴上缩放了<span class=\"math inline\">\\(\\beta\\)</span>倍。同时原点平移了<span class=\"math inline\">\\([c_x, c_y]^T\\)</span>。那么可以得到P'与像素坐标的关系： <span class=\"math display\">\\[\r\n\\begin{aligned}\r\n&amp;u=\\alpha X^{\\prime}+c_{x} \\\\\r\n&amp;v=\\beta Y^{\\prime}+c_{y}\r\n\\end{aligned}\r\n\\]</span> 代入P与P'的关系式可得： <span class=\"math display\">\\[\r\n\\begin{aligned}\r\n&amp;u=\\alpha f \\frac{X}{Z}+c_{x}=f_{x} \\frac{X}{Z}+c_{x} \\\\\r\n&amp;v=\\beta f \\frac{Y}{Z}+c_{y}=f_{y} \\frac{Y}{Z}+c_{y}\r\n\\end{aligned}\r\n\\]</span> 用齐次坐标，把上式写出矩阵的形式： <span class=\"math display\">\\[\r\n\\left(\\begin{array}{l}\r\nu \\\\\r\nv \\\\\r\n1\r\n\\end{array}\\right)=\\frac{1}{Z}\\left(\\begin{array}{ccc}\r\nf_{x} &amp; 0 &amp; c_{x} \\\\\r\n0 &amp; f_{y} &amp; c_{y} \\\\\r\n0 &amp; 0 &amp; 1\r\n\\end{array}\\right)\\left(\\begin{array}{c}\r\nX \\\\\r\nY \\\\\r\nZ\r\n\\end{array}\\right)=\\frac{1}{Z} \\mathbf{K} \\mathbf{P}\r\n\\]</span> 也可以把Z写到等式左边去，就变成了： <span class=\"math display\">\\[\r\nZ\\left(\\begin{array}{l}\r\nu \\\\\r\nv \\\\\r\n1\r\n\\end{array}\\right)=\\left(\\begin{array}{ccc}\r\nf_{x} &amp; 0 &amp; c_{x} \\\\\r\n0 &amp; f_{y} &amp; c_{y} \\\\\r\n0 &amp; 0 &amp; 1\r\n\\end{array}\\right)\\left(\\begin{array}{l}\r\nX \\\\\r\nY \\\\\r\nZ\r\n\\end{array}\\right)=\\mathbf{K} \\mathbf{P}\r\n\\]</span> 上式中，<span class=\"math inline\">\\(\\mathbf{K}\\)</span>即为相机的内参矩阵(Intrinsics)。通常来说，相机的内参在出厂之后就是固定的了。</p>\r\n<h3 id=\"相机外参\">相机外参</h3>\r\n<p>在上面的推导中，我们用的是<span class=\"math inline\">\\(P\\)</span>在相机坐标系的坐标（也就是以相机光心为O点）。应该先将世界坐标系的<span class=\"math inline\">\\(P_w\\)</span>转换为相机坐标系<span class=\"math inline\">\\(P\\)</span>。</p>\r\n<p>这里需要用到相机的位姿，由旋转矩阵<span class=\"math inline\">\\(\\mathbf R\\)</span>与平移向量<span class=\"math inline\">\\(\\mathbf t\\)</span>来表示，故： <span class=\"math display\">\\[\r\n\\mathbf{P}=\\left(\\begin{array}{ccc}\r\nX \\\\\r\nY \\\\\r\nZ\r\n\\end{array}\\right)=\\mathbf{R} \\mathbf{P}_{\\mathbf{w}}+\\mathbf{t}\r\n\\]</span> 写成齐次形式： <span class=\"math display\">\\[\r\n\\mathbf P_{齐}=\\left(\\begin{array}{c}\r\nX \\\\\r\nY \\\\\r\nZ \\\\\r\n1\r\n\\end{array}\\right)=\\left(\\begin{array}{cc}\r\n\\mathbf R &amp; \\mathbf t \\\\\r\n0^{3} &amp; 1\r\n\\end{array}\\right)\\left(\\begin{array}{c}\r\nx_{w} \\\\\r\ny_{w} \\\\\r\nz_{w} \\\\\r\n1\r\n\\end{array}\\right)\r\n\\]</span> <span class=\"math inline\">\\(\\left(\\begin{array}{cc} \\mathbf R &amp; \\mathbf t \\\\ 0^{3} &amp; 1 \\end{array}\\right)\\)</span>即为外参矩阵(Extrinsics)</p>\r\n<h2 id=\"相机畸变矫正\">相机畸变矫正</h2>\r\n<p>相机主要包括径向畸变和切向畸变</p>\r\n<h3 id=\"径向畸变\">径向畸变</h3>\r\n<p>径向畸变（枕形、桶形）：光线在远离透镜中心的地方比靠近中心的地方更加弯曲，如下图</p>\r\n<p><img src=\"https://pic4.zhimg.com/80/v2-6f3c207f9be768df7b5a68cd25dd72cb_720w.jpg\" alt=\"img\" style=\"zoom: 67%;\" /></p>\r\n<p>有径向畸变的原始图像和矫正后的图像:</p>\r\n<p><img src=\"https://pic2.zhimg.com/80/v2-2ce9c2850872c32d3481d25a71dd5a39_720w.jpg\" alt=\"img\" style=\"zoom: 80%;\" /></p>\r\n<p><span class=\"math inline\">\\(\\mathrm{r}\\)</span> 是以图像 <span class=\"math inline\">\\(\\left[u_{0}, v_{0}\\right]\\)</span> 中心为半径的圆 <span class=\"math display\">\\[\r\nr^{2}=\\left(u-u_{0}\\right)^{2}+\\left(v-v_{0}\\right)^{2}\r\n\\]</span> 根据图像的畸变的程度, 有的时候为了简化相机模型, 高阶项 <span class=\"math inline\">\\(k_{2}, k_{3}\\)</span> 有时候会被舍弃。</p>\r\n<h3 id=\"切向畸变\">切向畸变</h3>\r\n<p>切向畸变：透镜不完全平行于图像平面，即sensor装配时与镜头间的角度不准，这样会导致图像的中心有所偏移(decentering)，如下图</p>\r\n<p><img src=\"https://pic2.zhimg.com/80/v2-b33329c1686f5120af7fd5dd4d49734d_720w.jpg\" alt=\"img\" style=\"zoom: 67%;\" /></p>\r\n<p>上述式子中加入切向畸变后： <span class=\"math display\">\\[\r\n\\left[\\begin{array}{l}\r\nu_{d} \\\\\r\nv_{d}\r\n\\end{array}\\right]=\\left(1+k_{1} r^{2}+k_{2} r^{4}+k_{3} r^{6}\\right)\\left[\\begin{array}{l}\r\nu-u_{0} \\\\\r\nv-v_{0}\r\n\\end{array}\\right]+\\left[\\begin{array}{l}\r\n2 k_{4}\\left(u-u_{0}\\right)\\left(v-v_{0}\\right)+k_{5}\\left(r^{2}+2\\left(u-u_{0}\\right)^{2}\\right) \\\\\r\nk_{4}\\left(r^{2}+2\\left(v-v_{0}\\right)^{2}\\right)+2 k_{5}\\left(u-u_{0}\\right)\\left(v-v_{0}\\right)\r\n\\end{array}\\right]+\\left[\\begin{array}{l}\r\nu_{0} \\\\\r\nv_{0}\r\n\\end{array}\\right]\r\n\\]</span></p>\r\n","categories":["知识总结"],"tags":["感知","图像","点云"]}]